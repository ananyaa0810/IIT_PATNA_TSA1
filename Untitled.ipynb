{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d65f2-90d4-4dad-ac88-4fb694532873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 04:08:48.444714\n",
      "2024-07-01-04-08-48\n",
      "errors_2024-07-01-04-08-48.txt\n",
      "(146242, 18)\n",
      "(81446, 18)\n",
      "(227688, 17)\n",
      "(227688,)\n",
      "(227688, 17)\n",
      "(227688,)\n",
      "******************************\n",
      "Decison Tree Completed :) \n",
      "******************************\n",
      "Linear Regression Completed :) \n",
      "******************************\n",
      "LogisticRegression Completed :) \n",
      "******************************\n",
      "KNN Completed :) \n",
      "******************************\n",
      "Random forest Completed :) \n",
      "******************************\n",
      "MLP Completed :) \n",
      "******************************\n",
      "Bagging Completed :) \n",
      "******************************\n",
      "J48 Completed :) \n",
      "******************************\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "ANN Completed :) \n",
      "******************************\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "DNN Completed :) \n",
      "******************************\n",
      "GradientBoostingClassifier Completed :) \n",
      "******************************\n",
      "XGBClassifier Completed :) \n",
      "******************************\n",
      "Gaussian_Naive_Bayes Completed :) \n",
      "******************************\n",
      "Adaptive Gradient Boosting Completed :) \n",
      "******************************\n",
      "QDA Completed :) \n",
      "******************************\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "SNN Completed :)  \n",
      "******************************\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "RBM Completed :)  \n",
      "******************************\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step\n",
      "lstm Completed :)  \n",
      "******************************\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "reconstruction neural networks, Completed :)  \n",
      "******************************\n",
      "Epoch 1/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.2627 - source_classifier_accuracy: 0.5567 - val_loss: 0.8531 - val_source_classifier_accuracy: 0.7287\n",
      "Epoch 2/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.8341 - source_classifier_accuracy: 0.7174 - val_loss: 0.7019 - val_source_classifier_accuracy: 0.7910\n",
      "Epoch 3/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.7218 - source_classifier_accuracy: 0.7567 - val_loss: 0.6389 - val_source_classifier_accuracy: 0.7922\n",
      "Epoch 4/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6719 - source_classifier_accuracy: 0.7681 - val_loss: 0.6073 - val_source_classifier_accuracy: 0.7923\n",
      "Epoch 5/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6413 - source_classifier_accuracy: 0.7777 - val_loss: 0.5858 - val_source_classifier_accuracy: 0.8049\n",
      "Epoch 6/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6229 - source_classifier_accuracy: 0.7836 - val_loss: 0.5691 - val_source_classifier_accuracy: 0.8072\n",
      "Epoch 7/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6059 - source_classifier_accuracy: 0.7882 - val_loss: 0.5567 - val_source_classifier_accuracy: 0.8196\n",
      "Epoch 8/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5971 - source_classifier_accuracy: 0.7943 - val_loss: 0.5447 - val_source_classifier_accuracy: 0.8153\n",
      "Epoch 9/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5811 - source_classifier_accuracy: 0.7970 - val_loss: 0.5349 - val_source_classifier_accuracy: 0.8156\n",
      "Epoch 10/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5704 - source_classifier_accuracy: 0.8021 - val_loss: 0.5254 - val_source_classifier_accuracy: 0.8242\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.2558 - source_classifier_accuracy: 0.5563 - val_loss: 0.8264 - val_source_classifier_accuracy: 0.7493\n",
      "Epoch 2/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.8107 - source_classifier_accuracy: 0.7289 - val_loss: 0.6881 - val_source_classifier_accuracy: 0.7828\n",
      "Epoch 3/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.7124 - source_classifier_accuracy: 0.7572 - val_loss: 0.6319 - val_source_classifier_accuracy: 0.7925\n",
      "Epoch 4/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.6627 - source_classifier_accuracy: 0.7707 - val_loss: 0.6012 - val_source_classifier_accuracy: 0.7996\n",
      "Epoch 5/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6339 - source_classifier_accuracy: 0.7803 - val_loss: 0.5789 - val_source_classifier_accuracy: 0.8070\n",
      "Epoch 6/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.6062 - source_classifier_accuracy: 0.7888 - val_loss: 0.5620 - val_source_classifier_accuracy: 0.8093\n",
      "Epoch 7/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5925 - source_classifier_accuracy: 0.7955 - val_loss: 0.5473 - val_source_classifier_accuracy: 0.8198\n",
      "Epoch 8/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5770 - source_classifier_accuracy: 0.7999 - val_loss: 0.5364 - val_source_classifier_accuracy: 0.8179\n",
      "Epoch 9/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5657 - source_classifier_accuracy: 0.8030 - val_loss: 0.5291 - val_source_classifier_accuracy: 0.8259\n",
      "Epoch 10/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.5565 - source_classifier_accuracy: 0.8049 - val_loss: 0.5156 - val_source_classifier_accuracy: 0.8238\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 1.2600 - source_classifier_accuracy: 0.5572 - val_loss: 0.8418 - val_source_classifier_accuracy: 0.7412\n",
      "Epoch 2/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.8226 - source_classifier_accuracy: 0.7228 - val_loss: 0.6891 - val_source_classifier_accuracy: 0.7803\n",
      "Epoch 3/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.7162 - source_classifier_accuracy: 0.7582 - val_loss: 0.6289 - val_source_classifier_accuracy: 0.7930\n",
      "Epoch 4/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6595 - source_classifier_accuracy: 0.7737 - val_loss: 0.5922 - val_source_classifier_accuracy: 0.8004\n",
      "Epoch 5/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6301 - source_classifier_accuracy: 0.7822 - val_loss: 0.5671 - val_source_classifier_accuracy: 0.8117\n",
      "Epoch 6/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6035 - source_classifier_accuracy: 0.7916 - val_loss: 0.5472 - val_source_classifier_accuracy: 0.8205\n",
      "Epoch 7/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5896 - source_classifier_accuracy: 0.7951 - val_loss: 0.5345 - val_source_classifier_accuracy: 0.8208\n",
      "Epoch 8/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5780 - source_classifier_accuracy: 0.7992 - val_loss: 0.5254 - val_source_classifier_accuracy: 0.8231\n",
      "Epoch 9/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5645 - source_classifier_accuracy: 0.8021 - val_loss: 0.5111 - val_source_classifier_accuracy: 0.8297\n",
      "Epoch 10/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5515 - source_classifier_accuracy: 0.8072 - val_loss: 0.5047 - val_source_classifier_accuracy: 0.8311\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.2623 - source_classifier_accuracy: 0.5610 - val_loss: 0.8537 - val_source_classifier_accuracy: 0.6924\n",
      "Epoch 2/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.8360 - source_classifier_accuracy: 0.7141 - val_loss: 0.6978 - val_source_classifier_accuracy: 0.7571\n",
      "Epoch 3/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.7204 - source_classifier_accuracy: 0.7579 - val_loss: 0.6296 - val_source_classifier_accuracy: 0.7831\n",
      "Epoch 4/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6614 - source_classifier_accuracy: 0.7733 - val_loss: 0.5939 - val_source_classifier_accuracy: 0.7989\n",
      "Epoch 5/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6301 - source_classifier_accuracy: 0.7811 - val_loss: 0.5715 - val_source_classifier_accuracy: 0.8052\n",
      "Epoch 6/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6062 - source_classifier_accuracy: 0.7893 - val_loss: 0.5507 - val_source_classifier_accuracy: 0.8158\n",
      "Epoch 7/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5881 - source_classifier_accuracy: 0.7964 - val_loss: 0.5356 - val_source_classifier_accuracy: 0.8132\n",
      "Epoch 8/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5705 - source_classifier_accuracy: 0.8005 - val_loss: 0.5261 - val_source_classifier_accuracy: 0.8186\n",
      "Epoch 9/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.5609 - source_classifier_accuracy: 0.8056 - val_loss: 0.5144 - val_source_classifier_accuracy: 0.8263\n",
      "Epoch 10/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5527 - source_classifier_accuracy: 0.8086 - val_loss: 0.5079 - val_source_classifier_accuracy: 0.8281\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 1.2747 - source_classifier_accuracy: 0.5523 - val_loss: 0.8610 - val_source_classifier_accuracy: 0.6758\n",
      "Epoch 2/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.8461 - source_classifier_accuracy: 0.7108 - val_loss: 0.7028 - val_source_classifier_accuracy: 0.7798\n",
      "Epoch 3/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7285 - source_classifier_accuracy: 0.7536 - val_loss: 0.6393 - val_source_classifier_accuracy: 0.7867\n",
      "Epoch 4/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6682 - source_classifier_accuracy: 0.7707 - val_loss: 0.6057 - val_source_classifier_accuracy: 0.7913\n",
      "Epoch 5/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6393 - source_classifier_accuracy: 0.7801 - val_loss: 0.5822 - val_source_classifier_accuracy: 0.8046\n",
      "Epoch 6/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6128 - source_classifier_accuracy: 0.7873 - val_loss: 0.5644 - val_source_classifier_accuracy: 0.8099\n",
      "Epoch 7/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5957 - source_classifier_accuracy: 0.7957 - val_loss: 0.5512 - val_source_classifier_accuracy: 0.8181\n",
      "Epoch 8/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5856 - source_classifier_accuracy: 0.7996 - val_loss: 0.5369 - val_source_classifier_accuracy: 0.8237\n",
      "Epoch 9/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.5674 - source_classifier_accuracy: 0.8044 - val_loss: 0.5273 - val_source_classifier_accuracy: 0.8204\n",
      "Epoch 10/10\n",
      "\u001b[1m2847/2847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.5644 - source_classifier_accuracy: 0.8055 - val_loss: 0.5197 - val_source_classifier_accuracy: 0.8218\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "DANN Completed :)  \n",
      "******************************\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -1.85, time = 6.84s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1.76, time = 6.30s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -1.67, time = 6.37s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1.68, time = 6.33s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1.71, time = 6.59s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1.65, time = 7.88s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -1.79, time = 8.15s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -1.63, time = 6.99s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -1.72, time = 6.76s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -2.06, time = 7.84s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -1.77, time = 7.26s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -1.69, time = 7.52s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -2.03, time = 7.08s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -2.18, time = 7.87s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -1.83, time = 7.98s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -1.77, time = 7.78s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -2.34, time = 6.57s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -1.70, time = 8.48s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -1.78, time = 7.78s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -1.64, time = 8.58s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -1.82, time = 7.39s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1.72, time = 8.22s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -1.63, time = 8.09s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1.72, time = 7.98s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1.64, time = 7.22s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1.64, time = 7.49s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -1.85, time = 8.33s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -1.68, time = 7.64s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -1.66, time = 7.87s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -1.61, time = 7.58s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -1.68, time = 8.46s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -1.76, time = 7.93s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -1.66, time = 7.74s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -1.95, time = 8.06s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -1.79, time = 7.78s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -2.29, time = 8.21s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -1.59, time = 7.74s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -1.59, time = 7.58s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -2.44, time = 7.12s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -1.89, time = 8.09s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -1.81, time = 6.45s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1.68, time = 8.78s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -1.60, time = 6.91s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1.65, time = 7.65s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1.63, time = 8.07s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1.68, time = 6.94s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -1.71, time = 7.85s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -1.88, time = 7.58s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -1.68, time = 8.06s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -1.61, time = 8.38s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -1.75, time = 8.62s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -1.89, time = 8.43s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -2.35, time = 7.70s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -1.86, time = 6.85s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -2.40, time = 7.99s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -1.72, time = 8.07s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -2.66, time = 7.30s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -1.84, time = 6.53s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -1.72, time = 7.41s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -1.96, time = 8.08s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -1.82, time = 6.30s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1.78, time = 7.42s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -1.66, time = 8.28s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1.76, time = 7.76s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1.71, time = 7.30s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1.62, time = 7.10s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -1.75, time = 7.11s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -1.79, time = 7.33s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -1.59, time = 7.14s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -1.73, time = 7.98s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -1.76, time = 7.28s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -1.67, time = 8.00s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -1.77, time = 6.68s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -2.19, time = 8.29s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -1.79, time = 7.29s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -1.62, time = 7.22s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -2.11, time = 6.92s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -1.73, time = 7.21s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -2.41, time = 7.69s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -1.58, time = 7.09s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -1.79, time = 5.84s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1.75, time = 7.99s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -1.67, time = 7.41s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1.67, time = 7.20s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1.75, time = 7.20s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1.59, time = 7.05s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -1.73, time = 6.73s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -1.75, time = 7.84s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -1.79, time = 7.86s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -1.61, time = 7.59s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -2.08, time = 6.55s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -1.96, time = 7.15s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -1.85, time = 7.44s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -2.00, time = 7.13s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -1.70, time = 7.54s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -1.65, time = 6.37s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -1.57, time = 7.94s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -1.78, time = 6.94s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -1.98, time = 7.51s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -1.61, time = 7.60s\n",
      "******************************\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "******************************\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1424/1424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Epoch 1/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4681 - loss: 1.5424\n",
      "Epoch 2/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6320 - loss: 1.0168\n",
      "Epoch 3/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6869 - loss: 0.8911\n",
      "Epoch 4/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.7777\n",
      "Epoch 5/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7686 - loss: 0.7031\n",
      "Epoch 6/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7760 - loss: 0.6625\n",
      "Epoch 7/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7896 - loss: 0.6204\n",
      "Epoch 8/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7835 - loss: 0.6223\n",
      "Epoch 9/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7983 - loss: 0.5899\n",
      "Epoch 10/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.5836\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4851 - loss: 1.5482\n",
      "Epoch 2/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6329 - loss: 1.0172\n",
      "Epoch 3/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6753 - loss: 0.9044\n",
      "Epoch 4/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7259 - loss: 0.8064\n",
      "Epoch 5/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7618 - loss: 0.7264\n",
      "Epoch 6/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7798 - loss: 0.6771\n",
      "Epoch 7/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7840 - loss: 0.6559\n",
      "Epoch 8/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7969 - loss: 0.6216\n",
      "Epoch 9/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.6166\n",
      "Epoch 10/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8032 - loss: 0.5936\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5001 - loss: 1.5196\n",
      "Epoch 2/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6279 - loss: 1.0086\n",
      "Epoch 3/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6830 - loss: 0.8885\n",
      "Epoch 4/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.7900\n",
      "Epoch 5/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7540 - loss: 0.7216\n",
      "Epoch 6/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7716 - loss: 0.6857\n",
      "Epoch 7/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7876 - loss: 0.6423\n",
      "Epoch 8/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.6158\n",
      "Epoch 9/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7993 - loss: 0.5920\n",
      "Epoch 10/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.5773\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4621 - loss: 1.5718\n",
      "Epoch 2/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6383 - loss: 1.0146\n",
      "Epoch 3/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6849 - loss: 0.8966\n",
      "Epoch 4/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7248 - loss: 0.7899\n",
      "Epoch 5/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7496 - loss: 0.7265\n",
      "Epoch 6/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7712 - loss: 0.6855\n",
      "Epoch 7/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7831 - loss: 0.6488\n",
      "Epoch 8/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7955 - loss: 0.6185\n",
      "Epoch 9/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7979 - loss: 0.6073\n",
      "Epoch 10/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 0.5826\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4902 - loss: 1.5519\n",
      "Epoch 2/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6353 - loss: 1.0118\n",
      "Epoch 3/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6789 - loss: 0.8826\n",
      "Epoch 4/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7249 - loss: 0.7956\n",
      "Epoch 5/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7601 - loss: 0.7255\n",
      "Epoch 6/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7695 - loss: 0.6915\n",
      "Epoch 7/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7815 - loss: 0.6559\n",
      "Epoch 8/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7824 - loss: 0.6400\n",
      "Epoch 9/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7909 - loss: 0.6290\n",
      "Epoch 10/10\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.6256\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "******************************\n",
      "******************************\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "******************************\n",
      "GMM Completed :)  \n",
      "******************************\n",
      "Bernoulli Naive Bayes with k-fold Cross-Validation Completed :)  \n",
      "******************************\n",
      "Learning rate set to 0.09175\n",
      "0:\tlearn: 1.8227740\ttotal: 253ms\tremaining: 4m 12s\n",
      "1:\tlearn: 1.6297497\ttotal: 298ms\tremaining: 2m 28s\n",
      "2:\tlearn: 1.4635271\ttotal: 336ms\tremaining: 1m 51s\n",
      "3:\tlearn: 1.3585667\ttotal: 374ms\tremaining: 1m 33s\n",
      "4:\tlearn: 1.2606501\ttotal: 412ms\tremaining: 1m 21s\n",
      "5:\tlearn: 1.1698414\ttotal: 451ms\tremaining: 1m 14s\n",
      "6:\tlearn: 1.1113175\ttotal: 497ms\tremaining: 1m 10s\n",
      "7:\tlearn: 1.0477034\ttotal: 545ms\tremaining: 1m 7s\n",
      "8:\tlearn: 0.9884096\ttotal: 594ms\tremaining: 1m 5s\n",
      "9:\tlearn: 0.9478228\ttotal: 641ms\tremaining: 1m 3s\n",
      "10:\tlearn: 0.9039452\ttotal: 690ms\tremaining: 1m 2s\n",
      "11:\tlearn: 0.8657955\ttotal: 742ms\tremaining: 1m 1s\n",
      "12:\tlearn: 0.8337047\ttotal: 795ms\tremaining: 1m\n",
      "13:\tlearn: 0.8037984\ttotal: 846ms\tremaining: 59.5s\n",
      "14:\tlearn: 0.7769945\ttotal: 895ms\tremaining: 58.8s\n",
      "15:\tlearn: 0.7547285\ttotal: 930ms\tremaining: 57.2s\n",
      "16:\tlearn: 0.7350999\ttotal: 969ms\tremaining: 56.1s\n",
      "17:\tlearn: 0.7135575\ttotal: 1s\tremaining: 54.8s\n",
      "18:\tlearn: 0.6967095\ttotal: 1.04s\tremaining: 53.6s\n",
      "19:\tlearn: 0.6769263\ttotal: 1.07s\tremaining: 52.5s\n",
      "20:\tlearn: 0.6581660\ttotal: 1.11s\tremaining: 51.6s\n",
      "21:\tlearn: 0.6431314\ttotal: 1.14s\tremaining: 50.6s\n",
      "22:\tlearn: 0.6324863\ttotal: 1.17s\tremaining: 49.6s\n",
      "23:\tlearn: 0.6210254\ttotal: 1.2s\tremaining: 48.9s\n",
      "24:\tlearn: 0.6087053\ttotal: 1.23s\tremaining: 48.1s\n",
      "25:\tlearn: 0.5933198\ttotal: 1.26s\tremaining: 47.4s\n",
      "26:\tlearn: 0.5827614\ttotal: 1.29s\tremaining: 46.7s\n",
      "27:\tlearn: 0.5720974\ttotal: 1.33s\tremaining: 46.1s\n",
      "28:\tlearn: 0.5628378\ttotal: 1.36s\tremaining: 45.4s\n",
      "29:\tlearn: 0.5529689\ttotal: 1.39s\tremaining: 44.9s\n",
      "30:\tlearn: 0.5457975\ttotal: 1.42s\tremaining: 44.4s\n",
      "31:\tlearn: 0.5363774\ttotal: 1.45s\tremaining: 44s\n",
      "32:\tlearn: 0.5274770\ttotal: 1.49s\tremaining: 43.5s\n",
      "33:\tlearn: 0.5207401\ttotal: 1.51s\tremaining: 43.1s\n",
      "34:\tlearn: 0.5107875\ttotal: 1.55s\tremaining: 42.7s\n",
      "35:\tlearn: 0.5043876\ttotal: 1.58s\tremaining: 42.3s\n",
      "36:\tlearn: 0.4981845\ttotal: 1.61s\tremaining: 41.8s\n",
      "37:\tlearn: 0.4908762\ttotal: 1.64s\tremaining: 41.5s\n",
      "38:\tlearn: 0.4854186\ttotal: 1.68s\tremaining: 41.5s\n",
      "39:\tlearn: 0.4803350\ttotal: 1.73s\tremaining: 41.5s\n",
      "40:\tlearn: 0.4748663\ttotal: 1.77s\tremaining: 41.3s\n",
      "41:\tlearn: 0.4690068\ttotal: 1.8s\tremaining: 41s\n",
      "42:\tlearn: 0.4641859\ttotal: 1.82s\tremaining: 40.6s\n",
      "43:\tlearn: 0.4617255\ttotal: 1.85s\tremaining: 40.3s\n",
      "44:\tlearn: 0.4567308\ttotal: 1.89s\tremaining: 40.1s\n",
      "45:\tlearn: 0.4507528\ttotal: 1.92s\tremaining: 39.9s\n",
      "46:\tlearn: 0.4463708\ttotal: 1.95s\tremaining: 39.6s\n",
      "47:\tlearn: 0.4421784\ttotal: 1.98s\tremaining: 39.4s\n",
      "48:\tlearn: 0.4390296\ttotal: 2.01s\tremaining: 39.1s\n",
      "49:\tlearn: 0.4377471\ttotal: 2.04s\tremaining: 38.8s\n",
      "50:\tlearn: 0.4348904\ttotal: 2.07s\tremaining: 38.6s\n",
      "51:\tlearn: 0.4309840\ttotal: 2.11s\tremaining: 38.5s\n",
      "52:\tlearn: 0.4266542\ttotal: 2.15s\tremaining: 38.4s\n",
      "53:\tlearn: 0.4228808\ttotal: 2.18s\tremaining: 38.2s\n",
      "54:\tlearn: 0.4211756\ttotal: 2.21s\tremaining: 37.9s\n",
      "55:\tlearn: 0.4178734\ttotal: 2.24s\tremaining: 37.7s\n",
      "56:\tlearn: 0.4152648\ttotal: 2.27s\tremaining: 37.5s\n",
      "57:\tlearn: 0.4128086\ttotal: 2.3s\tremaining: 37.3s\n",
      "58:\tlearn: 0.4092485\ttotal: 2.33s\tremaining: 37.2s\n",
      "59:\tlearn: 0.4073532\ttotal: 2.37s\tremaining: 37.1s\n",
      "60:\tlearn: 0.4056100\ttotal: 2.4s\tremaining: 37s\n",
      "61:\tlearn: 0.4028496\ttotal: 2.43s\tremaining: 36.8s\n",
      "62:\tlearn: 0.3999466\ttotal: 2.47s\tremaining: 36.7s\n",
      "63:\tlearn: 0.3985204\ttotal: 2.5s\tremaining: 36.5s\n",
      "64:\tlearn: 0.3970538\ttotal: 2.52s\tremaining: 36.3s\n",
      "65:\tlearn: 0.3949407\ttotal: 2.58s\tremaining: 36.4s\n",
      "66:\tlearn: 0.3911091\ttotal: 2.62s\tremaining: 36.5s\n",
      "67:\tlearn: 0.3890757\ttotal: 2.65s\tremaining: 36.3s\n",
      "68:\tlearn: 0.3869123\ttotal: 2.68s\tremaining: 36.2s\n",
      "69:\tlearn: 0.3848498\ttotal: 2.71s\tremaining: 36.1s\n",
      "70:\tlearn: 0.3816574\ttotal: 2.75s\tremaining: 35.9s\n",
      "71:\tlearn: 0.3801421\ttotal: 2.79s\tremaining: 35.9s\n",
      "72:\tlearn: 0.3780035\ttotal: 2.82s\tremaining: 35.8s\n",
      "73:\tlearn: 0.3765208\ttotal: 2.85s\tremaining: 35.6s\n",
      "74:\tlearn: 0.3750186\ttotal: 2.88s\tremaining: 35.5s\n",
      "75:\tlearn: 0.3738351\ttotal: 2.91s\tremaining: 35.3s\n",
      "76:\tlearn: 0.3717656\ttotal: 2.94s\tremaining: 35.2s\n",
      "77:\tlearn: 0.3699944\ttotal: 2.97s\tremaining: 35.1s\n",
      "78:\tlearn: 0.3686607\ttotal: 3s\tremaining: 35s\n",
      "79:\tlearn: 0.3660868\ttotal: 3.03s\tremaining: 34.9s\n",
      "80:\tlearn: 0.3648810\ttotal: 3.06s\tremaining: 34.7s\n",
      "81:\tlearn: 0.3638468\ttotal: 3.09s\tremaining: 34.6s\n",
      "82:\tlearn: 0.3624970\ttotal: 3.12s\tremaining: 34.5s\n",
      "83:\tlearn: 0.3614167\ttotal: 3.15s\tremaining: 34.4s\n",
      "84:\tlearn: 0.3600895\ttotal: 3.19s\tremaining: 34.3s\n",
      "85:\tlearn: 0.3592081\ttotal: 3.22s\tremaining: 34.2s\n",
      "86:\tlearn: 0.3575395\ttotal: 3.25s\tremaining: 34.1s\n",
      "87:\tlearn: 0.3562852\ttotal: 3.28s\tremaining: 34s\n",
      "88:\tlearn: 0.3553916\ttotal: 3.31s\tremaining: 33.8s\n",
      "89:\tlearn: 0.3533857\ttotal: 3.34s\tremaining: 33.8s\n",
      "90:\tlearn: 0.3523484\ttotal: 3.37s\tremaining: 33.6s\n",
      "91:\tlearn: 0.3504842\ttotal: 3.4s\tremaining: 33.6s\n",
      "92:\tlearn: 0.3493045\ttotal: 3.44s\tremaining: 33.6s\n",
      "93:\tlearn: 0.3485025\ttotal: 3.48s\tremaining: 33.6s\n",
      "94:\tlearn: 0.3473273\ttotal: 3.52s\tremaining: 33.5s\n",
      "95:\tlearn: 0.3458431\ttotal: 3.55s\tremaining: 33.5s\n",
      "96:\tlearn: 0.3440714\ttotal: 3.59s\tremaining: 33.4s\n",
      "97:\tlearn: 0.3426783\ttotal: 3.62s\tremaining: 33.3s\n",
      "98:\tlearn: 0.3418692\ttotal: 3.65s\tremaining: 33.2s\n",
      "99:\tlearn: 0.3407086\ttotal: 3.69s\tremaining: 33.2s\n",
      "100:\tlearn: 0.3395131\ttotal: 3.72s\tremaining: 33.1s\n",
      "101:\tlearn: 0.3384846\ttotal: 3.75s\tremaining: 33s\n",
      "102:\tlearn: 0.3376351\ttotal: 3.78s\tremaining: 32.9s\n",
      "103:\tlearn: 0.3372604\ttotal: 3.81s\tremaining: 32.8s\n",
      "104:\tlearn: 0.3367865\ttotal: 3.84s\tremaining: 32.7s\n",
      "105:\tlearn: 0.3356881\ttotal: 3.87s\tremaining: 32.6s\n",
      "106:\tlearn: 0.3350644\ttotal: 3.9s\tremaining: 32.5s\n",
      "107:\tlearn: 0.3342979\ttotal: 3.93s\tremaining: 32.5s\n",
      "108:\tlearn: 0.3333428\ttotal: 3.96s\tremaining: 32.4s\n",
      "109:\tlearn: 0.3327858\ttotal: 3.99s\tremaining: 32.3s\n",
      "110:\tlearn: 0.3320964\ttotal: 4.02s\tremaining: 32.2s\n",
      "111:\tlearn: 0.3312882\ttotal: 4.05s\tremaining: 32.1s\n",
      "112:\tlearn: 0.3307215\ttotal: 4.08s\tremaining: 32s\n",
      "113:\tlearn: 0.3300447\ttotal: 4.11s\tremaining: 32s\n",
      "114:\tlearn: 0.3290096\ttotal: 4.16s\tremaining: 32s\n",
      "115:\tlearn: 0.3280786\ttotal: 4.2s\tremaining: 32s\n",
      "116:\tlearn: 0.3267990\ttotal: 4.23s\tremaining: 31.9s\n",
      "117:\tlearn: 0.3260604\ttotal: 4.26s\tremaining: 31.9s\n",
      "118:\tlearn: 0.3246007\ttotal: 4.3s\tremaining: 31.8s\n",
      "119:\tlearn: 0.3238675\ttotal: 4.33s\tremaining: 31.8s\n",
      "120:\tlearn: 0.3226226\ttotal: 4.37s\tremaining: 31.7s\n",
      "121:\tlearn: 0.3209145\ttotal: 4.4s\tremaining: 31.6s\n",
      "122:\tlearn: 0.3200139\ttotal: 4.43s\tremaining: 31.6s\n",
      "123:\tlearn: 0.3191098\ttotal: 4.46s\tremaining: 31.5s\n",
      "124:\tlearn: 0.3183911\ttotal: 4.49s\tremaining: 31.4s\n",
      "125:\tlearn: 0.3175999\ttotal: 4.52s\tremaining: 31.3s\n",
      "126:\tlearn: 0.3173075\ttotal: 4.55s\tremaining: 31.3s\n",
      "127:\tlearn: 0.3168478\ttotal: 4.58s\tremaining: 31.2s\n",
      "128:\tlearn: 0.3164819\ttotal: 4.61s\tremaining: 31.1s\n",
      "129:\tlearn: 0.3153001\ttotal: 4.67s\tremaining: 31.2s\n",
      "130:\tlearn: 0.3146515\ttotal: 4.72s\tremaining: 31.3s\n",
      "131:\tlearn: 0.3142371\ttotal: 4.77s\tremaining: 31.4s\n",
      "132:\tlearn: 0.3131274\ttotal: 4.81s\tremaining: 31.4s\n",
      "133:\tlearn: 0.3124601\ttotal: 4.85s\tremaining: 31.4s\n",
      "134:\tlearn: 0.3114505\ttotal: 4.89s\tremaining: 31.4s\n",
      "135:\tlearn: 0.3109449\ttotal: 4.92s\tremaining: 31.3s\n",
      "136:\tlearn: 0.3105896\ttotal: 4.95s\tremaining: 31.2s\n",
      "137:\tlearn: 0.3094709\ttotal: 4.99s\tremaining: 31.2s\n",
      "138:\tlearn: 0.3085900\ttotal: 5.03s\tremaining: 31.1s\n",
      "139:\tlearn: 0.3078804\ttotal: 5.05s\tremaining: 31s\n",
      "140:\tlearn: 0.3070896\ttotal: 5.08s\tremaining: 31s\n",
      "141:\tlearn: 0.3057643\ttotal: 5.11s\tremaining: 30.9s\n",
      "142:\tlearn: 0.3051011\ttotal: 5.14s\tremaining: 30.8s\n",
      "143:\tlearn: 0.3048488\ttotal: 5.17s\tremaining: 30.7s\n",
      "144:\tlearn: 0.3041544\ttotal: 5.21s\tremaining: 30.7s\n",
      "145:\tlearn: 0.3038526\ttotal: 5.24s\tremaining: 30.6s\n",
      "146:\tlearn: 0.3023071\ttotal: 5.27s\tremaining: 30.6s\n",
      "147:\tlearn: 0.3017918\ttotal: 5.29s\tremaining: 30.5s\n",
      "148:\tlearn: 0.3013795\ttotal: 5.33s\tremaining: 30.4s\n",
      "149:\tlearn: 0.3009746\ttotal: 5.35s\tremaining: 30.3s\n",
      "150:\tlearn: 0.3004776\ttotal: 5.38s\tremaining: 30.3s\n",
      "151:\tlearn: 0.3001002\ttotal: 5.42s\tremaining: 30.2s\n",
      "152:\tlearn: 0.2994904\ttotal: 5.46s\tremaining: 30.2s\n",
      "153:\tlearn: 0.2992091\ttotal: 5.5s\tremaining: 30.2s\n",
      "154:\tlearn: 0.2987030\ttotal: 5.54s\tremaining: 30.2s\n",
      "155:\tlearn: 0.2978159\ttotal: 5.57s\tremaining: 30.1s\n",
      "156:\tlearn: 0.2976309\ttotal: 5.6s\tremaining: 30.1s\n",
      "157:\tlearn: 0.2969792\ttotal: 5.63s\tremaining: 30s\n",
      "158:\tlearn: 0.2959053\ttotal: 5.67s\tremaining: 30s\n",
      "159:\tlearn: 0.2952169\ttotal: 5.7s\tremaining: 29.9s\n",
      "160:\tlearn: 0.2943268\ttotal: 5.73s\tremaining: 29.9s\n",
      "161:\tlearn: 0.2937615\ttotal: 5.76s\tremaining: 29.8s\n",
      "162:\tlearn: 0.2927982\ttotal: 5.79s\tremaining: 29.7s\n",
      "163:\tlearn: 0.2924339\ttotal: 5.82s\tremaining: 29.7s\n",
      "164:\tlearn: 0.2917618\ttotal: 5.85s\tremaining: 29.6s\n",
      "165:\tlearn: 0.2915167\ttotal: 5.88s\tremaining: 29.6s\n",
      "166:\tlearn: 0.2910963\ttotal: 5.91s\tremaining: 29.5s\n",
      "167:\tlearn: 0.2905791\ttotal: 5.94s\tremaining: 29.4s\n",
      "168:\tlearn: 0.2900674\ttotal: 5.97s\tremaining: 29.4s\n",
      "169:\tlearn: 0.2896661\ttotal: 6s\tremaining: 29.3s\n",
      "170:\tlearn: 0.2894351\ttotal: 6.03s\tremaining: 29.3s\n",
      "171:\tlearn: 0.2886670\ttotal: 6.07s\tremaining: 29.2s\n",
      "172:\tlearn: 0.2882663\ttotal: 6.1s\tremaining: 29.2s\n",
      "173:\tlearn: 0.2877793\ttotal: 6.15s\tremaining: 29.2s\n",
      "174:\tlearn: 0.2873957\ttotal: 6.18s\tremaining: 29.2s\n",
      "175:\tlearn: 0.2861112\ttotal: 6.22s\tremaining: 29.1s\n",
      "176:\tlearn: 0.2857316\ttotal: 6.25s\tremaining: 29s\n",
      "177:\tlearn: 0.2851881\ttotal: 6.28s\tremaining: 29s\n",
      "178:\tlearn: 0.2846139\ttotal: 6.32s\tremaining: 29s\n",
      "179:\tlearn: 0.2839768\ttotal: 6.35s\tremaining: 28.9s\n",
      "180:\tlearn: 0.2835160\ttotal: 6.38s\tremaining: 28.9s\n",
      "181:\tlearn: 0.2831648\ttotal: 6.41s\tremaining: 28.8s\n",
      "182:\tlearn: 0.2824919\ttotal: 6.44s\tremaining: 28.8s\n",
      "183:\tlearn: 0.2822054\ttotal: 6.47s\tremaining: 28.7s\n",
      "184:\tlearn: 0.2814596\ttotal: 6.5s\tremaining: 28.6s\n",
      "185:\tlearn: 0.2812590\ttotal: 6.54s\tremaining: 28.6s\n",
      "186:\tlearn: 0.2808888\ttotal: 6.57s\tremaining: 28.6s\n",
      "187:\tlearn: 0.2803045\ttotal: 6.6s\tremaining: 28.5s\n",
      "188:\tlearn: 0.2800277\ttotal: 6.63s\tremaining: 28.4s\n",
      "189:\tlearn: 0.2794340\ttotal: 6.66s\tremaining: 28.4s\n",
      "190:\tlearn: 0.2786343\ttotal: 6.69s\tremaining: 28.3s\n",
      "191:\tlearn: 0.2781407\ttotal: 6.72s\tremaining: 28.3s\n",
      "192:\tlearn: 0.2778578\ttotal: 6.75s\tremaining: 28.2s\n",
      "193:\tlearn: 0.2776750\ttotal: 6.79s\tremaining: 28.2s\n",
      "194:\tlearn: 0.2772923\ttotal: 6.83s\tremaining: 28.2s\n",
      "195:\tlearn: 0.2770211\ttotal: 6.87s\tremaining: 28.2s\n",
      "196:\tlearn: 0.2767792\ttotal: 6.9s\tremaining: 28.1s\n",
      "197:\tlearn: 0.2763136\ttotal: 6.93s\tremaining: 28.1s\n",
      "198:\tlearn: 0.2753400\ttotal: 6.96s\tremaining: 28s\n",
      "199:\tlearn: 0.2745294\ttotal: 7s\tremaining: 28s\n",
      "200:\tlearn: 0.2739656\ttotal: 7.03s\tremaining: 28s\n",
      "201:\tlearn: 0.2736695\ttotal: 7.06s\tremaining: 27.9s\n",
      "202:\tlearn: 0.2731831\ttotal: 7.09s\tremaining: 27.8s\n",
      "203:\tlearn: 0.2727155\ttotal: 7.12s\tremaining: 27.8s\n",
      "204:\tlearn: 0.2724748\ttotal: 7.15s\tremaining: 27.7s\n",
      "205:\tlearn: 0.2717422\ttotal: 7.19s\tremaining: 27.7s\n",
      "206:\tlearn: 0.2713359\ttotal: 7.23s\tremaining: 27.7s\n",
      "207:\tlearn: 0.2709783\ttotal: 7.25s\tremaining: 27.6s\n",
      "208:\tlearn: 0.2705729\ttotal: 7.28s\tremaining: 27.6s\n",
      "209:\tlearn: 0.2703175\ttotal: 7.31s\tremaining: 27.5s\n",
      "210:\tlearn: 0.2695453\ttotal: 7.34s\tremaining: 27.5s\n",
      "211:\tlearn: 0.2692861\ttotal: 7.38s\tremaining: 27.4s\n",
      "212:\tlearn: 0.2689031\ttotal: 7.42s\tremaining: 27.4s\n",
      "213:\tlearn: 0.2685583\ttotal: 7.46s\tremaining: 27.4s\n",
      "214:\tlearn: 0.2681283\ttotal: 7.5s\tremaining: 27.4s\n",
      "215:\tlearn: 0.2677415\ttotal: 7.53s\tremaining: 27.3s\n",
      "216:\tlearn: 0.2674398\ttotal: 7.56s\tremaining: 27.3s\n",
      "217:\tlearn: 0.2672654\ttotal: 7.59s\tremaining: 27.2s\n",
      "218:\tlearn: 0.2670641\ttotal: 7.62s\tremaining: 27.2s\n",
      "219:\tlearn: 0.2664752\ttotal: 7.66s\tremaining: 27.2s\n",
      "220:\tlearn: 0.2657954\ttotal: 7.7s\tremaining: 27.1s\n",
      "221:\tlearn: 0.2654285\ttotal: 7.73s\tremaining: 27.1s\n",
      "222:\tlearn: 0.2653172\ttotal: 7.75s\tremaining: 27s\n",
      "223:\tlearn: 0.2648370\ttotal: 7.78s\tremaining: 27s\n",
      "224:\tlearn: 0.2645697\ttotal: 7.81s\tremaining: 26.9s\n",
      "225:\tlearn: 0.2640422\ttotal: 7.85s\tremaining: 26.9s\n",
      "226:\tlearn: 0.2635251\ttotal: 7.88s\tremaining: 26.8s\n",
      "227:\tlearn: 0.2630787\ttotal: 7.91s\tremaining: 26.8s\n",
      "228:\tlearn: 0.2627786\ttotal: 7.94s\tremaining: 26.7s\n",
      "229:\tlearn: 0.2624294\ttotal: 7.97s\tremaining: 26.7s\n",
      "230:\tlearn: 0.2617290\ttotal: 8s\tremaining: 26.6s\n",
      "231:\tlearn: 0.2611104\ttotal: 8.03s\tremaining: 26.6s\n",
      "232:\tlearn: 0.2608871\ttotal: 8.06s\tremaining: 26.5s\n",
      "233:\tlearn: 0.2607419\ttotal: 8.09s\tremaining: 26.5s\n",
      "234:\tlearn: 0.2606386\ttotal: 8.13s\tremaining: 26.5s\n",
      "235:\tlearn: 0.2604837\ttotal: 8.17s\tremaining: 26.5s\n",
      "236:\tlearn: 0.2599822\ttotal: 8.21s\tremaining: 26.4s\n",
      "237:\tlearn: 0.2595677\ttotal: 8.24s\tremaining: 26.4s\n",
      "238:\tlearn: 0.2588865\ttotal: 8.28s\tremaining: 26.4s\n",
      "239:\tlearn: 0.2586879\ttotal: 8.31s\tremaining: 26.3s\n",
      "240:\tlearn: 0.2582161\ttotal: 8.35s\tremaining: 26.3s\n",
      "241:\tlearn: 0.2578725\ttotal: 8.38s\tremaining: 26.2s\n",
      "242:\tlearn: 0.2574081\ttotal: 8.4s\tremaining: 26.2s\n",
      "243:\tlearn: 0.2569464\ttotal: 8.44s\tremaining: 26.1s\n",
      "244:\tlearn: 0.2562918\ttotal: 8.47s\tremaining: 26.1s\n",
      "245:\tlearn: 0.2557806\ttotal: 8.5s\tremaining: 26.1s\n",
      "246:\tlearn: 0.2553905\ttotal: 8.54s\tremaining: 26s\n",
      "247:\tlearn: 0.2552100\ttotal: 8.57s\tremaining: 26s\n",
      "248:\tlearn: 0.2547267\ttotal: 8.6s\tremaining: 25.9s\n",
      "249:\tlearn: 0.2545671\ttotal: 8.63s\tremaining: 25.9s\n",
      "250:\tlearn: 0.2543082\ttotal: 8.66s\tremaining: 25.8s\n",
      "251:\tlearn: 0.2537127\ttotal: 8.69s\tremaining: 25.8s\n",
      "252:\tlearn: 0.2535814\ttotal: 8.71s\tremaining: 25.7s\n",
      "253:\tlearn: 0.2531522\ttotal: 8.76s\tremaining: 25.7s\n",
      "254:\tlearn: 0.2528492\ttotal: 8.8s\tremaining: 25.7s\n",
      "255:\tlearn: 0.2526848\ttotal: 8.84s\tremaining: 25.7s\n",
      "256:\tlearn: 0.2522695\ttotal: 8.87s\tremaining: 25.6s\n",
      "257:\tlearn: 0.2520156\ttotal: 8.9s\tremaining: 25.6s\n",
      "258:\tlearn: 0.2518263\ttotal: 8.93s\tremaining: 25.5s\n",
      "259:\tlearn: 0.2511431\ttotal: 8.96s\tremaining: 25.5s\n",
      "260:\tlearn: 0.2506400\ttotal: 9s\tremaining: 25.5s\n",
      "261:\tlearn: 0.2504784\ttotal: 9.03s\tremaining: 25.4s\n",
      "262:\tlearn: 0.2500289\ttotal: 9.06s\tremaining: 25.4s\n",
      "263:\tlearn: 0.2494934\ttotal: 9.09s\tremaining: 25.4s\n",
      "264:\tlearn: 0.2493292\ttotal: 9.12s\tremaining: 25.3s\n",
      "265:\tlearn: 0.2486560\ttotal: 9.15s\tremaining: 25.3s\n",
      "266:\tlearn: 0.2484786\ttotal: 9.19s\tremaining: 25.2s\n",
      "267:\tlearn: 0.2483463\ttotal: 9.22s\tremaining: 25.2s\n",
      "268:\tlearn: 0.2481248\ttotal: 9.25s\tremaining: 25.1s\n",
      "269:\tlearn: 0.2477732\ttotal: 9.28s\tremaining: 25.1s\n",
      "270:\tlearn: 0.2473368\ttotal: 9.31s\tremaining: 25.1s\n",
      "271:\tlearn: 0.2470627\ttotal: 9.34s\tremaining: 25s\n",
      "272:\tlearn: 0.2469582\ttotal: 9.37s\tremaining: 25s\n",
      "273:\tlearn: 0.2467178\ttotal: 9.4s\tremaining: 24.9s\n",
      "274:\tlearn: 0.2464055\ttotal: 9.44s\tremaining: 24.9s\n",
      "275:\tlearn: 0.2462027\ttotal: 9.48s\tremaining: 24.9s\n",
      "276:\tlearn: 0.2458870\ttotal: 9.52s\tremaining: 24.9s\n",
      "277:\tlearn: 0.2457210\ttotal: 9.56s\tremaining: 24.8s\n",
      "278:\tlearn: 0.2454449\ttotal: 9.59s\tremaining: 24.8s\n",
      "279:\tlearn: 0.2453220\ttotal: 9.62s\tremaining: 24.7s\n",
      "280:\tlearn: 0.2451740\ttotal: 9.65s\tremaining: 24.7s\n",
      "281:\tlearn: 0.2450175\ttotal: 9.69s\tremaining: 24.7s\n",
      "282:\tlearn: 0.2449044\ttotal: 9.72s\tremaining: 24.6s\n",
      "283:\tlearn: 0.2444074\ttotal: 9.75s\tremaining: 24.6s\n",
      "284:\tlearn: 0.2442048\ttotal: 9.78s\tremaining: 24.5s\n",
      "285:\tlearn: 0.2441282\ttotal: 9.81s\tremaining: 24.5s\n",
      "286:\tlearn: 0.2436277\ttotal: 9.84s\tremaining: 24.4s\n",
      "287:\tlearn: 0.2432231\ttotal: 9.88s\tremaining: 24.4s\n",
      "288:\tlearn: 0.2429137\ttotal: 9.91s\tremaining: 24.4s\n",
      "289:\tlearn: 0.2422610\ttotal: 9.94s\tremaining: 24.3s\n",
      "290:\tlearn: 0.2417866\ttotal: 9.97s\tremaining: 24.3s\n",
      "291:\tlearn: 0.2416233\ttotal: 10s\tremaining: 24.2s\n",
      "292:\tlearn: 0.2412738\ttotal: 10s\tremaining: 24.2s\n",
      "293:\tlearn: 0.2411681\ttotal: 10.1s\tremaining: 24.1s\n",
      "294:\tlearn: 0.2409922\ttotal: 10.1s\tremaining: 24.1s\n",
      "295:\tlearn: 0.2405975\ttotal: 10.1s\tremaining: 24.1s\n",
      "296:\tlearn: 0.2403706\ttotal: 10.2s\tremaining: 24.1s\n",
      "297:\tlearn: 0.2401581\ttotal: 10.2s\tremaining: 24.1s\n",
      "298:\tlearn: 0.2395530\ttotal: 10.2s\tremaining: 24s\n",
      "299:\tlearn: 0.2389819\ttotal: 10.3s\tremaining: 24s\n",
      "300:\tlearn: 0.2385800\ttotal: 10.3s\tremaining: 23.9s\n",
      "301:\tlearn: 0.2383452\ttotal: 10.3s\tremaining: 23.9s\n",
      "302:\tlearn: 0.2381088\ttotal: 10.4s\tremaining: 23.9s\n",
      "303:\tlearn: 0.2378256\ttotal: 10.4s\tremaining: 23.8s\n",
      "304:\tlearn: 0.2376051\ttotal: 10.4s\tremaining: 23.8s\n",
      "305:\tlearn: 0.2374292\ttotal: 10.5s\tremaining: 23.7s\n",
      "306:\tlearn: 0.2371157\ttotal: 10.5s\tremaining: 23.7s\n",
      "307:\tlearn: 0.2368504\ttotal: 10.5s\tremaining: 23.7s\n",
      "308:\tlearn: 0.2365829\ttotal: 10.6s\tremaining: 23.6s\n",
      "309:\tlearn: 0.2360940\ttotal: 10.6s\tremaining: 23.6s\n",
      "310:\tlearn: 0.2358004\ttotal: 10.7s\tremaining: 23.6s\n",
      "311:\tlearn: 0.2355740\ttotal: 10.7s\tremaining: 23.6s\n",
      "312:\tlearn: 0.2350927\ttotal: 10.7s\tremaining: 23.5s\n",
      "313:\tlearn: 0.2345956\ttotal: 10.8s\tremaining: 23.5s\n",
      "314:\tlearn: 0.2342215\ttotal: 10.8s\tremaining: 23.5s\n",
      "315:\tlearn: 0.2341017\ttotal: 10.8s\tremaining: 23.4s\n",
      "316:\tlearn: 0.2337398\ttotal: 10.9s\tremaining: 23.4s\n",
      "317:\tlearn: 0.2335143\ttotal: 10.9s\tremaining: 23.4s\n",
      "318:\tlearn: 0.2332546\ttotal: 10.9s\tremaining: 23.3s\n",
      "319:\tlearn: 0.2328031\ttotal: 11s\tremaining: 23.3s\n",
      "320:\tlearn: 0.2327218\ttotal: 11s\tremaining: 23.2s\n",
      "321:\tlearn: 0.2325583\ttotal: 11s\tremaining: 23.2s\n",
      "322:\tlearn: 0.2323363\ttotal: 11.1s\tremaining: 23.2s\n",
      "323:\tlearn: 0.2320150\ttotal: 11.1s\tremaining: 23.2s\n",
      "324:\tlearn: 0.2318318\ttotal: 11.1s\tremaining: 23.1s\n",
      "325:\tlearn: 0.2316412\ttotal: 11.2s\tremaining: 23.1s\n",
      "326:\tlearn: 0.2313193\ttotal: 11.2s\tremaining: 23.1s\n",
      "327:\tlearn: 0.2310213\ttotal: 11.2s\tremaining: 23s\n",
      "328:\tlearn: 0.2308167\ttotal: 11.3s\tremaining: 23s\n",
      "329:\tlearn: 0.2306397\ttotal: 11.3s\tremaining: 23s\n",
      "330:\tlearn: 0.2305550\ttotal: 11.3s\tremaining: 22.9s\n",
      "331:\tlearn: 0.2304183\ttotal: 11.4s\tremaining: 22.9s\n",
      "332:\tlearn: 0.2301041\ttotal: 11.4s\tremaining: 22.8s\n",
      "333:\tlearn: 0.2296058\ttotal: 11.4s\tremaining: 22.8s\n",
      "334:\tlearn: 0.2294053\ttotal: 11.5s\tremaining: 22.8s\n",
      "335:\tlearn: 0.2291356\ttotal: 11.5s\tremaining: 22.7s\n",
      "336:\tlearn: 0.2287042\ttotal: 11.5s\tremaining: 22.7s\n",
      "337:\tlearn: 0.2283178\ttotal: 11.6s\tremaining: 22.7s\n",
      "338:\tlearn: 0.2281088\ttotal: 11.6s\tremaining: 22.7s\n",
      "339:\tlearn: 0.2278858\ttotal: 11.7s\tremaining: 22.6s\n",
      "340:\tlearn: 0.2277524\ttotal: 11.7s\tremaining: 22.6s\n",
      "341:\tlearn: 0.2276172\ttotal: 11.7s\tremaining: 22.5s\n",
      "342:\tlearn: 0.2271219\ttotal: 11.7s\tremaining: 22.5s\n",
      "343:\tlearn: 0.2269414\ttotal: 11.8s\tremaining: 22.4s\n",
      "344:\tlearn: 0.2264648\ttotal: 11.8s\tremaining: 22.4s\n",
      "345:\tlearn: 0.2261637\ttotal: 11.8s\tremaining: 22.4s\n",
      "346:\tlearn: 0.2259091\ttotal: 11.9s\tremaining: 22.3s\n",
      "347:\tlearn: 0.2258048\ttotal: 11.9s\tremaining: 22.3s\n",
      "348:\tlearn: 0.2254708\ttotal: 11.9s\tremaining: 22.2s\n",
      "349:\tlearn: 0.2253426\ttotal: 11.9s\tremaining: 22.2s\n",
      "350:\tlearn: 0.2251434\ttotal: 12s\tremaining: 22.2s\n",
      "351:\tlearn: 0.2248152\ttotal: 12s\tremaining: 22.1s\n",
      "352:\tlearn: 0.2246247\ttotal: 12s\tremaining: 22.1s\n",
      "353:\tlearn: 0.2243683\ttotal: 12.1s\tremaining: 22s\n",
      "354:\tlearn: 0.2235950\ttotal: 12.1s\tremaining: 22s\n",
      "355:\tlearn: 0.2233566\ttotal: 12.2s\tremaining: 22s\n",
      "356:\tlearn: 0.2230072\ttotal: 12.2s\tremaining: 22s\n",
      "357:\tlearn: 0.2228494\ttotal: 12.2s\tremaining: 21.9s\n",
      "358:\tlearn: 0.2224804\ttotal: 12.3s\tremaining: 21.9s\n",
      "359:\tlearn: 0.2222007\ttotal: 12.3s\tremaining: 21.9s\n",
      "360:\tlearn: 0.2220593\ttotal: 12.3s\tremaining: 21.8s\n",
      "361:\tlearn: 0.2217989\ttotal: 12.4s\tremaining: 21.8s\n",
      "362:\tlearn: 0.2217122\ttotal: 12.4s\tremaining: 21.7s\n",
      "363:\tlearn: 0.2215908\ttotal: 12.4s\tremaining: 21.7s\n",
      "364:\tlearn: 0.2212101\ttotal: 12.5s\tremaining: 21.7s\n",
      "365:\tlearn: 0.2209267\ttotal: 12.5s\tremaining: 21.6s\n",
      "366:\tlearn: 0.2207491\ttotal: 12.5s\tremaining: 21.6s\n",
      "367:\tlearn: 0.2205851\ttotal: 12.6s\tremaining: 21.6s\n",
      "368:\tlearn: 0.2204517\ttotal: 12.6s\tremaining: 21.5s\n",
      "369:\tlearn: 0.2200522\ttotal: 12.6s\tremaining: 21.5s\n",
      "370:\tlearn: 0.2197495\ttotal: 12.7s\tremaining: 21.5s\n",
      "371:\tlearn: 0.2195049\ttotal: 12.7s\tremaining: 21.5s\n",
      "372:\tlearn: 0.2190814\ttotal: 12.7s\tremaining: 21.4s\n",
      "373:\tlearn: 0.2188828\ttotal: 12.8s\tremaining: 21.4s\n",
      "374:\tlearn: 0.2187725\ttotal: 12.8s\tremaining: 21.4s\n",
      "375:\tlearn: 0.2187046\ttotal: 12.8s\tremaining: 21.3s\n",
      "376:\tlearn: 0.2184328\ttotal: 12.9s\tremaining: 21.3s\n",
      "377:\tlearn: 0.2182063\ttotal: 12.9s\tremaining: 21.2s\n",
      "378:\tlearn: 0.2181045\ttotal: 12.9s\tremaining: 21.2s\n",
      "379:\tlearn: 0.2179313\ttotal: 13s\tremaining: 21.1s\n",
      "380:\tlearn: 0.2178218\ttotal: 13s\tremaining: 21.1s\n",
      "381:\tlearn: 0.2175881\ttotal: 13s\tremaining: 21.1s\n",
      "382:\tlearn: 0.2172142\ttotal: 13.1s\tremaining: 21.1s\n",
      "383:\tlearn: 0.2170078\ttotal: 13.1s\tremaining: 21.1s\n",
      "384:\tlearn: 0.2169106\ttotal: 13.2s\tremaining: 21s\n",
      "385:\tlearn: 0.2167648\ttotal: 13.2s\tremaining: 21s\n",
      "386:\tlearn: 0.2166052\ttotal: 13.2s\tremaining: 20.9s\n",
      "387:\tlearn: 0.2163352\ttotal: 13.3s\tremaining: 20.9s\n",
      "388:\tlearn: 0.2160346\ttotal: 13.3s\tremaining: 20.9s\n",
      "389:\tlearn: 0.2154991\ttotal: 13.3s\tremaining: 20.8s\n",
      "390:\tlearn: 0.2154300\ttotal: 13.3s\tremaining: 20.8s\n",
      "391:\tlearn: 0.2152214\ttotal: 13.4s\tremaining: 20.7s\n",
      "392:\tlearn: 0.2151567\ttotal: 13.4s\tremaining: 20.7s\n",
      "393:\tlearn: 0.2147069\ttotal: 13.4s\tremaining: 20.7s\n",
      "394:\tlearn: 0.2146107\ttotal: 13.5s\tremaining: 20.6s\n",
      "395:\tlearn: 0.2145234\ttotal: 13.5s\tremaining: 20.6s\n",
      "396:\tlearn: 0.2144156\ttotal: 13.6s\tremaining: 20.6s\n",
      "397:\tlearn: 0.2140532\ttotal: 13.6s\tremaining: 20.6s\n",
      "398:\tlearn: 0.2137893\ttotal: 13.6s\tremaining: 20.5s\n",
      "399:\tlearn: 0.2137093\ttotal: 13.7s\tremaining: 20.5s\n",
      "400:\tlearn: 0.2134600\ttotal: 13.7s\tremaining: 20.4s\n",
      "401:\tlearn: 0.2131859\ttotal: 13.7s\tremaining: 20.4s\n",
      "402:\tlearn: 0.2129794\ttotal: 13.8s\tremaining: 20.4s\n",
      "403:\tlearn: 0.2129042\ttotal: 13.8s\tremaining: 20.3s\n",
      "404:\tlearn: 0.2126929\ttotal: 13.8s\tremaining: 20.3s\n",
      "405:\tlearn: 0.2126090\ttotal: 13.8s\tremaining: 20.3s\n",
      "406:\tlearn: 0.2125313\ttotal: 13.9s\tremaining: 20.2s\n",
      "407:\tlearn: 0.2123736\ttotal: 13.9s\tremaining: 20.2s\n",
      "408:\tlearn: 0.2120542\ttotal: 14s\tremaining: 20.2s\n",
      "409:\tlearn: 0.2119806\ttotal: 14s\tremaining: 20.1s\n",
      "410:\tlearn: 0.2118712\ttotal: 14s\tremaining: 20.1s\n",
      "411:\tlearn: 0.2114636\ttotal: 14.1s\tremaining: 20.1s\n",
      "412:\tlearn: 0.2114018\ttotal: 14.1s\tremaining: 20s\n",
      "413:\tlearn: 0.2111369\ttotal: 14.1s\tremaining: 20s\n",
      "414:\tlearn: 0.2107986\ttotal: 14.2s\tremaining: 19.9s\n",
      "415:\tlearn: 0.2103569\ttotal: 14.2s\tremaining: 19.9s\n",
      "416:\tlearn: 0.2100910\ttotal: 14.2s\tremaining: 19.9s\n",
      "417:\tlearn: 0.2097266\ttotal: 14.2s\tremaining: 19.8s\n",
      "418:\tlearn: 0.2095041\ttotal: 14.3s\tremaining: 19.8s\n",
      "419:\tlearn: 0.2093448\ttotal: 14.3s\tremaining: 19.8s\n",
      "420:\tlearn: 0.2089685\ttotal: 14.4s\tremaining: 19.7s\n",
      "421:\tlearn: 0.2086698\ttotal: 14.4s\tremaining: 19.7s\n",
      "422:\tlearn: 0.2082552\ttotal: 14.4s\tremaining: 19.7s\n",
      "423:\tlearn: 0.2080943\ttotal: 14.5s\tremaining: 19.6s\n",
      "424:\tlearn: 0.2079113\ttotal: 14.5s\tremaining: 19.6s\n",
      "425:\tlearn: 0.2075810\ttotal: 14.5s\tremaining: 19.6s\n",
      "426:\tlearn: 0.2072419\ttotal: 14.6s\tremaining: 19.5s\n",
      "427:\tlearn: 0.2071379\ttotal: 14.6s\tremaining: 19.5s\n",
      "428:\tlearn: 0.2069608\ttotal: 14.6s\tremaining: 19.5s\n",
      "429:\tlearn: 0.2065421\ttotal: 14.7s\tremaining: 19.4s\n",
      "430:\tlearn: 0.2063774\ttotal: 14.7s\tremaining: 19.4s\n",
      "431:\tlearn: 0.2062574\ttotal: 14.7s\tremaining: 19.4s\n",
      "432:\tlearn: 0.2061364\ttotal: 14.8s\tremaining: 19.3s\n",
      "433:\tlearn: 0.2059787\ttotal: 14.8s\tremaining: 19.3s\n",
      "434:\tlearn: 0.2059177\ttotal: 14.8s\tremaining: 19.3s\n",
      "435:\tlearn: 0.2057090\ttotal: 14.9s\tremaining: 19.2s\n",
      "436:\tlearn: 0.2056152\ttotal: 14.9s\tremaining: 19.2s\n",
      "437:\tlearn: 0.2054221\ttotal: 14.9s\tremaining: 19.2s\n",
      "438:\tlearn: 0.2053188\ttotal: 15s\tremaining: 19.1s\n",
      "439:\tlearn: 0.2050210\ttotal: 15s\tremaining: 19.1s\n",
      "440:\tlearn: 0.2049335\ttotal: 15s\tremaining: 19.1s\n",
      "441:\tlearn: 0.2046382\ttotal: 15.1s\tremaining: 19s\n",
      "442:\tlearn: 0.2043351\ttotal: 15.1s\tremaining: 19s\n",
      "443:\tlearn: 0.2041481\ttotal: 15.1s\tremaining: 18.9s\n",
      "444:\tlearn: 0.2040090\ttotal: 15.2s\tremaining: 18.9s\n",
      "445:\tlearn: 0.2038012\ttotal: 15.2s\tremaining: 18.9s\n",
      "446:\tlearn: 0.2033667\ttotal: 15.2s\tremaining: 18.9s\n",
      "447:\tlearn: 0.2031938\ttotal: 15.3s\tremaining: 18.8s\n",
      "448:\tlearn: 0.2030642\ttotal: 15.3s\tremaining: 18.8s\n",
      "449:\tlearn: 0.2028146\ttotal: 15.3s\tremaining: 18.8s\n",
      "450:\tlearn: 0.2025802\ttotal: 15.4s\tremaining: 18.7s\n",
      "451:\tlearn: 0.2024694\ttotal: 15.4s\tremaining: 18.7s\n",
      "452:\tlearn: 0.2021675\ttotal: 15.5s\tremaining: 18.7s\n",
      "453:\tlearn: 0.2019248\ttotal: 15.5s\tremaining: 18.6s\n",
      "454:\tlearn: 0.2018403\ttotal: 15.5s\tremaining: 18.6s\n",
      "455:\tlearn: 0.2017150\ttotal: 15.5s\tremaining: 18.5s\n",
      "456:\tlearn: 0.2014001\ttotal: 15.6s\tremaining: 18.5s\n",
      "457:\tlearn: 0.2012696\ttotal: 15.6s\tremaining: 18.5s\n",
      "458:\tlearn: 0.2011369\ttotal: 15.6s\tremaining: 18.4s\n",
      "459:\tlearn: 0.2008025\ttotal: 15.7s\tremaining: 18.4s\n",
      "460:\tlearn: 0.2006845\ttotal: 15.7s\tremaining: 18.4s\n",
      "461:\tlearn: 0.2006236\ttotal: 15.8s\tremaining: 18.4s\n",
      "462:\tlearn: 0.2004214\ttotal: 15.8s\tremaining: 18.3s\n",
      "463:\tlearn: 0.2003326\ttotal: 15.8s\tremaining: 18.3s\n",
      "464:\tlearn: 0.2002114\ttotal: 15.9s\tremaining: 18.3s\n",
      "465:\tlearn: 0.2000552\ttotal: 15.9s\tremaining: 18.2s\n",
      "466:\tlearn: 0.1999845\ttotal: 15.9s\tremaining: 18.2s\n",
      "467:\tlearn: 0.1996099\ttotal: 16s\tremaining: 18.1s\n",
      "468:\tlearn: 0.1993979\ttotal: 16s\tremaining: 18.1s\n",
      "469:\tlearn: 0.1990421\ttotal: 16s\tremaining: 18.1s\n",
      "470:\tlearn: 0.1986789\ttotal: 16.1s\tremaining: 18s\n",
      "471:\tlearn: 0.1985222\ttotal: 16.1s\tremaining: 18s\n",
      "472:\tlearn: 0.1981582\ttotal: 16.1s\tremaining: 18s\n",
      "473:\tlearn: 0.1977942\ttotal: 16.2s\tremaining: 17.9s\n",
      "474:\tlearn: 0.1976630\ttotal: 16.2s\tremaining: 17.9s\n",
      "475:\tlearn: 0.1973702\ttotal: 16.2s\tremaining: 17.9s\n",
      "476:\tlearn: 0.1972786\ttotal: 16.3s\tremaining: 17.8s\n",
      "477:\tlearn: 0.1971450\ttotal: 16.3s\tremaining: 17.8s\n",
      "478:\tlearn: 0.1970259\ttotal: 16.3s\tremaining: 17.8s\n",
      "479:\tlearn: 0.1969152\ttotal: 16.4s\tremaining: 17.7s\n",
      "480:\tlearn: 0.1967216\ttotal: 16.4s\tremaining: 17.7s\n",
      "481:\tlearn: 0.1966248\ttotal: 16.4s\tremaining: 17.7s\n",
      "482:\tlearn: 0.1965199\ttotal: 16.5s\tremaining: 17.6s\n",
      "483:\tlearn: 0.1963316\ttotal: 16.5s\tremaining: 17.6s\n",
      "484:\tlearn: 0.1961549\ttotal: 16.5s\tremaining: 17.6s\n",
      "485:\tlearn: 0.1960934\ttotal: 16.6s\tremaining: 17.5s\n",
      "486:\tlearn: 0.1957223\ttotal: 16.6s\tremaining: 17.5s\n",
      "487:\tlearn: 0.1956074\ttotal: 16.7s\tremaining: 17.5s\n",
      "488:\tlearn: 0.1953648\ttotal: 16.7s\tremaining: 17.4s\n",
      "489:\tlearn: 0.1951317\ttotal: 16.7s\tremaining: 17.4s\n",
      "490:\tlearn: 0.1948117\ttotal: 16.8s\tremaining: 17.4s\n",
      "491:\tlearn: 0.1947124\ttotal: 16.8s\tremaining: 17.3s\n",
      "492:\tlearn: 0.1945173\ttotal: 16.8s\tremaining: 17.3s\n",
      "493:\tlearn: 0.1944492\ttotal: 16.9s\tremaining: 17.3s\n",
      "494:\tlearn: 0.1942834\ttotal: 16.9s\tremaining: 17.2s\n",
      "495:\tlearn: 0.1940456\ttotal: 16.9s\tremaining: 17.2s\n",
      "496:\tlearn: 0.1938279\ttotal: 16.9s\tremaining: 17.2s\n",
      "497:\tlearn: 0.1936958\ttotal: 17s\tremaining: 17.1s\n",
      "498:\tlearn: 0.1935535\ttotal: 17s\tremaining: 17.1s\n",
      "499:\tlearn: 0.1933710\ttotal: 17.1s\tremaining: 17.1s\n",
      "500:\tlearn: 0.1933202\ttotal: 17.1s\tremaining: 17s\n",
      "501:\tlearn: 0.1931926\ttotal: 17.1s\tremaining: 17s\n",
      "502:\tlearn: 0.1930442\ttotal: 17.2s\tremaining: 17s\n",
      "503:\tlearn: 0.1926653\ttotal: 17.2s\tremaining: 16.9s\n",
      "504:\tlearn: 0.1925126\ttotal: 17.2s\tremaining: 16.9s\n",
      "505:\tlearn: 0.1923192\ttotal: 17.3s\tremaining: 16.9s\n",
      "506:\tlearn: 0.1921784\ttotal: 17.3s\tremaining: 16.8s\n",
      "507:\tlearn: 0.1920326\ttotal: 17.3s\tremaining: 16.8s\n",
      "508:\tlearn: 0.1919040\ttotal: 17.4s\tremaining: 16.7s\n",
      "509:\tlearn: 0.1918149\ttotal: 17.4s\tremaining: 16.7s\n",
      "510:\tlearn: 0.1915047\ttotal: 17.4s\tremaining: 16.7s\n",
      "511:\tlearn: 0.1913340\ttotal: 17.5s\tremaining: 16.6s\n",
      "512:\tlearn: 0.1910798\ttotal: 17.5s\tremaining: 16.6s\n",
      "513:\tlearn: 0.1909298\ttotal: 17.5s\tremaining: 16.6s\n",
      "514:\tlearn: 0.1907305\ttotal: 17.6s\tremaining: 16.6s\n",
      "515:\tlearn: 0.1905854\ttotal: 17.6s\tremaining: 16.5s\n",
      "516:\tlearn: 0.1904669\ttotal: 17.7s\tremaining: 16.5s\n",
      "517:\tlearn: 0.1901924\ttotal: 17.7s\tremaining: 16.5s\n",
      "518:\tlearn: 0.1899805\ttotal: 17.7s\tremaining: 16.4s\n",
      "519:\tlearn: 0.1898639\ttotal: 17.7s\tremaining: 16.4s\n",
      "520:\tlearn: 0.1897364\ttotal: 17.8s\tremaining: 16.3s\n",
      "521:\tlearn: 0.1895860\ttotal: 17.8s\tremaining: 16.3s\n",
      "522:\tlearn: 0.1895122\ttotal: 17.8s\tremaining: 16.3s\n",
      "523:\tlearn: 0.1894073\ttotal: 17.9s\tremaining: 16.2s\n",
      "524:\tlearn: 0.1892583\ttotal: 17.9s\tremaining: 16.2s\n",
      "525:\tlearn: 0.1890075\ttotal: 18s\tremaining: 16.2s\n",
      "526:\tlearn: 0.1889097\ttotal: 18s\tremaining: 16.1s\n",
      "527:\tlearn: 0.1888013\ttotal: 18s\tremaining: 16.1s\n",
      "528:\tlearn: 0.1886913\ttotal: 18.1s\tremaining: 16.1s\n",
      "529:\tlearn: 0.1885513\ttotal: 18.1s\tremaining: 16s\n",
      "530:\tlearn: 0.1884750\ttotal: 18.1s\tremaining: 16s\n",
      "531:\tlearn: 0.1883425\ttotal: 18.2s\tremaining: 16s\n",
      "532:\tlearn: 0.1882521\ttotal: 18.2s\tremaining: 15.9s\n",
      "533:\tlearn: 0.1880712\ttotal: 18.2s\tremaining: 15.9s\n",
      "534:\tlearn: 0.1878727\ttotal: 18.2s\tremaining: 15.9s\n",
      "535:\tlearn: 0.1876246\ttotal: 18.3s\tremaining: 15.8s\n",
      "536:\tlearn: 0.1874615\ttotal: 18.3s\tremaining: 15.8s\n",
      "537:\tlearn: 0.1872122\ttotal: 18.4s\tremaining: 15.8s\n",
      "538:\tlearn: 0.1870805\ttotal: 18.4s\tremaining: 15.7s\n",
      "539:\tlearn: 0.1869414\ttotal: 18.4s\tremaining: 15.7s\n",
      "540:\tlearn: 0.1868782\ttotal: 18.5s\tremaining: 15.7s\n",
      "541:\tlearn: 0.1865920\ttotal: 18.5s\tremaining: 15.6s\n",
      "542:\tlearn: 0.1863956\ttotal: 18.5s\tremaining: 15.6s\n",
      "543:\tlearn: 0.1860706\ttotal: 18.6s\tremaining: 15.6s\n",
      "544:\tlearn: 0.1857976\ttotal: 18.6s\tremaining: 15.5s\n",
      "545:\tlearn: 0.1857241\ttotal: 18.6s\tremaining: 15.5s\n",
      "546:\tlearn: 0.1856466\ttotal: 18.7s\tremaining: 15.5s\n",
      "547:\tlearn: 0.1854949\ttotal: 18.7s\tremaining: 15.4s\n",
      "548:\tlearn: 0.1852180\ttotal: 18.7s\tremaining: 15.4s\n",
      "549:\tlearn: 0.1851208\ttotal: 18.8s\tremaining: 15.4s\n",
      "550:\tlearn: 0.1850815\ttotal: 18.8s\tremaining: 15.3s\n",
      "551:\tlearn: 0.1849276\ttotal: 18.9s\tremaining: 15.3s\n",
      "552:\tlearn: 0.1847718\ttotal: 18.9s\tremaining: 15.3s\n",
      "553:\tlearn: 0.1846841\ttotal: 18.9s\tremaining: 15.2s\n",
      "554:\tlearn: 0.1845607\ttotal: 19s\tremaining: 15.2s\n",
      "555:\tlearn: 0.1844861\ttotal: 19s\tremaining: 15.2s\n",
      "556:\tlearn: 0.1842911\ttotal: 19s\tremaining: 15.1s\n",
      "557:\tlearn: 0.1842083\ttotal: 19.1s\tremaining: 15.1s\n",
      "558:\tlearn: 0.1841594\ttotal: 19.1s\tremaining: 15.1s\n",
      "559:\tlearn: 0.1840951\ttotal: 19.1s\tremaining: 15s\n",
      "560:\tlearn: 0.1840142\ttotal: 19.1s\tremaining: 15s\n",
      "561:\tlearn: 0.1837856\ttotal: 19.2s\tremaining: 14.9s\n",
      "562:\tlearn: 0.1835272\ttotal: 19.2s\tremaining: 14.9s\n",
      "563:\tlearn: 0.1834658\ttotal: 19.3s\tremaining: 14.9s\n",
      "564:\tlearn: 0.1833497\ttotal: 19.3s\tremaining: 14.9s\n",
      "565:\tlearn: 0.1829592\ttotal: 19.3s\tremaining: 14.8s\n",
      "566:\tlearn: 0.1827193\ttotal: 19.4s\tremaining: 14.8s\n",
      "567:\tlearn: 0.1825906\ttotal: 19.4s\tremaining: 14.8s\n",
      "568:\tlearn: 0.1824855\ttotal: 19.4s\tremaining: 14.7s\n",
      "569:\tlearn: 0.1823552\ttotal: 19.5s\tremaining: 14.7s\n",
      "570:\tlearn: 0.1822383\ttotal: 19.5s\tremaining: 14.7s\n",
      "571:\tlearn: 0.1819968\ttotal: 19.5s\tremaining: 14.6s\n",
      "572:\tlearn: 0.1819411\ttotal: 19.6s\tremaining: 14.6s\n",
      "573:\tlearn: 0.1816771\ttotal: 19.6s\tremaining: 14.5s\n",
      "574:\tlearn: 0.1815379\ttotal: 19.6s\tremaining: 14.5s\n",
      "575:\tlearn: 0.1814545\ttotal: 19.7s\tremaining: 14.5s\n",
      "576:\tlearn: 0.1813703\ttotal: 19.7s\tremaining: 14.5s\n",
      "577:\tlearn: 0.1812145\ttotal: 19.8s\tremaining: 14.4s\n",
      "578:\tlearn: 0.1809430\ttotal: 19.8s\tremaining: 14.4s\n",
      "579:\tlearn: 0.1807873\ttotal: 19.8s\tremaining: 14.4s\n",
      "580:\tlearn: 0.1806942\ttotal: 19.9s\tremaining: 14.3s\n",
      "581:\tlearn: 0.1804587\ttotal: 19.9s\tremaining: 14.3s\n",
      "582:\tlearn: 0.1801845\ttotal: 19.9s\tremaining: 14.3s\n",
      "583:\tlearn: 0.1800432\ttotal: 20s\tremaining: 14.2s\n",
      "584:\tlearn: 0.1799117\ttotal: 20s\tremaining: 14.2s\n",
      "585:\tlearn: 0.1798212\ttotal: 20s\tremaining: 14.1s\n",
      "586:\tlearn: 0.1797129\ttotal: 20s\tremaining: 14.1s\n",
      "587:\tlearn: 0.1795491\ttotal: 20.1s\tremaining: 14.1s\n",
      "588:\tlearn: 0.1793649\ttotal: 20.1s\tremaining: 14s\n",
      "589:\tlearn: 0.1792905\ttotal: 20.2s\tremaining: 14s\n",
      "590:\tlearn: 0.1791515\ttotal: 20.2s\tremaining: 14s\n",
      "591:\tlearn: 0.1790475\ttotal: 20.2s\tremaining: 13.9s\n",
      "592:\tlearn: 0.1788963\ttotal: 20.3s\tremaining: 13.9s\n",
      "593:\tlearn: 0.1787880\ttotal: 20.3s\tremaining: 13.9s\n",
      "594:\tlearn: 0.1786059\ttotal: 20.3s\tremaining: 13.8s\n",
      "595:\tlearn: 0.1784496\ttotal: 20.4s\tremaining: 13.8s\n",
      "596:\tlearn: 0.1783814\ttotal: 20.4s\tremaining: 13.8s\n",
      "597:\tlearn: 0.1782042\ttotal: 20.4s\tremaining: 13.7s\n",
      "598:\tlearn: 0.1779818\ttotal: 20.5s\tremaining: 13.7s\n",
      "599:\tlearn: 0.1777497\ttotal: 20.5s\tremaining: 13.7s\n",
      "600:\tlearn: 0.1776008\ttotal: 20.5s\tremaining: 13.6s\n",
      "601:\tlearn: 0.1774530\ttotal: 20.6s\tremaining: 13.6s\n",
      "602:\tlearn: 0.1772746\ttotal: 20.6s\tremaining: 13.6s\n",
      "603:\tlearn: 0.1771719\ttotal: 20.6s\tremaining: 13.5s\n",
      "604:\tlearn: 0.1770919\ttotal: 20.7s\tremaining: 13.5s\n",
      "605:\tlearn: 0.1769407\ttotal: 20.7s\tremaining: 13.5s\n",
      "606:\tlearn: 0.1767356\ttotal: 20.7s\tremaining: 13.4s\n",
      "607:\tlearn: 0.1763546\ttotal: 20.8s\tremaining: 13.4s\n",
      "608:\tlearn: 0.1761145\ttotal: 20.8s\tremaining: 13.4s\n",
      "609:\tlearn: 0.1760212\ttotal: 20.8s\tremaining: 13.3s\n",
      "610:\tlearn: 0.1759071\ttotal: 20.9s\tremaining: 13.3s\n",
      "611:\tlearn: 0.1758312\ttotal: 20.9s\tremaining: 13.2s\n",
      "612:\tlearn: 0.1756339\ttotal: 20.9s\tremaining: 13.2s\n",
      "613:\tlearn: 0.1755028\ttotal: 21s\tremaining: 13.2s\n",
      "614:\tlearn: 0.1754013\ttotal: 21s\tremaining: 13.1s\n",
      "615:\tlearn: 0.1753018\ttotal: 21s\tremaining: 13.1s\n",
      "616:\tlearn: 0.1751056\ttotal: 21.1s\tremaining: 13.1s\n",
      "617:\tlearn: 0.1749984\ttotal: 21.1s\tremaining: 13.1s\n",
      "618:\tlearn: 0.1748304\ttotal: 21.2s\tremaining: 13s\n",
      "619:\tlearn: 0.1747042\ttotal: 21.2s\tremaining: 13s\n",
      "620:\tlearn: 0.1745791\ttotal: 21.2s\tremaining: 13s\n",
      "621:\tlearn: 0.1743992\ttotal: 21.3s\tremaining: 12.9s\n",
      "622:\tlearn: 0.1742598\ttotal: 21.3s\tremaining: 12.9s\n",
      "623:\tlearn: 0.1741633\ttotal: 21.3s\tremaining: 12.8s\n",
      "624:\tlearn: 0.1741135\ttotal: 21.3s\tremaining: 12.8s\n",
      "625:\tlearn: 0.1739562\ttotal: 21.4s\tremaining: 12.8s\n",
      "626:\tlearn: 0.1738135\ttotal: 21.4s\tremaining: 12.7s\n",
      "627:\tlearn: 0.1737241\ttotal: 21.4s\tremaining: 12.7s\n",
      "628:\tlearn: 0.1736341\ttotal: 21.5s\tremaining: 12.7s\n",
      "629:\tlearn: 0.1735447\ttotal: 21.5s\tremaining: 12.6s\n",
      "630:\tlearn: 0.1734376\ttotal: 21.6s\tremaining: 12.6s\n",
      "631:\tlearn: 0.1730513\ttotal: 21.6s\tremaining: 12.6s\n",
      "632:\tlearn: 0.1729821\ttotal: 21.6s\tremaining: 12.5s\n",
      "633:\tlearn: 0.1728638\ttotal: 21.7s\tremaining: 12.5s\n",
      "634:\tlearn: 0.1727462\ttotal: 21.7s\tremaining: 12.5s\n",
      "635:\tlearn: 0.1727013\ttotal: 21.7s\tremaining: 12.4s\n",
      "636:\tlearn: 0.1724700\ttotal: 21.8s\tremaining: 12.4s\n",
      "637:\tlearn: 0.1723315\ttotal: 21.8s\tremaining: 12.4s\n",
      "638:\tlearn: 0.1722599\ttotal: 21.8s\tremaining: 12.3s\n",
      "639:\tlearn: 0.1720882\ttotal: 21.9s\tremaining: 12.3s\n",
      "640:\tlearn: 0.1719378\ttotal: 21.9s\tremaining: 12.3s\n",
      "641:\tlearn: 0.1718611\ttotal: 21.9s\tremaining: 12.2s\n",
      "642:\tlearn: 0.1717632\ttotal: 22s\tremaining: 12.2s\n",
      "643:\tlearn: 0.1716105\ttotal: 22s\tremaining: 12.2s\n",
      "644:\tlearn: 0.1714863\ttotal: 22.1s\tremaining: 12.1s\n",
      "645:\tlearn: 0.1713589\ttotal: 22.1s\tremaining: 12.1s\n",
      "646:\tlearn: 0.1712963\ttotal: 22.1s\tremaining: 12.1s\n",
      "647:\tlearn: 0.1711897\ttotal: 22.1s\tremaining: 12s\n",
      "648:\tlearn: 0.1710069\ttotal: 22.2s\tremaining: 12s\n",
      "649:\tlearn: 0.1708023\ttotal: 22.2s\tremaining: 12s\n",
      "650:\tlearn: 0.1705876\ttotal: 22.2s\tremaining: 11.9s\n",
      "651:\tlearn: 0.1704885\ttotal: 22.3s\tremaining: 11.9s\n",
      "652:\tlearn: 0.1702521\ttotal: 22.3s\tremaining: 11.9s\n",
      "653:\tlearn: 0.1700848\ttotal: 22.3s\tremaining: 11.8s\n",
      "654:\tlearn: 0.1700093\ttotal: 22.4s\tremaining: 11.8s\n",
      "655:\tlearn: 0.1698553\ttotal: 22.4s\tremaining: 11.8s\n",
      "656:\tlearn: 0.1697804\ttotal: 22.5s\tremaining: 11.7s\n",
      "657:\tlearn: 0.1696822\ttotal: 22.5s\tremaining: 11.7s\n",
      "658:\tlearn: 0.1696241\ttotal: 22.5s\tremaining: 11.7s\n",
      "659:\tlearn: 0.1695911\ttotal: 22.6s\tremaining: 11.6s\n",
      "660:\tlearn: 0.1694654\ttotal: 22.6s\tremaining: 11.6s\n",
      "661:\tlearn: 0.1692607\ttotal: 22.6s\tremaining: 11.6s\n",
      "662:\tlearn: 0.1691053\ttotal: 22.7s\tremaining: 11.5s\n",
      "663:\tlearn: 0.1689710\ttotal: 22.7s\tremaining: 11.5s\n",
      "664:\tlearn: 0.1688289\ttotal: 22.7s\tremaining: 11.4s\n",
      "665:\tlearn: 0.1686436\ttotal: 22.8s\tremaining: 11.4s\n",
      "666:\tlearn: 0.1685936\ttotal: 22.8s\tremaining: 11.4s\n",
      "667:\tlearn: 0.1684813\ttotal: 22.9s\tremaining: 11.4s\n",
      "668:\tlearn: 0.1683727\ttotal: 22.9s\tremaining: 11.3s\n",
      "669:\tlearn: 0.1683408\ttotal: 22.9s\tremaining: 11.3s\n",
      "670:\tlearn: 0.1682415\ttotal: 23s\tremaining: 11.3s\n",
      "671:\tlearn: 0.1681543\ttotal: 23s\tremaining: 11.2s\n",
      "672:\tlearn: 0.1679645\ttotal: 23s\tremaining: 11.2s\n",
      "673:\tlearn: 0.1678851\ttotal: 23.1s\tremaining: 11.2s\n",
      "674:\tlearn: 0.1676672\ttotal: 23.1s\tremaining: 11.1s\n",
      "675:\tlearn: 0.1674843\ttotal: 23.1s\tremaining: 11.1s\n",
      "676:\tlearn: 0.1673873\ttotal: 23.1s\tremaining: 11s\n",
      "677:\tlearn: 0.1672622\ttotal: 23.2s\tremaining: 11s\n",
      "678:\tlearn: 0.1672239\ttotal: 23.2s\tremaining: 11s\n",
      "679:\tlearn: 0.1671104\ttotal: 23.3s\tremaining: 10.9s\n",
      "680:\tlearn: 0.1670523\ttotal: 23.3s\tremaining: 10.9s\n",
      "681:\tlearn: 0.1669144\ttotal: 23.3s\tremaining: 10.9s\n",
      "682:\tlearn: 0.1668358\ttotal: 23.4s\tremaining: 10.9s\n",
      "683:\tlearn: 0.1666575\ttotal: 23.4s\tremaining: 10.8s\n",
      "684:\tlearn: 0.1665864\ttotal: 23.5s\tremaining: 10.8s\n",
      "685:\tlearn: 0.1665184\ttotal: 23.5s\tremaining: 10.8s\n",
      "686:\tlearn: 0.1664269\ttotal: 23.5s\tremaining: 10.7s\n",
      "687:\tlearn: 0.1663277\ttotal: 23.6s\tremaining: 10.7s\n",
      "688:\tlearn: 0.1661488\ttotal: 23.6s\tremaining: 10.6s\n",
      "689:\tlearn: 0.1660855\ttotal: 23.6s\tremaining: 10.6s\n",
      "690:\tlearn: 0.1660197\ttotal: 23.7s\tremaining: 10.6s\n",
      "691:\tlearn: 0.1658933\ttotal: 23.7s\tremaining: 10.6s\n",
      "692:\tlearn: 0.1658253\ttotal: 23.7s\tremaining: 10.5s\n",
      "693:\tlearn: 0.1656521\ttotal: 23.8s\tremaining: 10.5s\n",
      "694:\tlearn: 0.1656213\ttotal: 23.8s\tremaining: 10.4s\n",
      "695:\tlearn: 0.1653606\ttotal: 23.8s\tremaining: 10.4s\n",
      "696:\tlearn: 0.1652140\ttotal: 23.9s\tremaining: 10.4s\n",
      "697:\tlearn: 0.1649848\ttotal: 23.9s\tremaining: 10.3s\n",
      "698:\tlearn: 0.1648781\ttotal: 23.9s\tremaining: 10.3s\n",
      "699:\tlearn: 0.1647546\ttotal: 24s\tremaining: 10.3s\n",
      "700:\tlearn: 0.1647143\ttotal: 24s\tremaining: 10.2s\n",
      "701:\tlearn: 0.1645450\ttotal: 24s\tremaining: 10.2s\n",
      "702:\tlearn: 0.1644788\ttotal: 24.1s\tremaining: 10.2s\n",
      "703:\tlearn: 0.1643441\ttotal: 24.1s\tremaining: 10.1s\n",
      "704:\tlearn: 0.1642884\ttotal: 24.1s\tremaining: 10.1s\n",
      "705:\tlearn: 0.1641942\ttotal: 24.2s\tremaining: 10.1s\n",
      "706:\tlearn: 0.1640996\ttotal: 24.2s\tremaining: 10s\n",
      "707:\tlearn: 0.1639075\ttotal: 24.2s\tremaining: 10s\n",
      "708:\tlearn: 0.1637348\ttotal: 24.3s\tremaining: 9.97s\n",
      "709:\tlearn: 0.1636783\ttotal: 24.3s\tremaining: 9.93s\n",
      "710:\tlearn: 0.1635991\ttotal: 24.4s\tremaining: 9.9s\n",
      "711:\tlearn: 0.1633112\ttotal: 24.4s\tremaining: 9.86s\n",
      "712:\tlearn: 0.1632590\ttotal: 24.4s\tremaining: 9.83s\n",
      "713:\tlearn: 0.1631694\ttotal: 24.4s\tremaining: 9.79s\n",
      "714:\tlearn: 0.1629299\ttotal: 24.5s\tremaining: 9.76s\n",
      "715:\tlearn: 0.1628663\ttotal: 24.5s\tremaining: 9.72s\n",
      "716:\tlearn: 0.1628029\ttotal: 24.5s\tremaining: 9.69s\n",
      "717:\tlearn: 0.1627151\ttotal: 24.6s\tremaining: 9.65s\n",
      "718:\tlearn: 0.1626445\ttotal: 24.6s\tremaining: 9.62s\n",
      "719:\tlearn: 0.1625268\ttotal: 24.7s\tremaining: 9.59s\n",
      "720:\tlearn: 0.1623717\ttotal: 24.7s\tremaining: 9.56s\n",
      "721:\tlearn: 0.1622206\ttotal: 24.7s\tremaining: 9.52s\n",
      "722:\tlearn: 0.1620584\ttotal: 24.8s\tremaining: 9.49s\n",
      "723:\tlearn: 0.1619359\ttotal: 24.8s\tremaining: 9.46s\n",
      "724:\tlearn: 0.1617634\ttotal: 24.8s\tremaining: 9.42s\n",
      "725:\tlearn: 0.1615618\ttotal: 24.9s\tremaining: 9.39s\n",
      "726:\tlearn: 0.1614499\ttotal: 24.9s\tremaining: 9.35s\n",
      "727:\tlearn: 0.1612176\ttotal: 24.9s\tremaining: 9.31s\n",
      "728:\tlearn: 0.1611448\ttotal: 25s\tremaining: 9.28s\n",
      "729:\tlearn: 0.1610669\ttotal: 25s\tremaining: 9.25s\n",
      "730:\tlearn: 0.1609305\ttotal: 25s\tremaining: 9.22s\n",
      "731:\tlearn: 0.1608327\ttotal: 25.1s\tremaining: 9.19s\n",
      "732:\tlearn: 0.1607023\ttotal: 25.1s\tremaining: 9.15s\n",
      "733:\tlearn: 0.1606177\ttotal: 25.2s\tremaining: 9.12s\n",
      "734:\tlearn: 0.1605185\ttotal: 25.2s\tremaining: 9.08s\n",
      "735:\tlearn: 0.1604238\ttotal: 25.2s\tremaining: 9.05s\n",
      "736:\tlearn: 0.1602954\ttotal: 25.3s\tremaining: 9.01s\n",
      "737:\tlearn: 0.1601449\ttotal: 25.3s\tremaining: 8.98s\n",
      "738:\tlearn: 0.1599738\ttotal: 25.3s\tremaining: 8.94s\n",
      "739:\tlearn: 0.1598446\ttotal: 25.4s\tremaining: 8.91s\n",
      "740:\tlearn: 0.1597388\ttotal: 25.4s\tremaining: 8.87s\n",
      "741:\tlearn: 0.1595052\ttotal: 25.4s\tremaining: 8.84s\n",
      "742:\tlearn: 0.1594816\ttotal: 25.4s\tremaining: 8.8s\n",
      "743:\tlearn: 0.1593685\ttotal: 25.5s\tremaining: 8.77s\n",
      "744:\tlearn: 0.1591576\ttotal: 25.5s\tremaining: 8.74s\n",
      "745:\tlearn: 0.1589827\ttotal: 25.6s\tremaining: 8.71s\n",
      "746:\tlearn: 0.1588887\ttotal: 25.6s\tremaining: 8.67s\n",
      "747:\tlearn: 0.1586480\ttotal: 25.6s\tremaining: 8.64s\n",
      "748:\tlearn: 0.1584558\ttotal: 25.7s\tremaining: 8.61s\n",
      "749:\tlearn: 0.1583199\ttotal: 25.7s\tremaining: 8.57s\n",
      "750:\tlearn: 0.1581417\ttotal: 25.7s\tremaining: 8.54s\n",
      "751:\tlearn: 0.1579634\ttotal: 25.8s\tremaining: 8.5s\n",
      "752:\tlearn: 0.1579137\ttotal: 25.8s\tremaining: 8.46s\n",
      "753:\tlearn: 0.1577841\ttotal: 25.8s\tremaining: 8.43s\n",
      "754:\tlearn: 0.1577223\ttotal: 25.9s\tremaining: 8.39s\n",
      "755:\tlearn: 0.1576409\ttotal: 25.9s\tremaining: 8.36s\n",
      "756:\tlearn: 0.1574879\ttotal: 25.9s\tremaining: 8.33s\n",
      "757:\tlearn: 0.1574178\ttotal: 26s\tremaining: 8.3s\n",
      "758:\tlearn: 0.1573697\ttotal: 26s\tremaining: 8.27s\n",
      "759:\tlearn: 0.1573097\ttotal: 26.1s\tremaining: 8.23s\n",
      "760:\tlearn: 0.1571181\ttotal: 26.1s\tremaining: 8.2s\n",
      "761:\tlearn: 0.1570464\ttotal: 26.1s\tremaining: 8.16s\n",
      "762:\tlearn: 0.1569962\ttotal: 26.2s\tremaining: 8.13s\n",
      "763:\tlearn: 0.1568779\ttotal: 26.2s\tremaining: 8.09s\n",
      "764:\tlearn: 0.1567712\ttotal: 26.2s\tremaining: 8.06s\n",
      "765:\tlearn: 0.1567024\ttotal: 26.3s\tremaining: 8.02s\n",
      "766:\tlearn: 0.1566348\ttotal: 26.3s\tremaining: 7.98s\n",
      "767:\tlearn: 0.1566069\ttotal: 26.3s\tremaining: 7.95s\n",
      "768:\tlearn: 0.1564752\ttotal: 26.3s\tremaining: 7.91s\n",
      "769:\tlearn: 0.1564178\ttotal: 26.4s\tremaining: 7.88s\n",
      "770:\tlearn: 0.1562482\ttotal: 26.4s\tremaining: 7.85s\n",
      "771:\tlearn: 0.1561215\ttotal: 26.5s\tremaining: 7.82s\n",
      "772:\tlearn: 0.1560633\ttotal: 26.5s\tremaining: 7.79s\n",
      "773:\tlearn: 0.1559718\ttotal: 26.6s\tremaining: 7.75s\n",
      "774:\tlearn: 0.1558108\ttotal: 26.6s\tremaining: 7.72s\n",
      "775:\tlearn: 0.1556424\ttotal: 26.6s\tremaining: 7.68s\n",
      "776:\tlearn: 0.1554688\ttotal: 26.6s\tremaining: 7.65s\n",
      "777:\tlearn: 0.1553166\ttotal: 26.7s\tremaining: 7.61s\n",
      "778:\tlearn: 0.1552876\ttotal: 26.7s\tremaining: 7.58s\n",
      "779:\tlearn: 0.1552067\ttotal: 26.7s\tremaining: 7.54s\n",
      "780:\tlearn: 0.1550618\ttotal: 26.8s\tremaining: 7.5s\n",
      "781:\tlearn: 0.1549945\ttotal: 26.8s\tremaining: 7.47s\n",
      "782:\tlearn: 0.1549038\ttotal: 26.8s\tremaining: 7.44s\n",
      "783:\tlearn: 0.1548076\ttotal: 26.9s\tremaining: 7.41s\n",
      "784:\tlearn: 0.1546914\ttotal: 26.9s\tremaining: 7.38s\n",
      "785:\tlearn: 0.1545301\ttotal: 27s\tremaining: 7.34s\n",
      "786:\tlearn: 0.1543644\ttotal: 27s\tremaining: 7.31s\n",
      "787:\tlearn: 0.1542516\ttotal: 27s\tremaining: 7.27s\n",
      "788:\tlearn: 0.1541763\ttotal: 27.1s\tremaining: 7.24s\n",
      "789:\tlearn: 0.1540844\ttotal: 27.1s\tremaining: 7.2s\n",
      "790:\tlearn: 0.1539705\ttotal: 27.1s\tremaining: 7.17s\n",
      "791:\tlearn: 0.1538365\ttotal: 27.2s\tremaining: 7.13s\n",
      "792:\tlearn: 0.1537776\ttotal: 27.2s\tremaining: 7.1s\n",
      "793:\tlearn: 0.1536580\ttotal: 27.2s\tremaining: 7.06s\n",
      "794:\tlearn: 0.1535943\ttotal: 27.3s\tremaining: 7.03s\n",
      "795:\tlearn: 0.1534930\ttotal: 27.3s\tremaining: 7s\n",
      "796:\tlearn: 0.1534273\ttotal: 27.3s\tremaining: 6.96s\n",
      "797:\tlearn: 0.1534052\ttotal: 27.4s\tremaining: 6.93s\n",
      "798:\tlearn: 0.1532210\ttotal: 27.4s\tremaining: 6.89s\n",
      "799:\tlearn: 0.1531174\ttotal: 27.4s\tremaining: 6.86s\n",
      "800:\tlearn: 0.1530093\ttotal: 27.5s\tremaining: 6.83s\n",
      "801:\tlearn: 0.1529321\ttotal: 27.5s\tremaining: 6.79s\n",
      "802:\tlearn: 0.1527993\ttotal: 27.6s\tremaining: 6.76s\n",
      "803:\tlearn: 0.1527286\ttotal: 27.6s\tremaining: 6.72s\n",
      "804:\tlearn: 0.1525770\ttotal: 27.6s\tremaining: 6.69s\n",
      "805:\tlearn: 0.1525066\ttotal: 27.7s\tremaining: 6.67s\n",
      "806:\tlearn: 0.1524738\ttotal: 27.7s\tremaining: 6.63s\n",
      "807:\tlearn: 0.1523520\ttotal: 27.8s\tremaining: 6.6s\n",
      "808:\tlearn: 0.1521742\ttotal: 27.8s\tremaining: 6.57s\n",
      "809:\tlearn: 0.1520852\ttotal: 27.9s\tremaining: 6.53s\n",
      "810:\tlearn: 0.1519718\ttotal: 27.9s\tremaining: 6.5s\n",
      "811:\tlearn: 0.1518811\ttotal: 27.9s\tremaining: 6.46s\n",
      "812:\tlearn: 0.1517799\ttotal: 28s\tremaining: 6.43s\n",
      "813:\tlearn: 0.1516542\ttotal: 28s\tremaining: 6.39s\n",
      "814:\tlearn: 0.1514713\ttotal: 28s\tremaining: 6.36s\n",
      "815:\tlearn: 0.1513431\ttotal: 28.1s\tremaining: 6.33s\n",
      "816:\tlearn: 0.1512652\ttotal: 28.1s\tremaining: 6.29s\n",
      "817:\tlearn: 0.1512184\ttotal: 28.1s\tremaining: 6.26s\n",
      "818:\tlearn: 0.1511440\ttotal: 28.2s\tremaining: 6.23s\n",
      "819:\tlearn: 0.1510638\ttotal: 28.2s\tremaining: 6.19s\n",
      "820:\tlearn: 0.1509641\ttotal: 28.2s\tremaining: 6.16s\n",
      "821:\tlearn: 0.1508597\ttotal: 28.3s\tremaining: 6.12s\n",
      "822:\tlearn: 0.1508257\ttotal: 28.3s\tremaining: 6.09s\n",
      "823:\tlearn: 0.1507309\ttotal: 28.3s\tremaining: 6.05s\n",
      "824:\tlearn: 0.1505856\ttotal: 28.4s\tremaining: 6.02s\n",
      "825:\tlearn: 0.1504644\ttotal: 28.4s\tremaining: 5.98s\n",
      "826:\tlearn: 0.1503625\ttotal: 28.4s\tremaining: 5.95s\n",
      "827:\tlearn: 0.1503049\ttotal: 28.5s\tremaining: 5.91s\n",
      "828:\tlearn: 0.1502537\ttotal: 28.5s\tremaining: 5.88s\n",
      "829:\tlearn: 0.1500921\ttotal: 28.5s\tremaining: 5.84s\n",
      "830:\tlearn: 0.1499769\ttotal: 28.6s\tremaining: 5.81s\n",
      "831:\tlearn: 0.1499097\ttotal: 28.6s\tremaining: 5.78s\n",
      "832:\tlearn: 0.1497594\ttotal: 28.7s\tremaining: 5.74s\n",
      "833:\tlearn: 0.1496656\ttotal: 28.7s\tremaining: 5.71s\n",
      "834:\tlearn: 0.1495830\ttotal: 28.7s\tremaining: 5.68s\n",
      "835:\tlearn: 0.1494439\ttotal: 28.8s\tremaining: 5.64s\n",
      "836:\tlearn: 0.1493812\ttotal: 28.8s\tremaining: 5.61s\n",
      "837:\tlearn: 0.1492859\ttotal: 28.8s\tremaining: 5.57s\n",
      "838:\tlearn: 0.1491604\ttotal: 28.9s\tremaining: 5.54s\n",
      "839:\tlearn: 0.1490697\ttotal: 28.9s\tremaining: 5.5s\n",
      "840:\tlearn: 0.1488938\ttotal: 28.9s\tremaining: 5.47s\n",
      "841:\tlearn: 0.1488546\ttotal: 28.9s\tremaining: 5.43s\n",
      "842:\tlearn: 0.1487806\ttotal: 29s\tremaining: 5.4s\n",
      "843:\tlearn: 0.1486569\ttotal: 29s\tremaining: 5.37s\n",
      "844:\tlearn: 0.1485042\ttotal: 29.1s\tremaining: 5.33s\n",
      "845:\tlearn: 0.1484107\ttotal: 29.1s\tremaining: 5.3s\n",
      "846:\tlearn: 0.1483359\ttotal: 29.1s\tremaining: 5.26s\n",
      "847:\tlearn: 0.1481939\ttotal: 29.2s\tremaining: 5.23s\n",
      "848:\tlearn: 0.1480633\ttotal: 29.2s\tremaining: 5.2s\n",
      "849:\tlearn: 0.1479436\ttotal: 29.2s\tremaining: 5.16s\n",
      "850:\tlearn: 0.1478567\ttotal: 29.3s\tremaining: 5.13s\n",
      "851:\tlearn: 0.1477771\ttotal: 29.3s\tremaining: 5.09s\n",
      "852:\tlearn: 0.1476849\ttotal: 29.3s\tremaining: 5.06s\n",
      "853:\tlearn: 0.1475824\ttotal: 29.4s\tremaining: 5.02s\n",
      "854:\tlearn: 0.1475154\ttotal: 29.4s\tremaining: 4.99s\n",
      "855:\tlearn: 0.1473581\ttotal: 29.4s\tremaining: 4.95s\n",
      "856:\tlearn: 0.1472936\ttotal: 29.5s\tremaining: 4.92s\n",
      "857:\tlearn: 0.1472209\ttotal: 29.5s\tremaining: 4.88s\n",
      "858:\tlearn: 0.1471444\ttotal: 29.5s\tremaining: 4.85s\n",
      "859:\tlearn: 0.1470465\ttotal: 29.6s\tremaining: 4.82s\n",
      "860:\tlearn: 0.1469393\ttotal: 29.6s\tremaining: 4.78s\n",
      "861:\tlearn: 0.1468731\ttotal: 29.7s\tremaining: 4.75s\n",
      "862:\tlearn: 0.1468401\ttotal: 29.7s\tremaining: 4.71s\n",
      "863:\tlearn: 0.1467584\ttotal: 29.7s\tremaining: 4.68s\n",
      "864:\tlearn: 0.1466732\ttotal: 29.8s\tremaining: 4.64s\n",
      "865:\tlearn: 0.1465851\ttotal: 29.8s\tremaining: 4.61s\n",
      "866:\tlearn: 0.1463501\ttotal: 29.8s\tremaining: 4.58s\n",
      "867:\tlearn: 0.1462189\ttotal: 29.9s\tremaining: 4.54s\n",
      "868:\tlearn: 0.1460740\ttotal: 29.9s\tremaining: 4.51s\n",
      "869:\tlearn: 0.1460104\ttotal: 30s\tremaining: 4.48s\n",
      "870:\tlearn: 0.1459238\ttotal: 30s\tremaining: 4.44s\n",
      "871:\tlearn: 0.1458173\ttotal: 30s\tremaining: 4.41s\n",
      "872:\tlearn: 0.1457322\ttotal: 30.1s\tremaining: 4.37s\n",
      "873:\tlearn: 0.1455522\ttotal: 30.1s\tremaining: 4.34s\n",
      "874:\tlearn: 0.1454929\ttotal: 30.1s\tremaining: 4.3s\n",
      "875:\tlearn: 0.1453309\ttotal: 30.2s\tremaining: 4.27s\n",
      "876:\tlearn: 0.1452075\ttotal: 30.2s\tremaining: 4.24s\n",
      "877:\tlearn: 0.1450876\ttotal: 30.2s\tremaining: 4.2s\n",
      "878:\tlearn: 0.1450399\ttotal: 30.3s\tremaining: 4.17s\n",
      "879:\tlearn: 0.1449929\ttotal: 30.3s\tremaining: 4.13s\n",
      "880:\tlearn: 0.1449454\ttotal: 30.3s\tremaining: 4.09s\n",
      "881:\tlearn: 0.1448240\ttotal: 30.4s\tremaining: 4.06s\n",
      "882:\tlearn: 0.1447463\ttotal: 30.4s\tremaining: 4.03s\n",
      "883:\tlearn: 0.1445228\ttotal: 30.4s\tremaining: 3.99s\n",
      "884:\tlearn: 0.1444316\ttotal: 30.5s\tremaining: 3.96s\n",
      "885:\tlearn: 0.1443632\ttotal: 30.5s\tremaining: 3.93s\n",
      "886:\tlearn: 0.1442834\ttotal: 30.5s\tremaining: 3.89s\n",
      "887:\tlearn: 0.1441636\ttotal: 30.6s\tremaining: 3.86s\n",
      "888:\tlearn: 0.1440784\ttotal: 30.6s\tremaining: 3.82s\n",
      "889:\tlearn: 0.1440087\ttotal: 30.7s\tremaining: 3.79s\n",
      "890:\tlearn: 0.1438883\ttotal: 30.7s\tremaining: 3.75s\n",
      "891:\tlearn: 0.1438090\ttotal: 30.7s\tremaining: 3.72s\n",
      "892:\tlearn: 0.1435708\ttotal: 30.7s\tremaining: 3.68s\n",
      "893:\tlearn: 0.1435409\ttotal: 30.8s\tremaining: 3.65s\n",
      "894:\tlearn: 0.1435109\ttotal: 30.8s\tremaining: 3.61s\n",
      "895:\tlearn: 0.1434497\ttotal: 30.9s\tremaining: 3.58s\n",
      "896:\tlearn: 0.1433390\ttotal: 30.9s\tremaining: 3.55s\n",
      "897:\tlearn: 0.1432884\ttotal: 30.9s\tremaining: 3.51s\n",
      "898:\tlearn: 0.1431611\ttotal: 31s\tremaining: 3.48s\n",
      "899:\tlearn: 0.1430641\ttotal: 31s\tremaining: 3.44s\n",
      "900:\tlearn: 0.1429532\ttotal: 31s\tremaining: 3.41s\n",
      "901:\tlearn: 0.1428576\ttotal: 31.1s\tremaining: 3.38s\n",
      "902:\tlearn: 0.1427974\ttotal: 31.1s\tremaining: 3.34s\n",
      "903:\tlearn: 0.1426809\ttotal: 31.1s\tremaining: 3.31s\n",
      "904:\tlearn: 0.1426048\ttotal: 31.2s\tremaining: 3.27s\n",
      "905:\tlearn: 0.1425674\ttotal: 31.2s\tremaining: 3.23s\n",
      "906:\tlearn: 0.1424544\ttotal: 31.2s\tremaining: 3.2s\n",
      "907:\tlearn: 0.1423737\ttotal: 31.3s\tremaining: 3.17s\n",
      "908:\tlearn: 0.1422694\ttotal: 31.3s\tremaining: 3.13s\n",
      "909:\tlearn: 0.1421485\ttotal: 31.3s\tremaining: 3.1s\n",
      "910:\tlearn: 0.1420741\ttotal: 31.4s\tremaining: 3.06s\n",
      "911:\tlearn: 0.1420109\ttotal: 31.4s\tremaining: 3.03s\n",
      "912:\tlearn: 0.1419486\ttotal: 31.4s\tremaining: 3s\n",
      "913:\tlearn: 0.1418800\ttotal: 31.5s\tremaining: 2.96s\n",
      "914:\tlearn: 0.1418458\ttotal: 31.5s\tremaining: 2.93s\n",
      "915:\tlearn: 0.1418167\ttotal: 31.5s\tremaining: 2.89s\n",
      "916:\tlearn: 0.1417059\ttotal: 31.6s\tremaining: 2.86s\n",
      "917:\tlearn: 0.1415102\ttotal: 31.6s\tremaining: 2.82s\n",
      "918:\tlearn: 0.1414428\ttotal: 31.6s\tremaining: 2.79s\n",
      "919:\tlearn: 0.1413988\ttotal: 31.7s\tremaining: 2.75s\n",
      "920:\tlearn: 0.1412809\ttotal: 31.7s\tremaining: 2.72s\n",
      "921:\tlearn: 0.1411748\ttotal: 31.7s\tremaining: 2.69s\n",
      "922:\tlearn: 0.1411150\ttotal: 31.8s\tremaining: 2.65s\n",
      "923:\tlearn: 0.1410145\ttotal: 31.8s\tremaining: 2.62s\n",
      "924:\tlearn: 0.1408965\ttotal: 31.9s\tremaining: 2.58s\n",
      "925:\tlearn: 0.1408459\ttotal: 31.9s\tremaining: 2.55s\n",
      "926:\tlearn: 0.1407769\ttotal: 31.9s\tremaining: 2.51s\n",
      "927:\tlearn: 0.1407211\ttotal: 32s\tremaining: 2.48s\n",
      "928:\tlearn: 0.1405898\ttotal: 32s\tremaining: 2.44s\n",
      "929:\tlearn: 0.1405247\ttotal: 32s\tremaining: 2.41s\n",
      "930:\tlearn: 0.1404719\ttotal: 32.1s\tremaining: 2.38s\n",
      "931:\tlearn: 0.1403153\ttotal: 32.1s\tremaining: 2.34s\n",
      "932:\tlearn: 0.1401718\ttotal: 32.1s\tremaining: 2.31s\n",
      "933:\tlearn: 0.1400790\ttotal: 32.2s\tremaining: 2.27s\n",
      "934:\tlearn: 0.1400585\ttotal: 32.2s\tremaining: 2.24s\n",
      "935:\tlearn: 0.1398897\ttotal: 32.2s\tremaining: 2.21s\n",
      "936:\tlearn: 0.1397636\ttotal: 32.3s\tremaining: 2.17s\n",
      "937:\tlearn: 0.1396748\ttotal: 32.3s\tremaining: 2.14s\n",
      "938:\tlearn: 0.1395568\ttotal: 32.4s\tremaining: 2.1s\n",
      "939:\tlearn: 0.1394999\ttotal: 32.4s\tremaining: 2.07s\n",
      "940:\tlearn: 0.1393334\ttotal: 32.4s\tremaining: 2.03s\n",
      "941:\tlearn: 0.1392235\ttotal: 32.5s\tremaining: 2s\n",
      "942:\tlearn: 0.1391322\ttotal: 32.5s\tremaining: 1.96s\n",
      "943:\tlearn: 0.1390593\ttotal: 32.5s\tremaining: 1.93s\n",
      "944:\tlearn: 0.1390120\ttotal: 32.5s\tremaining: 1.89s\n",
      "945:\tlearn: 0.1388706\ttotal: 32.6s\tremaining: 1.86s\n",
      "946:\tlearn: 0.1387995\ttotal: 32.6s\tremaining: 1.82s\n",
      "947:\tlearn: 0.1387269\ttotal: 32.7s\tremaining: 1.79s\n",
      "948:\tlearn: 0.1385580\ttotal: 32.7s\tremaining: 1.76s\n",
      "949:\tlearn: 0.1384720\ttotal: 32.7s\tremaining: 1.72s\n",
      "950:\tlearn: 0.1383741\ttotal: 32.8s\tremaining: 1.69s\n",
      "951:\tlearn: 0.1381811\ttotal: 32.8s\tremaining: 1.65s\n",
      "952:\tlearn: 0.1381071\ttotal: 32.9s\tremaining: 1.62s\n",
      "953:\tlearn: 0.1380167\ttotal: 32.9s\tremaining: 1.58s\n",
      "954:\tlearn: 0.1379730\ttotal: 32.9s\tremaining: 1.55s\n",
      "955:\tlearn: 0.1378134\ttotal: 33s\tremaining: 1.52s\n",
      "956:\tlearn: 0.1377576\ttotal: 33s\tremaining: 1.48s\n",
      "957:\tlearn: 0.1376768\ttotal: 33s\tremaining: 1.45s\n",
      "958:\tlearn: 0.1376004\ttotal: 33s\tremaining: 1.41s\n",
      "959:\tlearn: 0.1375583\ttotal: 33.1s\tremaining: 1.38s\n",
      "960:\tlearn: 0.1374262\ttotal: 33.1s\tremaining: 1.34s\n",
      "961:\tlearn: 0.1373369\ttotal: 33.2s\tremaining: 1.31s\n",
      "962:\tlearn: 0.1372176\ttotal: 33.2s\tremaining: 1.27s\n",
      "963:\tlearn: 0.1371914\ttotal: 33.2s\tremaining: 1.24s\n",
      "964:\tlearn: 0.1371277\ttotal: 33.3s\tremaining: 1.21s\n",
      "965:\tlearn: 0.1370413\ttotal: 33.3s\tremaining: 1.17s\n",
      "966:\tlearn: 0.1369615\ttotal: 33.3s\tremaining: 1.14s\n",
      "967:\tlearn: 0.1368339\ttotal: 33.4s\tremaining: 1.1s\n",
      "968:\tlearn: 0.1367222\ttotal: 33.4s\tremaining: 1.07s\n",
      "969:\tlearn: 0.1366061\ttotal: 33.4s\tremaining: 1.03s\n",
      "970:\tlearn: 0.1365419\ttotal: 33.5s\tremaining: 1000ms\n",
      "971:\tlearn: 0.1364373\ttotal: 33.5s\tremaining: 965ms\n",
      "972:\tlearn: 0.1363259\ttotal: 33.6s\tremaining: 931ms\n",
      "973:\tlearn: 0.1362219\ttotal: 33.6s\tremaining: 897ms\n",
      "974:\tlearn: 0.1361790\ttotal: 33.6s\tremaining: 862ms\n",
      "975:\tlearn: 0.1361409\ttotal: 33.7s\tremaining: 828ms\n",
      "976:\tlearn: 0.1360562\ttotal: 33.7s\tremaining: 793ms\n",
      "977:\tlearn: 0.1360247\ttotal: 33.7s\tremaining: 759ms\n",
      "978:\tlearn: 0.1359609\ttotal: 33.8s\tremaining: 725ms\n",
      "979:\tlearn: 0.1358638\ttotal: 33.8s\tremaining: 690ms\n",
      "980:\tlearn: 0.1357703\ttotal: 33.9s\tremaining: 656ms\n",
      "981:\tlearn: 0.1356386\ttotal: 33.9s\tremaining: 621ms\n",
      "982:\tlearn: 0.1355566\ttotal: 33.9s\tremaining: 587ms\n",
      "983:\tlearn: 0.1353381\ttotal: 34s\tremaining: 552ms\n",
      "984:\tlearn: 0.1352593\ttotal: 34s\tremaining: 518ms\n",
      "985:\tlearn: 0.1352101\ttotal: 34s\tremaining: 483ms\n",
      "986:\tlearn: 0.1351735\ttotal: 34s\tremaining: 448ms\n",
      "987:\tlearn: 0.1350583\ttotal: 34.1s\tremaining: 414ms\n",
      "988:\tlearn: 0.1349965\ttotal: 34.1s\tremaining: 379ms\n",
      "989:\tlearn: 0.1349023\ttotal: 34.1s\tremaining: 345ms\n",
      "990:\tlearn: 0.1348761\ttotal: 34.2s\tremaining: 310ms\n",
      "991:\tlearn: 0.1347785\ttotal: 34.2s\tremaining: 276ms\n",
      "992:\tlearn: 0.1347051\ttotal: 34.3s\tremaining: 241ms\n",
      "993:\tlearn: 0.1346369\ttotal: 34.3s\tremaining: 207ms\n",
      "994:\tlearn: 0.1345065\ttotal: 34.3s\tremaining: 173ms\n",
      "995:\tlearn: 0.1344366\ttotal: 34.4s\tremaining: 138ms\n",
      "996:\tlearn: 0.1343374\ttotal: 34.4s\tremaining: 104ms\n",
      "997:\tlearn: 0.1342923\ttotal: 34.4s\tremaining: 69ms\n",
      "998:\tlearn: 0.1342419\ttotal: 34.5s\tremaining: 34.5ms\n",
      "999:\tlearn: 0.1341484\ttotal: 34.5s\tremaining: 0us\n",
      "Learning rate set to 0.09175\n",
      "0:\tlearn: 1.8254986\ttotal: 50.4ms\tremaining: 50.3s\n",
      "1:\tlearn: 1.6171357\ttotal: 97.4ms\tremaining: 48.6s\n",
      "2:\tlearn: 1.4564471\ttotal: 144ms\tremaining: 47.7s\n",
      "3:\tlearn: 1.3495183\ttotal: 185ms\tremaining: 46.1s\n",
      "4:\tlearn: 1.2570598\ttotal: 220ms\tremaining: 43.8s\n",
      "5:\tlearn: 1.1656859\ttotal: 256ms\tremaining: 42.5s\n",
      "6:\tlearn: 1.1060051\ttotal: 293ms\tremaining: 41.5s\n",
      "7:\tlearn: 1.0451800\ttotal: 331ms\tremaining: 41s\n",
      "8:\tlearn: 0.9861194\ttotal: 364ms\tremaining: 40s\n",
      "9:\tlearn: 0.9397384\ttotal: 394ms\tremaining: 39s\n",
      "10:\tlearn: 0.8966731\ttotal: 425ms\tremaining: 38.2s\n",
      "11:\tlearn: 0.8614806\ttotal: 460ms\tremaining: 37.8s\n",
      "12:\tlearn: 0.8290923\ttotal: 505ms\tremaining: 38.3s\n",
      "13:\tlearn: 0.7990625\ttotal: 552ms\tremaining: 38.9s\n",
      "14:\tlearn: 0.7765988\ttotal: 588ms\tremaining: 38.6s\n",
      "15:\tlearn: 0.7561342\ttotal: 627ms\tremaining: 38.6s\n",
      "16:\tlearn: 0.7295745\ttotal: 663ms\tremaining: 38.3s\n",
      "17:\tlearn: 0.7087840\ttotal: 698ms\tremaining: 38.1s\n",
      "18:\tlearn: 0.6925240\ttotal: 735ms\tremaining: 38s\n",
      "19:\tlearn: 0.6753160\ttotal: 769ms\tremaining: 37.7s\n",
      "20:\tlearn: 0.6586453\ttotal: 803ms\tremaining: 37.4s\n",
      "21:\tlearn: 0.6433284\ttotal: 833ms\tremaining: 37s\n",
      "22:\tlearn: 0.6276145\ttotal: 866ms\tremaining: 36.8s\n",
      "23:\tlearn: 0.6144354\ttotal: 898ms\tremaining: 36.5s\n",
      "24:\tlearn: 0.6026527\ttotal: 932ms\tremaining: 36.3s\n",
      "25:\tlearn: 0.5872484\ttotal: 984ms\tremaining: 36.9s\n",
      "26:\tlearn: 0.5757740\ttotal: 1.02s\tremaining: 36.8s\n",
      "27:\tlearn: 0.5659181\ttotal: 1.05s\tremaining: 36.5s\n",
      "28:\tlearn: 0.5577648\ttotal: 1.09s\tremaining: 36.4s\n",
      "29:\tlearn: 0.5476455\ttotal: 1.12s\tremaining: 36.2s\n",
      "30:\tlearn: 0.5387587\ttotal: 1.15s\tremaining: 36.1s\n",
      "31:\tlearn: 0.5297410\ttotal: 1.19s\tremaining: 36s\n",
      "32:\tlearn: 0.5245675\ttotal: 1.22s\tremaining: 35.8s\n",
      "33:\tlearn: 0.5191581\ttotal: 1.25s\tremaining: 35.6s\n",
      "34:\tlearn: 0.5130684\ttotal: 1.29s\tremaining: 35.5s\n",
      "35:\tlearn: 0.5066249\ttotal: 1.33s\tremaining: 35.7s\n",
      "36:\tlearn: 0.5014712\ttotal: 1.37s\tremaining: 35.7s\n",
      "37:\tlearn: 0.4952948\ttotal: 1.41s\tremaining: 35.8s\n",
      "38:\tlearn: 0.4897734\ttotal: 1.45s\tremaining: 35.7s\n",
      "39:\tlearn: 0.4858211\ttotal: 1.48s\tremaining: 35.5s\n",
      "40:\tlearn: 0.4809303\ttotal: 1.51s\tremaining: 35.4s\n",
      "41:\tlearn: 0.4751796\ttotal: 1.55s\tremaining: 35.5s\n",
      "42:\tlearn: 0.4696885\ttotal: 1.6s\tremaining: 35.6s\n",
      "43:\tlearn: 0.4655717\ttotal: 1.64s\tremaining: 35.6s\n",
      "44:\tlearn: 0.4635752\ttotal: 1.68s\tremaining: 35.6s\n",
      "45:\tlearn: 0.4581899\ttotal: 1.72s\tremaining: 35.6s\n",
      "46:\tlearn: 0.4526458\ttotal: 1.75s\tremaining: 35.5s\n",
      "47:\tlearn: 0.4485780\ttotal: 1.78s\tremaining: 35.3s\n",
      "48:\tlearn: 0.4437712\ttotal: 1.81s\tremaining: 35.2s\n",
      "49:\tlearn: 0.4385776\ttotal: 1.86s\tremaining: 35.3s\n",
      "50:\tlearn: 0.4351738\ttotal: 1.9s\tremaining: 35.3s\n",
      "51:\tlearn: 0.4321983\ttotal: 1.94s\tremaining: 35.4s\n",
      "52:\tlearn: 0.4283130\ttotal: 1.97s\tremaining: 35.2s\n",
      "53:\tlearn: 0.4263836\ttotal: 2s\tremaining: 35.1s\n",
      "54:\tlearn: 0.4224437\ttotal: 2.04s\tremaining: 35.1s\n",
      "55:\tlearn: 0.4190313\ttotal: 2.08s\tremaining: 35.1s\n",
      "56:\tlearn: 0.4160236\ttotal: 2.12s\tremaining: 35s\n",
      "57:\tlearn: 0.4118533\ttotal: 2.15s\tremaining: 34.9s\n",
      "58:\tlearn: 0.4094143\ttotal: 2.18s\tremaining: 34.8s\n",
      "59:\tlearn: 0.4069101\ttotal: 2.24s\tremaining: 35.1s\n",
      "60:\tlearn: 0.4037734\ttotal: 2.28s\tremaining: 35s\n",
      "61:\tlearn: 0.4008916\ttotal: 2.31s\tremaining: 34.9s\n",
      "62:\tlearn: 0.3992164\ttotal: 2.35s\tremaining: 35s\n",
      "63:\tlearn: 0.3970554\ttotal: 2.39s\tremaining: 34.9s\n",
      "64:\tlearn: 0.3955558\ttotal: 2.42s\tremaining: 34.9s\n",
      "65:\tlearn: 0.3938030\ttotal: 2.46s\tremaining: 34.9s\n",
      "66:\tlearn: 0.3910411\ttotal: 2.51s\tremaining: 34.9s\n",
      "67:\tlearn: 0.3877505\ttotal: 2.55s\tremaining: 34.9s\n",
      "68:\tlearn: 0.3850412\ttotal: 2.59s\tremaining: 34.9s\n",
      "69:\tlearn: 0.3826578\ttotal: 2.62s\tremaining: 34.8s\n",
      "70:\tlearn: 0.3800685\ttotal: 2.66s\tremaining: 34.8s\n",
      "71:\tlearn: 0.3786065\ttotal: 2.69s\tremaining: 34.6s\n",
      "72:\tlearn: 0.3770481\ttotal: 2.72s\tremaining: 34.5s\n",
      "73:\tlearn: 0.3756785\ttotal: 2.75s\tremaining: 34.5s\n",
      "74:\tlearn: 0.3741131\ttotal: 2.81s\tremaining: 34.6s\n",
      "75:\tlearn: 0.3726953\ttotal: 2.84s\tremaining: 34.5s\n",
      "76:\tlearn: 0.3711255\ttotal: 2.87s\tremaining: 34.4s\n",
      "77:\tlearn: 0.3691661\ttotal: 2.91s\tremaining: 34.4s\n",
      "78:\tlearn: 0.3672153\ttotal: 2.94s\tremaining: 34.3s\n",
      "79:\tlearn: 0.3655055\ttotal: 2.97s\tremaining: 34.2s\n",
      "80:\tlearn: 0.3639952\ttotal: 3.01s\tremaining: 34.1s\n",
      "81:\tlearn: 0.3630519\ttotal: 3.04s\tremaining: 34s\n",
      "82:\tlearn: 0.3612554\ttotal: 3.07s\tremaining: 33.9s\n",
      "83:\tlearn: 0.3596809\ttotal: 3.11s\tremaining: 34s\n",
      "84:\tlearn: 0.3582305\ttotal: 3.16s\tremaining: 34s\n",
      "85:\tlearn: 0.3571019\ttotal: 3.19s\tremaining: 34s\n",
      "86:\tlearn: 0.3553416\ttotal: 3.23s\tremaining: 33.9s\n",
      "87:\tlearn: 0.3536360\ttotal: 3.27s\tremaining: 33.9s\n",
      "88:\tlearn: 0.3530943\ttotal: 3.3s\tremaining: 33.8s\n",
      "89:\tlearn: 0.3519004\ttotal: 3.33s\tremaining: 33.7s\n",
      "90:\tlearn: 0.3491417\ttotal: 3.36s\tremaining: 33.6s\n",
      "91:\tlearn: 0.3472492\ttotal: 3.41s\tremaining: 33.6s\n",
      "92:\tlearn: 0.3459169\ttotal: 3.45s\tremaining: 33.7s\n",
      "93:\tlearn: 0.3439314\ttotal: 3.5s\tremaining: 33.7s\n",
      "94:\tlearn: 0.3417847\ttotal: 3.53s\tremaining: 33.7s\n",
      "95:\tlearn: 0.3402237\ttotal: 3.57s\tremaining: 33.6s\n",
      "96:\tlearn: 0.3393773\ttotal: 3.61s\tremaining: 33.6s\n",
      "97:\tlearn: 0.3380723\ttotal: 3.65s\tremaining: 33.6s\n",
      "98:\tlearn: 0.3367353\ttotal: 3.7s\tremaining: 33.7s\n",
      "99:\tlearn: 0.3349523\ttotal: 3.73s\tremaining: 33.6s\n",
      "100:\tlearn: 0.3339691\ttotal: 3.77s\tremaining: 33.5s\n",
      "101:\tlearn: 0.3332739\ttotal: 3.8s\tremaining: 33.5s\n",
      "102:\tlearn: 0.3320880\ttotal: 3.86s\tremaining: 33.6s\n",
      "103:\tlearn: 0.3308547\ttotal: 3.9s\tremaining: 33.6s\n",
      "104:\tlearn: 0.3297688\ttotal: 3.93s\tremaining: 33.5s\n",
      "105:\tlearn: 0.3285979\ttotal: 3.97s\tremaining: 33.5s\n",
      "106:\tlearn: 0.3279677\ttotal: 4s\tremaining: 33.4s\n",
      "107:\tlearn: 0.3274597\ttotal: 4.03s\tremaining: 33.3s\n",
      "108:\tlearn: 0.3269323\ttotal: 4.06s\tremaining: 33.2s\n",
      "109:\tlearn: 0.3259910\ttotal: 4.11s\tremaining: 33.2s\n",
      "110:\tlearn: 0.3256497\ttotal: 4.15s\tremaining: 33.3s\n",
      "111:\tlearn: 0.3245509\ttotal: 4.19s\tremaining: 33.2s\n",
      "112:\tlearn: 0.3233522\ttotal: 4.22s\tremaining: 33.1s\n",
      "113:\tlearn: 0.3227655\ttotal: 4.25s\tremaining: 33s\n",
      "114:\tlearn: 0.3217194\ttotal: 4.28s\tremaining: 33s\n",
      "115:\tlearn: 0.3207241\ttotal: 4.32s\tremaining: 32.9s\n",
      "116:\tlearn: 0.3193248\ttotal: 4.36s\tremaining: 32.9s\n",
      "117:\tlearn: 0.3180817\ttotal: 4.4s\tremaining: 32.9s\n",
      "118:\tlearn: 0.3175359\ttotal: 4.44s\tremaining: 32.9s\n",
      "119:\tlearn: 0.3161884\ttotal: 4.47s\tremaining: 32.8s\n",
      "120:\tlearn: 0.3157184\ttotal: 4.51s\tremaining: 32.7s\n",
      "121:\tlearn: 0.3147965\ttotal: 4.55s\tremaining: 32.7s\n",
      "122:\tlearn: 0.3144691\ttotal: 4.58s\tremaining: 32.6s\n",
      "123:\tlearn: 0.3135273\ttotal: 4.61s\tremaining: 32.5s\n",
      "124:\tlearn: 0.3130415\ttotal: 4.64s\tremaining: 32.5s\n",
      "125:\tlearn: 0.3126063\ttotal: 4.67s\tremaining: 32.4s\n",
      "126:\tlearn: 0.3117624\ttotal: 4.7s\tremaining: 32.3s\n",
      "127:\tlearn: 0.3110742\ttotal: 4.73s\tremaining: 32.2s\n",
      "128:\tlearn: 0.3102861\ttotal: 4.78s\tremaining: 32.3s\n",
      "129:\tlearn: 0.3098521\ttotal: 4.82s\tremaining: 32.2s\n",
      "130:\tlearn: 0.3095514\ttotal: 4.84s\tremaining: 32.1s\n",
      "131:\tlearn: 0.3088258\ttotal: 4.88s\tremaining: 32.1s\n",
      "132:\tlearn: 0.3085476\ttotal: 4.92s\tremaining: 32.1s\n",
      "133:\tlearn: 0.3078281\ttotal: 4.95s\tremaining: 32s\n",
      "134:\tlearn: 0.3073887\ttotal: 4.98s\tremaining: 31.9s\n",
      "135:\tlearn: 0.3058631\ttotal: 5.02s\tremaining: 31.9s\n",
      "136:\tlearn: 0.3045407\ttotal: 5.06s\tremaining: 31.9s\n",
      "137:\tlearn: 0.3041430\ttotal: 5.1s\tremaining: 31.9s\n",
      "138:\tlearn: 0.3032249\ttotal: 5.14s\tremaining: 31.8s\n",
      "139:\tlearn: 0.3022979\ttotal: 5.17s\tremaining: 31.8s\n",
      "140:\tlearn: 0.3019468\ttotal: 5.21s\tremaining: 31.7s\n",
      "141:\tlearn: 0.3016662\ttotal: 5.24s\tremaining: 31.7s\n",
      "142:\tlearn: 0.3007845\ttotal: 5.27s\tremaining: 31.6s\n",
      "143:\tlearn: 0.3000642\ttotal: 5.32s\tremaining: 31.6s\n",
      "144:\tlearn: 0.2994825\ttotal: 5.35s\tremaining: 31.6s\n",
      "145:\tlearn: 0.2990783\ttotal: 5.39s\tremaining: 31.5s\n",
      "146:\tlearn: 0.2982133\ttotal: 5.43s\tremaining: 31.5s\n",
      "147:\tlearn: 0.2978748\ttotal: 5.46s\tremaining: 31.4s\n",
      "148:\tlearn: 0.2970689\ttotal: 5.5s\tremaining: 31.4s\n",
      "149:\tlearn: 0.2960782\ttotal: 5.54s\tremaining: 31.4s\n",
      "150:\tlearn: 0.2957832\ttotal: 5.59s\tremaining: 31.4s\n",
      "151:\tlearn: 0.2948551\ttotal: 5.62s\tremaining: 31.3s\n",
      "152:\tlearn: 0.2942818\ttotal: 5.65s\tremaining: 31.3s\n",
      "153:\tlearn: 0.2933388\ttotal: 5.68s\tremaining: 31.2s\n",
      "154:\tlearn: 0.2925073\ttotal: 5.72s\tremaining: 31.2s\n",
      "155:\tlearn: 0.2917721\ttotal: 5.75s\tremaining: 31.1s\n",
      "156:\tlearn: 0.2910906\ttotal: 5.78s\tremaining: 31.1s\n",
      "157:\tlearn: 0.2906959\ttotal: 5.82s\tremaining: 31s\n",
      "158:\tlearn: 0.2898066\ttotal: 5.85s\tremaining: 30.9s\n",
      "159:\tlearn: 0.2893152\ttotal: 5.89s\tremaining: 30.9s\n",
      "160:\tlearn: 0.2890457\ttotal: 5.94s\tremaining: 31s\n",
      "161:\tlearn: 0.2884275\ttotal: 5.98s\tremaining: 30.9s\n",
      "162:\tlearn: 0.2878278\ttotal: 6.01s\tremaining: 30.9s\n",
      "163:\tlearn: 0.2873831\ttotal: 6.05s\tremaining: 30.9s\n",
      "164:\tlearn: 0.2870641\ttotal: 6.09s\tremaining: 30.8s\n",
      "165:\tlearn: 0.2864367\ttotal: 6.12s\tremaining: 30.7s\n",
      "166:\tlearn: 0.2858907\ttotal: 6.15s\tremaining: 30.7s\n",
      "167:\tlearn: 0.2851760\ttotal: 6.19s\tremaining: 30.7s\n",
      "168:\tlearn: 0.2849982\ttotal: 6.23s\tremaining: 30.7s\n",
      "169:\tlearn: 0.2845535\ttotal: 6.27s\tremaining: 30.6s\n",
      "170:\tlearn: 0.2843627\ttotal: 6.3s\tremaining: 30.5s\n",
      "171:\tlearn: 0.2839771\ttotal: 6.33s\tremaining: 30.5s\n",
      "172:\tlearn: 0.2837750\ttotal: 6.37s\tremaining: 30.4s\n",
      "173:\tlearn: 0.2828194\ttotal: 6.4s\tremaining: 30.4s\n",
      "174:\tlearn: 0.2824885\ttotal: 6.44s\tremaining: 30.3s\n",
      "175:\tlearn: 0.2817630\ttotal: 6.47s\tremaining: 30.3s\n",
      "176:\tlearn: 0.2812848\ttotal: 6.51s\tremaining: 30.3s\n",
      "177:\tlearn: 0.2810854\ttotal: 6.55s\tremaining: 30.2s\n",
      "178:\tlearn: 0.2807498\ttotal: 6.59s\tremaining: 30.2s\n",
      "179:\tlearn: 0.2801386\ttotal: 6.63s\tremaining: 30.2s\n",
      "180:\tlearn: 0.2798936\ttotal: 6.67s\tremaining: 30.2s\n",
      "181:\tlearn: 0.2789524\ttotal: 6.71s\tremaining: 30.2s\n",
      "182:\tlearn: 0.2782841\ttotal: 6.74s\tremaining: 30.1s\n",
      "183:\tlearn: 0.2778694\ttotal: 6.77s\tremaining: 30s\n",
      "184:\tlearn: 0.2777392\ttotal: 6.81s\tremaining: 30s\n",
      "185:\tlearn: 0.2773780\ttotal: 6.85s\tremaining: 30s\n",
      "186:\tlearn: 0.2770138\ttotal: 6.89s\tremaining: 30s\n",
      "187:\tlearn: 0.2768644\ttotal: 6.92s\tremaining: 29.9s\n",
      "188:\tlearn: 0.2760150\ttotal: 6.95s\tremaining: 29.8s\n",
      "189:\tlearn: 0.2757553\ttotal: 6.99s\tremaining: 29.8s\n",
      "190:\tlearn: 0.2754806\ttotal: 7.02s\tremaining: 29.7s\n",
      "191:\tlearn: 0.2752834\ttotal: 7.05s\tremaining: 29.7s\n",
      "192:\tlearn: 0.2745463\ttotal: 7.09s\tremaining: 29.6s\n",
      "193:\tlearn: 0.2742101\ttotal: 7.12s\tremaining: 29.6s\n",
      "194:\tlearn: 0.2739931\ttotal: 7.15s\tremaining: 29.5s\n",
      "195:\tlearn: 0.2735299\ttotal: 7.18s\tremaining: 29.5s\n",
      "196:\tlearn: 0.2730945\ttotal: 7.23s\tremaining: 29.5s\n",
      "197:\tlearn: 0.2728339\ttotal: 7.27s\tremaining: 29.5s\n",
      "198:\tlearn: 0.2719227\ttotal: 7.3s\tremaining: 29.4s\n",
      "199:\tlearn: 0.2709973\ttotal: 7.34s\tremaining: 29.4s\n",
      "200:\tlearn: 0.2705897\ttotal: 7.38s\tremaining: 29.3s\n",
      "201:\tlearn: 0.2700127\ttotal: 7.42s\tremaining: 29.3s\n",
      "202:\tlearn: 0.2697487\ttotal: 7.45s\tremaining: 29.3s\n",
      "203:\tlearn: 0.2691549\ttotal: 7.48s\tremaining: 29.2s\n",
      "204:\tlearn: 0.2689907\ttotal: 7.52s\tremaining: 29.2s\n",
      "205:\tlearn: 0.2688606\ttotal: 7.57s\tremaining: 29.2s\n",
      "206:\tlearn: 0.2683802\ttotal: 7.61s\tremaining: 29.1s\n",
      "207:\tlearn: 0.2680550\ttotal: 7.64s\tremaining: 29.1s\n",
      "208:\tlearn: 0.2678630\ttotal: 7.67s\tremaining: 29s\n",
      "209:\tlearn: 0.2674660\ttotal: 7.7s\tremaining: 29s\n",
      "210:\tlearn: 0.2669882\ttotal: 7.75s\tremaining: 29s\n",
      "211:\tlearn: 0.2665637\ttotal: 7.79s\tremaining: 29s\n",
      "212:\tlearn: 0.2663012\ttotal: 7.82s\tremaining: 28.9s\n",
      "213:\tlearn: 0.2658881\ttotal: 7.86s\tremaining: 28.9s\n",
      "214:\tlearn: 0.2656662\ttotal: 7.89s\tremaining: 28.8s\n",
      "215:\tlearn: 0.2654948\ttotal: 7.93s\tremaining: 28.8s\n",
      "216:\tlearn: 0.2651473\ttotal: 7.96s\tremaining: 28.7s\n",
      "217:\tlearn: 0.2647880\ttotal: 7.99s\tremaining: 28.7s\n",
      "218:\tlearn: 0.2645512\ttotal: 8.02s\tremaining: 28.6s\n",
      "219:\tlearn: 0.2641023\ttotal: 8.05s\tremaining: 28.5s\n",
      "220:\tlearn: 0.2638179\ttotal: 8.08s\tremaining: 28.5s\n",
      "221:\tlearn: 0.2633188\ttotal: 8.13s\tremaining: 28.5s\n",
      "222:\tlearn: 0.2631118\ttotal: 8.17s\tremaining: 28.5s\n",
      "223:\tlearn: 0.2624971\ttotal: 8.21s\tremaining: 28.4s\n",
      "224:\tlearn: 0.2622984\ttotal: 8.24s\tremaining: 28.4s\n",
      "225:\tlearn: 0.2619963\ttotal: 8.27s\tremaining: 28.3s\n",
      "226:\tlearn: 0.2615322\ttotal: 8.3s\tremaining: 28.3s\n",
      "227:\tlearn: 0.2609398\ttotal: 8.34s\tremaining: 28.2s\n",
      "228:\tlearn: 0.2602896\ttotal: 8.39s\tremaining: 28.2s\n",
      "229:\tlearn: 0.2597204\ttotal: 8.42s\tremaining: 28.2s\n",
      "230:\tlearn: 0.2593656\ttotal: 8.46s\tremaining: 28.2s\n",
      "231:\tlearn: 0.2590292\ttotal: 8.5s\tremaining: 28.1s\n",
      "232:\tlearn: 0.2582345\ttotal: 8.53s\tremaining: 28.1s\n",
      "233:\tlearn: 0.2580800\ttotal: 8.56s\tremaining: 28s\n",
      "234:\tlearn: 0.2577501\ttotal: 8.6s\tremaining: 28s\n",
      "235:\tlearn: 0.2570395\ttotal: 8.63s\tremaining: 28s\n",
      "236:\tlearn: 0.2568182\ttotal: 8.68s\tremaining: 27.9s\n",
      "237:\tlearn: 0.2565679\ttotal: 8.72s\tremaining: 27.9s\n",
      "238:\tlearn: 0.2563746\ttotal: 8.75s\tremaining: 27.9s\n",
      "239:\tlearn: 0.2560609\ttotal: 8.78s\tremaining: 27.8s\n",
      "240:\tlearn: 0.2554946\ttotal: 8.82s\tremaining: 27.8s\n",
      "241:\tlearn: 0.2550959\ttotal: 8.85s\tremaining: 27.7s\n",
      "242:\tlearn: 0.2548178\ttotal: 8.89s\tremaining: 27.7s\n",
      "243:\tlearn: 0.2543805\ttotal: 8.92s\tremaining: 27.6s\n",
      "244:\tlearn: 0.2541234\ttotal: 8.95s\tremaining: 27.6s\n",
      "245:\tlearn: 0.2538584\ttotal: 8.98s\tremaining: 27.5s\n",
      "246:\tlearn: 0.2536852\ttotal: 9.02s\tremaining: 27.5s\n",
      "247:\tlearn: 0.2534552\ttotal: 9.07s\tremaining: 27.5s\n",
      "248:\tlearn: 0.2529563\ttotal: 9.11s\tremaining: 27.5s\n",
      "249:\tlearn: 0.2527582\ttotal: 9.14s\tremaining: 27.4s\n",
      "250:\tlearn: 0.2523966\ttotal: 9.18s\tremaining: 27.4s\n",
      "251:\tlearn: 0.2522641\ttotal: 9.21s\tremaining: 27.3s\n",
      "252:\tlearn: 0.2520166\ttotal: 9.24s\tremaining: 27.3s\n",
      "253:\tlearn: 0.2518517\ttotal: 9.28s\tremaining: 27.3s\n",
      "254:\tlearn: 0.2513532\ttotal: 9.32s\tremaining: 27.2s\n",
      "255:\tlearn: 0.2506616\ttotal: 9.36s\tremaining: 27.2s\n",
      "256:\tlearn: 0.2502724\ttotal: 9.39s\tremaining: 27.2s\n",
      "257:\tlearn: 0.2500892\ttotal: 9.42s\tremaining: 27.1s\n",
      "258:\tlearn: 0.2494962\ttotal: 9.46s\tremaining: 27.1s\n",
      "259:\tlearn: 0.2492915\ttotal: 9.49s\tremaining: 27s\n",
      "260:\tlearn: 0.2490832\ttotal: 9.53s\tremaining: 27s\n",
      "261:\tlearn: 0.2489258\ttotal: 9.56s\tremaining: 26.9s\n",
      "262:\tlearn: 0.2482571\ttotal: 9.6s\tremaining: 26.9s\n",
      "263:\tlearn: 0.2477316\ttotal: 9.63s\tremaining: 26.9s\n",
      "264:\tlearn: 0.2476322\ttotal: 9.68s\tremaining: 26.8s\n",
      "265:\tlearn: 0.2474155\ttotal: 9.72s\tremaining: 26.8s\n",
      "266:\tlearn: 0.2470447\ttotal: 9.75s\tremaining: 26.8s\n",
      "267:\tlearn: 0.2467275\ttotal: 9.78s\tremaining: 26.7s\n",
      "268:\tlearn: 0.2464314\ttotal: 9.82s\tremaining: 26.7s\n",
      "269:\tlearn: 0.2462785\ttotal: 9.86s\tremaining: 26.7s\n",
      "270:\tlearn: 0.2457434\ttotal: 9.89s\tremaining: 26.6s\n",
      "271:\tlearn: 0.2453275\ttotal: 9.92s\tremaining: 26.6s\n",
      "272:\tlearn: 0.2450799\ttotal: 9.96s\tremaining: 26.5s\n",
      "273:\tlearn: 0.2447908\ttotal: 10s\tremaining: 26.5s\n",
      "274:\tlearn: 0.2442392\ttotal: 10.1s\tremaining: 26.5s\n",
      "275:\tlearn: 0.2438909\ttotal: 10.1s\tremaining: 26.4s\n",
      "276:\tlearn: 0.2436676\ttotal: 10.1s\tremaining: 26.4s\n",
      "277:\tlearn: 0.2435171\ttotal: 10.1s\tremaining: 26.4s\n",
      "278:\tlearn: 0.2430207\ttotal: 10.2s\tremaining: 26.3s\n",
      "279:\tlearn: 0.2425465\ttotal: 10.2s\tremaining: 26.3s\n",
      "280:\tlearn: 0.2423894\ttotal: 10.3s\tremaining: 26.2s\n",
      "281:\tlearn: 0.2420100\ttotal: 10.3s\tremaining: 26.2s\n",
      "282:\tlearn: 0.2416418\ttotal: 10.3s\tremaining: 26.2s\n",
      "283:\tlearn: 0.2412296\ttotal: 10.4s\tremaining: 26.2s\n",
      "284:\tlearn: 0.2409227\ttotal: 10.4s\tremaining: 26.1s\n",
      "285:\tlearn: 0.2403950\ttotal: 10.4s\tremaining: 26.1s\n",
      "286:\tlearn: 0.2402692\ttotal: 10.5s\tremaining: 26s\n",
      "287:\tlearn: 0.2396394\ttotal: 10.5s\tremaining: 26s\n",
      "288:\tlearn: 0.2393234\ttotal: 10.6s\tremaining: 26s\n",
      "289:\tlearn: 0.2390801\ttotal: 10.6s\tremaining: 25.9s\n",
      "290:\tlearn: 0.2386747\ttotal: 10.6s\tremaining: 25.9s\n",
      "291:\tlearn: 0.2384422\ttotal: 10.7s\tremaining: 25.9s\n",
      "292:\tlearn: 0.2382851\ttotal: 10.7s\tremaining: 25.8s\n",
      "293:\tlearn: 0.2380673\ttotal: 10.7s\tremaining: 25.8s\n",
      "294:\tlearn: 0.2377007\ttotal: 10.8s\tremaining: 25.7s\n",
      "295:\tlearn: 0.2375167\ttotal: 10.8s\tremaining: 25.7s\n",
      "296:\tlearn: 0.2374198\ttotal: 10.8s\tremaining: 25.6s\n",
      "297:\tlearn: 0.2372674\ttotal: 10.9s\tremaining: 25.6s\n",
      "298:\tlearn: 0.2370497\ttotal: 10.9s\tremaining: 25.6s\n",
      "299:\tlearn: 0.2369178\ttotal: 10.9s\tremaining: 25.5s\n",
      "300:\tlearn: 0.2366494\ttotal: 11s\tremaining: 25.5s\n",
      "301:\tlearn: 0.2362371\ttotal: 11s\tremaining: 25.4s\n",
      "302:\tlearn: 0.2361198\ttotal: 11s\tremaining: 25.4s\n",
      "303:\tlearn: 0.2357814\ttotal: 11.1s\tremaining: 25.4s\n",
      "304:\tlearn: 0.2353852\ttotal: 11.1s\tremaining: 25.3s\n",
      "305:\tlearn: 0.2349456\ttotal: 11.2s\tremaining: 25.3s\n",
      "306:\tlearn: 0.2348669\ttotal: 11.2s\tremaining: 25.2s\n",
      "307:\tlearn: 0.2345468\ttotal: 11.2s\tremaining: 25.2s\n",
      "308:\tlearn: 0.2343263\ttotal: 11.3s\tremaining: 25.2s\n",
      "309:\tlearn: 0.2340877\ttotal: 11.3s\tremaining: 25.1s\n",
      "310:\tlearn: 0.2340165\ttotal: 11.3s\tremaining: 25.1s\n",
      "311:\tlearn: 0.2336540\ttotal: 11.4s\tremaining: 25s\n",
      "312:\tlearn: 0.2333613\ttotal: 11.4s\tremaining: 25s\n",
      "313:\tlearn: 0.2331733\ttotal: 11.4s\tremaining: 25s\n",
      "314:\tlearn: 0.2328638\ttotal: 11.5s\tremaining: 24.9s\n",
      "315:\tlearn: 0.2324382\ttotal: 11.5s\tremaining: 24.9s\n",
      "316:\tlearn: 0.2320470\ttotal: 11.5s\tremaining: 24.9s\n",
      "317:\tlearn: 0.2318347\ttotal: 11.6s\tremaining: 24.8s\n",
      "318:\tlearn: 0.2316926\ttotal: 11.6s\tremaining: 24.8s\n",
      "319:\tlearn: 0.2315518\ttotal: 11.6s\tremaining: 24.8s\n",
      "320:\tlearn: 0.2312438\ttotal: 11.7s\tremaining: 24.7s\n",
      "321:\tlearn: 0.2307658\ttotal: 11.7s\tremaining: 24.7s\n",
      "322:\tlearn: 0.2304314\ttotal: 11.8s\tremaining: 24.7s\n",
      "323:\tlearn: 0.2301577\ttotal: 11.8s\tremaining: 24.6s\n",
      "324:\tlearn: 0.2298941\ttotal: 11.8s\tremaining: 24.6s\n",
      "325:\tlearn: 0.2294367\ttotal: 11.9s\tremaining: 24.5s\n",
      "326:\tlearn: 0.2292817\ttotal: 11.9s\tremaining: 24.5s\n",
      "327:\tlearn: 0.2290784\ttotal: 11.9s\tremaining: 24.4s\n",
      "328:\tlearn: 0.2288798\ttotal: 12s\tremaining: 24.4s\n",
      "329:\tlearn: 0.2286932\ttotal: 12s\tremaining: 24.4s\n",
      "330:\tlearn: 0.2283226\ttotal: 12s\tremaining: 24.3s\n",
      "331:\tlearn: 0.2280167\ttotal: 12.1s\tremaining: 24.3s\n",
      "332:\tlearn: 0.2278164\ttotal: 12.1s\tremaining: 24.3s\n",
      "333:\tlearn: 0.2275583\ttotal: 12.2s\tremaining: 24.3s\n",
      "334:\tlearn: 0.2272905\ttotal: 12.2s\tremaining: 24.2s\n",
      "335:\tlearn: 0.2271775\ttotal: 12.2s\tremaining: 24.2s\n",
      "336:\tlearn: 0.2270148\ttotal: 12.3s\tremaining: 24.1s\n",
      "337:\tlearn: 0.2266859\ttotal: 12.3s\tremaining: 24.1s\n",
      "338:\tlearn: 0.2261255\ttotal: 12.3s\tremaining: 24s\n",
      "339:\tlearn: 0.2258951\ttotal: 12.4s\tremaining: 24s\n",
      "340:\tlearn: 0.2255493\ttotal: 12.4s\tremaining: 24s\n",
      "341:\tlearn: 0.2251478\ttotal: 12.4s\tremaining: 23.9s\n",
      "342:\tlearn: 0.2250245\ttotal: 12.5s\tremaining: 23.9s\n",
      "343:\tlearn: 0.2248879\ttotal: 12.5s\tremaining: 23.8s\n",
      "344:\tlearn: 0.2246274\ttotal: 12.6s\tremaining: 23.8s\n",
      "345:\tlearn: 0.2244545\ttotal: 12.6s\tremaining: 23.8s\n",
      "346:\tlearn: 0.2242960\ttotal: 12.6s\tremaining: 23.7s\n",
      "347:\tlearn: 0.2240213\ttotal: 12.6s\tremaining: 23.7s\n",
      "348:\tlearn: 0.2238057\ttotal: 12.7s\tremaining: 23.6s\n",
      "349:\tlearn: 0.2236507\ttotal: 12.7s\tremaining: 23.6s\n",
      "350:\tlearn: 0.2235121\ttotal: 12.7s\tremaining: 23.6s\n",
      "351:\tlearn: 0.2232950\ttotal: 12.8s\tremaining: 23.5s\n",
      "352:\tlearn: 0.2230059\ttotal: 12.8s\tremaining: 23.5s\n",
      "353:\tlearn: 0.2224781\ttotal: 12.8s\tremaining: 23.4s\n",
      "354:\tlearn: 0.2221300\ttotal: 12.9s\tremaining: 23.4s\n",
      "355:\tlearn: 0.2218583\ttotal: 12.9s\tremaining: 23.3s\n",
      "356:\tlearn: 0.2216634\ttotal: 12.9s\tremaining: 23.3s\n",
      "357:\tlearn: 0.2214417\ttotal: 13s\tremaining: 23.3s\n",
      "358:\tlearn: 0.2211130\ttotal: 13s\tremaining: 23.2s\n",
      "359:\tlearn: 0.2208046\ttotal: 13s\tremaining: 23.2s\n",
      "360:\tlearn: 0.2203912\ttotal: 13.1s\tremaining: 23.1s\n",
      "361:\tlearn: 0.2202932\ttotal: 13.1s\tremaining: 23.1s\n",
      "362:\tlearn: 0.2198825\ttotal: 13.2s\tremaining: 23.1s\n",
      "363:\tlearn: 0.2196264\ttotal: 13.2s\tremaining: 23s\n",
      "364:\tlearn: 0.2193865\ttotal: 13.2s\tremaining: 23s\n",
      "365:\tlearn: 0.2192681\ttotal: 13.3s\tremaining: 23s\n",
      "366:\tlearn: 0.2190613\ttotal: 13.3s\tremaining: 22.9s\n",
      "367:\tlearn: 0.2188851\ttotal: 13.3s\tremaining: 22.9s\n",
      "368:\tlearn: 0.2187137\ttotal: 13.4s\tremaining: 22.8s\n",
      "369:\tlearn: 0.2183592\ttotal: 13.4s\tremaining: 22.8s\n",
      "370:\tlearn: 0.2180177\ttotal: 13.4s\tremaining: 22.8s\n",
      "371:\tlearn: 0.2178596\ttotal: 13.5s\tremaining: 22.7s\n",
      "372:\tlearn: 0.2176176\ttotal: 13.5s\tremaining: 22.7s\n",
      "373:\tlearn: 0.2174081\ttotal: 13.5s\tremaining: 22.7s\n",
      "374:\tlearn: 0.2172975\ttotal: 13.6s\tremaining: 22.6s\n",
      "375:\tlearn: 0.2169612\ttotal: 13.6s\tremaining: 22.6s\n",
      "376:\tlearn: 0.2167431\ttotal: 13.6s\tremaining: 22.6s\n",
      "377:\tlearn: 0.2165860\ttotal: 13.7s\tremaining: 22.5s\n",
      "378:\tlearn: 0.2162289\ttotal: 13.7s\tremaining: 22.5s\n",
      "379:\tlearn: 0.2159788\ttotal: 13.8s\tremaining: 22.4s\n",
      "380:\tlearn: 0.2157076\ttotal: 13.8s\tremaining: 22.4s\n",
      "381:\tlearn: 0.2154784\ttotal: 13.8s\tremaining: 22.4s\n",
      "382:\tlearn: 0.2153468\ttotal: 13.9s\tremaining: 22.4s\n",
      "383:\tlearn: 0.2149872\ttotal: 13.9s\tremaining: 22.3s\n",
      "384:\tlearn: 0.2148273\ttotal: 13.9s\tremaining: 22.3s\n",
      "385:\tlearn: 0.2145927\ttotal: 14s\tremaining: 22.2s\n",
      "386:\tlearn: 0.2145361\ttotal: 14s\tremaining: 22.2s\n",
      "387:\tlearn: 0.2144419\ttotal: 14.1s\tremaining: 22.2s\n",
      "388:\tlearn: 0.2143667\ttotal: 14.1s\tremaining: 22.1s\n",
      "389:\tlearn: 0.2138941\ttotal: 14.1s\tremaining: 22.1s\n",
      "390:\tlearn: 0.2137575\ttotal: 14.2s\tremaining: 22.1s\n",
      "391:\tlearn: 0.2134171\ttotal: 14.2s\tremaining: 22s\n",
      "392:\tlearn: 0.2130533\ttotal: 14.2s\tremaining: 22s\n",
      "393:\tlearn: 0.2128401\ttotal: 14.3s\tremaining: 21.9s\n",
      "394:\tlearn: 0.2127322\ttotal: 14.3s\tremaining: 21.9s\n",
      "395:\tlearn: 0.2124474\ttotal: 14.3s\tremaining: 21.9s\n",
      "396:\tlearn: 0.2120858\ttotal: 14.4s\tremaining: 21.8s\n",
      "397:\tlearn: 0.2118630\ttotal: 14.4s\tremaining: 21.8s\n",
      "398:\tlearn: 0.2116555\ttotal: 14.5s\tremaining: 21.8s\n",
      "399:\tlearn: 0.2114851\ttotal: 14.5s\tremaining: 21.7s\n",
      "400:\tlearn: 0.2111576\ttotal: 14.5s\tremaining: 21.7s\n",
      "401:\tlearn: 0.2110099\ttotal: 14.6s\tremaining: 21.7s\n",
      "402:\tlearn: 0.2106694\ttotal: 14.6s\tremaining: 21.6s\n",
      "403:\tlearn: 0.2103550\ttotal: 14.6s\tremaining: 21.6s\n",
      "404:\tlearn: 0.2102848\ttotal: 14.7s\tremaining: 21.5s\n",
      "405:\tlearn: 0.2100091\ttotal: 14.7s\tremaining: 21.5s\n",
      "406:\tlearn: 0.2099184\ttotal: 14.7s\tremaining: 21.4s\n",
      "407:\tlearn: 0.2098418\ttotal: 14.8s\tremaining: 21.4s\n",
      "408:\tlearn: 0.2093583\ttotal: 14.8s\tremaining: 21.4s\n",
      "409:\tlearn: 0.2092295\ttotal: 14.8s\tremaining: 21.4s\n",
      "410:\tlearn: 0.2089684\ttotal: 14.9s\tremaining: 21.3s\n",
      "411:\tlearn: 0.2086705\ttotal: 14.9s\tremaining: 21.3s\n",
      "412:\tlearn: 0.2085558\ttotal: 14.9s\tremaining: 21.2s\n",
      "413:\tlearn: 0.2082078\ttotal: 15s\tremaining: 21.2s\n",
      "414:\tlearn: 0.2079944\ttotal: 15s\tremaining: 21.2s\n",
      "415:\tlearn: 0.2078684\ttotal: 15s\tremaining: 21.1s\n",
      "416:\tlearn: 0.2077565\ttotal: 15.1s\tremaining: 21.1s\n",
      "417:\tlearn: 0.2076919\ttotal: 15.1s\tremaining: 21.1s\n",
      "418:\tlearn: 0.2076229\ttotal: 15.2s\tremaining: 21s\n",
      "419:\tlearn: 0.2074585\ttotal: 15.2s\tremaining: 21s\n",
      "420:\tlearn: 0.2073542\ttotal: 15.2s\tremaining: 20.9s\n",
      "421:\tlearn: 0.2072589\ttotal: 15.3s\tremaining: 20.9s\n",
      "422:\tlearn: 0.2068913\ttotal: 15.3s\tremaining: 20.9s\n",
      "423:\tlearn: 0.2065629\ttotal: 15.3s\tremaining: 20.8s\n",
      "424:\tlearn: 0.2062673\ttotal: 15.4s\tremaining: 20.8s\n",
      "425:\tlearn: 0.2060284\ttotal: 15.4s\tremaining: 20.8s\n",
      "426:\tlearn: 0.2057188\ttotal: 15.5s\tremaining: 20.7s\n",
      "427:\tlearn: 0.2056332\ttotal: 15.5s\tremaining: 20.7s\n",
      "428:\tlearn: 0.2051167\ttotal: 15.5s\tremaining: 20.7s\n",
      "429:\tlearn: 0.2048518\ttotal: 15.6s\tremaining: 20.6s\n",
      "430:\tlearn: 0.2047668\ttotal: 15.6s\tremaining: 20.6s\n",
      "431:\tlearn: 0.2044935\ttotal: 15.6s\tremaining: 20.5s\n",
      "432:\tlearn: 0.2044305\ttotal: 15.7s\tremaining: 20.5s\n",
      "433:\tlearn: 0.2043309\ttotal: 15.7s\tremaining: 20.5s\n",
      "434:\tlearn: 0.2041973\ttotal: 15.7s\tremaining: 20.5s\n",
      "435:\tlearn: 0.2038291\ttotal: 15.8s\tremaining: 20.4s\n",
      "436:\tlearn: 0.2037054\ttotal: 15.8s\tremaining: 20.4s\n",
      "437:\tlearn: 0.2036508\ttotal: 15.8s\tremaining: 20.3s\n",
      "438:\tlearn: 0.2035375\ttotal: 15.9s\tremaining: 20.3s\n",
      "439:\tlearn: 0.2034471\ttotal: 15.9s\tremaining: 20.3s\n",
      "440:\tlearn: 0.2032425\ttotal: 16s\tremaining: 20.2s\n",
      "441:\tlearn: 0.2030937\ttotal: 16s\tremaining: 20.2s\n",
      "442:\tlearn: 0.2029107\ttotal: 16s\tremaining: 20.1s\n",
      "443:\tlearn: 0.2026107\ttotal: 16.1s\tremaining: 20.1s\n",
      "444:\tlearn: 0.2024946\ttotal: 16.1s\tremaining: 20.1s\n",
      "445:\tlearn: 0.2022168\ttotal: 16.1s\tremaining: 20.1s\n",
      "446:\tlearn: 0.2020483\ttotal: 16.2s\tremaining: 20s\n",
      "447:\tlearn: 0.2019034\ttotal: 16.2s\tremaining: 20s\n",
      "448:\tlearn: 0.2017667\ttotal: 16.2s\tremaining: 19.9s\n",
      "449:\tlearn: 0.2016628\ttotal: 16.3s\tremaining: 19.9s\n",
      "450:\tlearn: 0.2013830\ttotal: 16.3s\tremaining: 19.9s\n",
      "451:\tlearn: 0.2011464\ttotal: 16.3s\tremaining: 19.8s\n",
      "452:\tlearn: 0.2010153\ttotal: 16.4s\tremaining: 19.8s\n",
      "453:\tlearn: 0.2008739\ttotal: 16.4s\tremaining: 19.7s\n",
      "454:\tlearn: 0.2008110\ttotal: 16.4s\tremaining: 19.7s\n",
      "455:\tlearn: 0.2006917\ttotal: 16.5s\tremaining: 19.6s\n",
      "456:\tlearn: 0.2005418\ttotal: 16.5s\tremaining: 19.6s\n",
      "457:\tlearn: 0.2003859\ttotal: 16.6s\tremaining: 19.6s\n",
      "458:\tlearn: 0.2001783\ttotal: 16.6s\tremaining: 19.5s\n",
      "459:\tlearn: 0.1999660\ttotal: 16.6s\tremaining: 19.5s\n",
      "460:\tlearn: 0.1997777\ttotal: 16.7s\tremaining: 19.5s\n",
      "461:\tlearn: 0.1996327\ttotal: 16.7s\tremaining: 19.4s\n",
      "462:\tlearn: 0.1994914\ttotal: 16.7s\tremaining: 19.4s\n",
      "463:\tlearn: 0.1993443\ttotal: 16.8s\tremaining: 19.4s\n",
      "464:\tlearn: 0.1992056\ttotal: 16.8s\tremaining: 19.3s\n",
      "465:\tlearn: 0.1991197\ttotal: 16.8s\tremaining: 19.3s\n",
      "466:\tlearn: 0.1988695\ttotal: 16.9s\tremaining: 19.2s\n",
      "467:\tlearn: 0.1985271\ttotal: 16.9s\tremaining: 19.2s\n",
      "468:\tlearn: 0.1982575\ttotal: 16.9s\tremaining: 19.2s\n",
      "469:\tlearn: 0.1979468\ttotal: 17s\tremaining: 19.1s\n",
      "470:\tlearn: 0.1977696\ttotal: 17s\tremaining: 19.1s\n",
      "471:\tlearn: 0.1975801\ttotal: 17.1s\tremaining: 19.1s\n",
      "472:\tlearn: 0.1975097\ttotal: 17.1s\tremaining: 19s\n",
      "473:\tlearn: 0.1974421\ttotal: 17.1s\tremaining: 19s\n",
      "474:\tlearn: 0.1973174\ttotal: 17.1s\tremaining: 18.9s\n",
      "475:\tlearn: 0.1970439\ttotal: 17.2s\tremaining: 18.9s\n",
      "476:\tlearn: 0.1967472\ttotal: 17.2s\tremaining: 18.9s\n",
      "477:\tlearn: 0.1966593\ttotal: 17.3s\tremaining: 18.8s\n",
      "478:\tlearn: 0.1965117\ttotal: 17.3s\tremaining: 18.8s\n",
      "479:\tlearn: 0.1962464\ttotal: 17.3s\tremaining: 18.8s\n",
      "480:\tlearn: 0.1959069\ttotal: 17.3s\tremaining: 18.7s\n",
      "481:\tlearn: 0.1956271\ttotal: 17.4s\tremaining: 18.7s\n",
      "482:\tlearn: 0.1955949\ttotal: 17.4s\tremaining: 18.7s\n",
      "483:\tlearn: 0.1954124\ttotal: 17.5s\tremaining: 18.6s\n",
      "484:\tlearn: 0.1953124\ttotal: 17.5s\tremaining: 18.6s\n",
      "485:\tlearn: 0.1951420\ttotal: 17.5s\tremaining: 18.5s\n",
      "486:\tlearn: 0.1948490\ttotal: 17.6s\tremaining: 18.5s\n",
      "487:\tlearn: 0.1946918\ttotal: 17.6s\tremaining: 18.5s\n",
      "488:\tlearn: 0.1945968\ttotal: 17.6s\tremaining: 18.4s\n",
      "489:\tlearn: 0.1943608\ttotal: 17.7s\tremaining: 18.4s\n",
      "490:\tlearn: 0.1941887\ttotal: 17.7s\tremaining: 18.4s\n",
      "491:\tlearn: 0.1939480\ttotal: 17.8s\tremaining: 18.3s\n",
      "492:\tlearn: 0.1936933\ttotal: 17.8s\tremaining: 18.3s\n",
      "493:\tlearn: 0.1934842\ttotal: 17.8s\tremaining: 18.3s\n",
      "494:\tlearn: 0.1932938\ttotal: 17.9s\tremaining: 18.2s\n",
      "495:\tlearn: 0.1932000\ttotal: 17.9s\tremaining: 18.2s\n",
      "496:\tlearn: 0.1930330\ttotal: 17.9s\tremaining: 18.2s\n",
      "497:\tlearn: 0.1929630\ttotal: 18s\tremaining: 18.1s\n",
      "498:\tlearn: 0.1927169\ttotal: 18s\tremaining: 18.1s\n",
      "499:\tlearn: 0.1926072\ttotal: 18s\tremaining: 18s\n",
      "500:\tlearn: 0.1923652\ttotal: 18.1s\tremaining: 18s\n",
      "501:\tlearn: 0.1922647\ttotal: 18.1s\tremaining: 18s\n",
      "502:\tlearn: 0.1921687\ttotal: 18.2s\tremaining: 17.9s\n",
      "503:\tlearn: 0.1920955\ttotal: 18.2s\tremaining: 17.9s\n",
      "504:\tlearn: 0.1919761\ttotal: 18.2s\tremaining: 17.9s\n",
      "505:\tlearn: 0.1919199\ttotal: 18.3s\tremaining: 17.8s\n",
      "506:\tlearn: 0.1918423\ttotal: 18.3s\tremaining: 17.8s\n",
      "507:\tlearn: 0.1917063\ttotal: 18.3s\tremaining: 17.8s\n",
      "508:\tlearn: 0.1916658\ttotal: 18.4s\tremaining: 17.7s\n",
      "509:\tlearn: 0.1915754\ttotal: 18.4s\tremaining: 17.7s\n",
      "510:\tlearn: 0.1915061\ttotal: 18.4s\tremaining: 17.6s\n",
      "511:\tlearn: 0.1912168\ttotal: 18.5s\tremaining: 17.6s\n",
      "512:\tlearn: 0.1909896\ttotal: 18.5s\tremaining: 17.6s\n",
      "513:\tlearn: 0.1906967\ttotal: 18.5s\tremaining: 17.5s\n",
      "514:\tlearn: 0.1904149\ttotal: 18.6s\tremaining: 17.5s\n",
      "515:\tlearn: 0.1902675\ttotal: 18.6s\tremaining: 17.5s\n",
      "516:\tlearn: 0.1899971\ttotal: 18.7s\tremaining: 17.4s\n",
      "517:\tlearn: 0.1897427\ttotal: 18.7s\tremaining: 17.4s\n",
      "518:\tlearn: 0.1896420\ttotal: 18.7s\tremaining: 17.4s\n",
      "519:\tlearn: 0.1894017\ttotal: 18.8s\tremaining: 17.3s\n",
      "520:\tlearn: 0.1893265\ttotal: 18.8s\tremaining: 17.3s\n",
      "521:\tlearn: 0.1891436\ttotal: 18.8s\tremaining: 17.2s\n",
      "522:\tlearn: 0.1890714\ttotal: 18.9s\tremaining: 17.2s\n",
      "523:\tlearn: 0.1889268\ttotal: 18.9s\tremaining: 17.2s\n",
      "524:\tlearn: 0.1888157\ttotal: 19s\tremaining: 17.1s\n",
      "525:\tlearn: 0.1884913\ttotal: 19s\tremaining: 17.1s\n",
      "526:\tlearn: 0.1883440\ttotal: 19s\tremaining: 17.1s\n",
      "527:\tlearn: 0.1882532\ttotal: 19.1s\tremaining: 17s\n",
      "528:\tlearn: 0.1879086\ttotal: 19.1s\tremaining: 17s\n",
      "529:\tlearn: 0.1877191\ttotal: 19.1s\tremaining: 17s\n",
      "530:\tlearn: 0.1876695\ttotal: 19.2s\tremaining: 16.9s\n",
      "531:\tlearn: 0.1873399\ttotal: 19.2s\tremaining: 16.9s\n",
      "532:\tlearn: 0.1871743\ttotal: 19.2s\tremaining: 16.9s\n",
      "533:\tlearn: 0.1870698\ttotal: 19.3s\tremaining: 16.8s\n",
      "534:\tlearn: 0.1869889\ttotal: 19.3s\tremaining: 16.8s\n",
      "535:\tlearn: 0.1868504\ttotal: 19.4s\tremaining: 16.8s\n",
      "536:\tlearn: 0.1866665\ttotal: 19.4s\tremaining: 16.7s\n",
      "537:\tlearn: 0.1865150\ttotal: 19.4s\tremaining: 16.7s\n",
      "538:\tlearn: 0.1864135\ttotal: 19.5s\tremaining: 16.6s\n",
      "539:\tlearn: 0.1863564\ttotal: 19.5s\tremaining: 16.6s\n",
      "540:\tlearn: 0.1861830\ttotal: 19.5s\tremaining: 16.6s\n",
      "541:\tlearn: 0.1860247\ttotal: 19.6s\tremaining: 16.5s\n",
      "542:\tlearn: 0.1857449\ttotal: 19.6s\tremaining: 16.5s\n",
      "543:\tlearn: 0.1855658\ttotal: 19.7s\tremaining: 16.5s\n",
      "544:\tlearn: 0.1855099\ttotal: 19.7s\tremaining: 16.4s\n",
      "545:\tlearn: 0.1854465\ttotal: 19.7s\tremaining: 16.4s\n",
      "546:\tlearn: 0.1850841\ttotal: 19.8s\tremaining: 16.4s\n",
      "547:\tlearn: 0.1850351\ttotal: 19.8s\tremaining: 16.3s\n",
      "548:\tlearn: 0.1848629\ttotal: 19.9s\tremaining: 16.3s\n",
      "549:\tlearn: 0.1847726\ttotal: 19.9s\tremaining: 16.3s\n",
      "550:\tlearn: 0.1845906\ttotal: 19.9s\tremaining: 16.2s\n",
      "551:\tlearn: 0.1843961\ttotal: 19.9s\tremaining: 16.2s\n",
      "552:\tlearn: 0.1842505\ttotal: 20s\tremaining: 16.2s\n",
      "553:\tlearn: 0.1840939\ttotal: 20s\tremaining: 16.1s\n",
      "554:\tlearn: 0.1840348\ttotal: 20.1s\tremaining: 16.1s\n",
      "555:\tlearn: 0.1839091\ttotal: 20.1s\tremaining: 16.1s\n",
      "556:\tlearn: 0.1837163\ttotal: 20.1s\tremaining: 16s\n",
      "557:\tlearn: 0.1835915\ttotal: 20.2s\tremaining: 16s\n",
      "558:\tlearn: 0.1834392\ttotal: 20.2s\tremaining: 15.9s\n",
      "559:\tlearn: 0.1832603\ttotal: 20.2s\tremaining: 15.9s\n",
      "560:\tlearn: 0.1829842\ttotal: 20.3s\tremaining: 15.9s\n",
      "561:\tlearn: 0.1828634\ttotal: 20.3s\tremaining: 15.8s\n",
      "562:\tlearn: 0.1827593\ttotal: 20.3s\tremaining: 15.8s\n",
      "563:\tlearn: 0.1826389\ttotal: 20.4s\tremaining: 15.8s\n",
      "564:\tlearn: 0.1823502\ttotal: 20.4s\tremaining: 15.7s\n",
      "565:\tlearn: 0.1822595\ttotal: 20.4s\tremaining: 15.7s\n",
      "566:\tlearn: 0.1820204\ttotal: 20.5s\tremaining: 15.6s\n",
      "567:\tlearn: 0.1818226\ttotal: 20.5s\tremaining: 15.6s\n",
      "568:\tlearn: 0.1816741\ttotal: 20.6s\tremaining: 15.6s\n",
      "569:\tlearn: 0.1815546\ttotal: 20.6s\tremaining: 15.5s\n",
      "570:\tlearn: 0.1813097\ttotal: 20.6s\tremaining: 15.5s\n",
      "571:\tlearn: 0.1812083\ttotal: 20.7s\tremaining: 15.5s\n",
      "572:\tlearn: 0.1810455\ttotal: 20.7s\tremaining: 15.4s\n",
      "573:\tlearn: 0.1808343\ttotal: 20.7s\tremaining: 15.4s\n",
      "574:\tlearn: 0.1806852\ttotal: 20.8s\tremaining: 15.4s\n",
      "575:\tlearn: 0.1804942\ttotal: 20.8s\tremaining: 15.3s\n",
      "576:\tlearn: 0.1803486\ttotal: 20.9s\tremaining: 15.3s\n",
      "577:\tlearn: 0.1802127\ttotal: 20.9s\tremaining: 15.3s\n",
      "578:\tlearn: 0.1799255\ttotal: 20.9s\tremaining: 15.2s\n",
      "579:\tlearn: 0.1797833\ttotal: 21s\tremaining: 15.2s\n",
      "580:\tlearn: 0.1795903\ttotal: 21s\tremaining: 15.1s\n",
      "581:\tlearn: 0.1795192\ttotal: 21s\tremaining: 15.1s\n",
      "582:\tlearn: 0.1794093\ttotal: 21.1s\tremaining: 15.1s\n",
      "583:\tlearn: 0.1793079\ttotal: 21.1s\tremaining: 15s\n",
      "584:\tlearn: 0.1791840\ttotal: 21.1s\tremaining: 15s\n",
      "585:\tlearn: 0.1791306\ttotal: 21.2s\tremaining: 14.9s\n",
      "586:\tlearn: 0.1788489\ttotal: 21.2s\tremaining: 14.9s\n",
      "587:\tlearn: 0.1786264\ttotal: 21.2s\tremaining: 14.9s\n",
      "588:\tlearn: 0.1783079\ttotal: 21.3s\tremaining: 14.8s\n",
      "589:\tlearn: 0.1781776\ttotal: 21.3s\tremaining: 14.8s\n",
      "590:\tlearn: 0.1780633\ttotal: 21.3s\tremaining: 14.8s\n",
      "591:\tlearn: 0.1779723\ttotal: 21.4s\tremaining: 14.7s\n",
      "592:\tlearn: 0.1778977\ttotal: 21.4s\tremaining: 14.7s\n",
      "593:\tlearn: 0.1777788\ttotal: 21.4s\tremaining: 14.7s\n",
      "594:\tlearn: 0.1777524\ttotal: 21.5s\tremaining: 14.6s\n",
      "595:\tlearn: 0.1776526\ttotal: 21.5s\tremaining: 14.6s\n",
      "596:\tlearn: 0.1775908\ttotal: 21.5s\tremaining: 14.5s\n",
      "597:\tlearn: 0.1774102\ttotal: 21.6s\tremaining: 14.5s\n",
      "598:\tlearn: 0.1772883\ttotal: 21.6s\tremaining: 14.5s\n",
      "599:\tlearn: 0.1771246\ttotal: 21.7s\tremaining: 14.4s\n",
      "600:\tlearn: 0.1770912\ttotal: 21.7s\tremaining: 14.4s\n",
      "601:\tlearn: 0.1768662\ttotal: 21.7s\tremaining: 14.4s\n",
      "602:\tlearn: 0.1766457\ttotal: 21.8s\tremaining: 14.3s\n",
      "603:\tlearn: 0.1766212\ttotal: 21.8s\tremaining: 14.3s\n",
      "604:\tlearn: 0.1765276\ttotal: 21.8s\tremaining: 14.3s\n",
      "605:\tlearn: 0.1764822\ttotal: 21.9s\tremaining: 14.2s\n",
      "606:\tlearn: 0.1762680\ttotal: 21.9s\tremaining: 14.2s\n",
      "607:\tlearn: 0.1762335\ttotal: 21.9s\tremaining: 14.1s\n",
      "608:\tlearn: 0.1760529\ttotal: 22s\tremaining: 14.1s\n",
      "609:\tlearn: 0.1759502\ttotal: 22s\tremaining: 14.1s\n",
      "610:\tlearn: 0.1758588\ttotal: 22s\tremaining: 14s\n",
      "611:\tlearn: 0.1757996\ttotal: 22.1s\tremaining: 14s\n",
      "612:\tlearn: 0.1754802\ttotal: 22.1s\tremaining: 14s\n",
      "613:\tlearn: 0.1753791\ttotal: 22.2s\tremaining: 13.9s\n",
      "614:\tlearn: 0.1753153\ttotal: 22.2s\tremaining: 13.9s\n",
      "615:\tlearn: 0.1751395\ttotal: 22.2s\tremaining: 13.9s\n",
      "616:\tlearn: 0.1749790\ttotal: 22.3s\tremaining: 13.8s\n",
      "617:\tlearn: 0.1748545\ttotal: 22.3s\tremaining: 13.8s\n",
      "618:\tlearn: 0.1748030\ttotal: 22.3s\tremaining: 13.7s\n",
      "619:\tlearn: 0.1746887\ttotal: 22.4s\tremaining: 13.7s\n",
      "620:\tlearn: 0.1744371\ttotal: 22.4s\tremaining: 13.7s\n",
      "621:\tlearn: 0.1742335\ttotal: 22.4s\tremaining: 13.6s\n",
      "622:\tlearn: 0.1740465\ttotal: 22.5s\tremaining: 13.6s\n",
      "623:\tlearn: 0.1738974\ttotal: 22.5s\tremaining: 13.6s\n",
      "624:\tlearn: 0.1738266\ttotal: 22.5s\tremaining: 13.5s\n",
      "625:\tlearn: 0.1734838\ttotal: 22.6s\tremaining: 13.5s\n",
      "626:\tlearn: 0.1733440\ttotal: 22.6s\tremaining: 13.4s\n",
      "627:\tlearn: 0.1732148\ttotal: 22.6s\tremaining: 13.4s\n",
      "628:\tlearn: 0.1731602\ttotal: 22.7s\tremaining: 13.4s\n",
      "629:\tlearn: 0.1730630\ttotal: 22.7s\tremaining: 13.4s\n",
      "630:\tlearn: 0.1729435\ttotal: 22.8s\tremaining: 13.3s\n",
      "631:\tlearn: 0.1727796\ttotal: 22.8s\tremaining: 13.3s\n",
      "632:\tlearn: 0.1726173\ttotal: 22.8s\tremaining: 13.2s\n",
      "633:\tlearn: 0.1725653\ttotal: 22.9s\tremaining: 13.2s\n",
      "634:\tlearn: 0.1723239\ttotal: 22.9s\tremaining: 13.2s\n",
      "635:\tlearn: 0.1722666\ttotal: 22.9s\tremaining: 13.1s\n",
      "636:\tlearn: 0.1721552\ttotal: 23s\tremaining: 13.1s\n",
      "637:\tlearn: 0.1720413\ttotal: 23s\tremaining: 13.1s\n",
      "638:\tlearn: 0.1718388\ttotal: 23s\tremaining: 13s\n",
      "639:\tlearn: 0.1716396\ttotal: 23.1s\tremaining: 13s\n",
      "640:\tlearn: 0.1715673\ttotal: 23.1s\tremaining: 13s\n",
      "641:\tlearn: 0.1713300\ttotal: 23.2s\tremaining: 12.9s\n",
      "642:\tlearn: 0.1711657\ttotal: 23.2s\tremaining: 12.9s\n",
      "643:\tlearn: 0.1709926\ttotal: 23.2s\tremaining: 12.8s\n",
      "644:\tlearn: 0.1708863\ttotal: 23.3s\tremaining: 12.8s\n",
      "645:\tlearn: 0.1707218\ttotal: 23.3s\tremaining: 12.8s\n",
      "646:\tlearn: 0.1705290\ttotal: 23.4s\tremaining: 12.7s\n",
      "647:\tlearn: 0.1704023\ttotal: 23.4s\tremaining: 12.7s\n",
      "648:\tlearn: 0.1701144\ttotal: 23.4s\tremaining: 12.7s\n",
      "649:\tlearn: 0.1699958\ttotal: 23.5s\tremaining: 12.6s\n",
      "650:\tlearn: 0.1697556\ttotal: 23.5s\tremaining: 12.6s\n",
      "651:\tlearn: 0.1696559\ttotal: 23.5s\tremaining: 12.6s\n",
      "652:\tlearn: 0.1695047\ttotal: 23.6s\tremaining: 12.5s\n",
      "653:\tlearn: 0.1693266\ttotal: 23.6s\tremaining: 12.5s\n",
      "654:\tlearn: 0.1692127\ttotal: 23.7s\tremaining: 12.5s\n",
      "655:\tlearn: 0.1691029\ttotal: 23.7s\tremaining: 12.4s\n",
      "656:\tlearn: 0.1689709\ttotal: 23.7s\tremaining: 12.4s\n",
      "657:\tlearn: 0.1688581\ttotal: 23.8s\tremaining: 12.4s\n",
      "658:\tlearn: 0.1687526\ttotal: 23.8s\tremaining: 12.3s\n",
      "659:\tlearn: 0.1687100\ttotal: 23.8s\tremaining: 12.3s\n",
      "660:\tlearn: 0.1686053\ttotal: 23.9s\tremaining: 12.2s\n",
      "661:\tlearn: 0.1683707\ttotal: 23.9s\tremaining: 12.2s\n",
      "662:\tlearn: 0.1682514\ttotal: 23.9s\tremaining: 12.2s\n",
      "663:\tlearn: 0.1681590\ttotal: 24s\tremaining: 12.1s\n",
      "664:\tlearn: 0.1679385\ttotal: 24s\tremaining: 12.1s\n",
      "665:\tlearn: 0.1677649\ttotal: 24.1s\tremaining: 12.1s\n",
      "666:\tlearn: 0.1676034\ttotal: 24.1s\tremaining: 12s\n",
      "667:\tlearn: 0.1675349\ttotal: 24.1s\tremaining: 12s\n",
      "668:\tlearn: 0.1675120\ttotal: 24.2s\tremaining: 12s\n",
      "669:\tlearn: 0.1673594\ttotal: 24.2s\tremaining: 11.9s\n",
      "670:\tlearn: 0.1671312\ttotal: 24.2s\tremaining: 11.9s\n",
      "671:\tlearn: 0.1670871\ttotal: 24.3s\tremaining: 11.8s\n",
      "672:\tlearn: 0.1669798\ttotal: 24.3s\tremaining: 11.8s\n",
      "673:\tlearn: 0.1668297\ttotal: 24.3s\tremaining: 11.8s\n",
      "674:\tlearn: 0.1665705\ttotal: 24.4s\tremaining: 11.7s\n",
      "675:\tlearn: 0.1664980\ttotal: 24.4s\tremaining: 11.7s\n",
      "676:\tlearn: 0.1663874\ttotal: 24.4s\tremaining: 11.7s\n",
      "677:\tlearn: 0.1662816\ttotal: 24.5s\tremaining: 11.6s\n",
      "678:\tlearn: 0.1661294\ttotal: 24.5s\tremaining: 11.6s\n",
      "679:\tlearn: 0.1659783\ttotal: 24.6s\tremaining: 11.6s\n",
      "680:\tlearn: 0.1657711\ttotal: 24.6s\tremaining: 11.5s\n",
      "681:\tlearn: 0.1656836\ttotal: 24.7s\tremaining: 11.5s\n",
      "682:\tlearn: 0.1654739\ttotal: 24.7s\tremaining: 11.5s\n",
      "683:\tlearn: 0.1652743\ttotal: 24.7s\tremaining: 11.4s\n",
      "684:\tlearn: 0.1652164\ttotal: 24.8s\tremaining: 11.4s\n",
      "685:\tlearn: 0.1651307\ttotal: 24.8s\tremaining: 11.4s\n",
      "686:\tlearn: 0.1650360\ttotal: 24.9s\tremaining: 11.3s\n",
      "687:\tlearn: 0.1649772\ttotal: 24.9s\tremaining: 11.3s\n",
      "688:\tlearn: 0.1648732\ttotal: 24.9s\tremaining: 11.2s\n",
      "689:\tlearn: 0.1647662\ttotal: 25s\tremaining: 11.2s\n",
      "690:\tlearn: 0.1646495\ttotal: 25s\tremaining: 11.2s\n",
      "691:\tlearn: 0.1644130\ttotal: 25s\tremaining: 11.1s\n",
      "692:\tlearn: 0.1643014\ttotal: 25.1s\tremaining: 11.1s\n",
      "693:\tlearn: 0.1642300\ttotal: 25.1s\tremaining: 11.1s\n",
      "694:\tlearn: 0.1641283\ttotal: 25.1s\tremaining: 11s\n",
      "695:\tlearn: 0.1640153\ttotal: 25.2s\tremaining: 11s\n",
      "696:\tlearn: 0.1638761\ttotal: 25.2s\tremaining: 11s\n",
      "697:\tlearn: 0.1637421\ttotal: 25.3s\tremaining: 10.9s\n",
      "698:\tlearn: 0.1637136\ttotal: 25.3s\tremaining: 10.9s\n",
      "699:\tlearn: 0.1636627\ttotal: 25.3s\tremaining: 10.9s\n",
      "700:\tlearn: 0.1635824\ttotal: 25.4s\tremaining: 10.8s\n",
      "701:\tlearn: 0.1634204\ttotal: 25.4s\tremaining: 10.8s\n",
      "702:\tlearn: 0.1633161\ttotal: 25.4s\tremaining: 10.7s\n",
      "703:\tlearn: 0.1631264\ttotal: 25.5s\tremaining: 10.7s\n",
      "704:\tlearn: 0.1629771\ttotal: 25.5s\tremaining: 10.7s\n",
      "705:\tlearn: 0.1628445\ttotal: 25.6s\tremaining: 10.6s\n",
      "706:\tlearn: 0.1627945\ttotal: 25.6s\tremaining: 10.6s\n",
      "707:\tlearn: 0.1626309\ttotal: 25.6s\tremaining: 10.6s\n",
      "708:\tlearn: 0.1625354\ttotal: 25.7s\tremaining: 10.5s\n",
      "709:\tlearn: 0.1624280\ttotal: 25.7s\tremaining: 10.5s\n",
      "710:\tlearn: 0.1622150\ttotal: 25.7s\tremaining: 10.5s\n",
      "711:\tlearn: 0.1620752\ttotal: 25.8s\tremaining: 10.4s\n",
      "712:\tlearn: 0.1619493\ttotal: 25.8s\tremaining: 10.4s\n",
      "713:\tlearn: 0.1618493\ttotal: 25.8s\tremaining: 10.3s\n",
      "714:\tlearn: 0.1617430\ttotal: 25.9s\tremaining: 10.3s\n",
      "715:\tlearn: 0.1615718\ttotal: 25.9s\tremaining: 10.3s\n",
      "716:\tlearn: 0.1613547\ttotal: 25.9s\tremaining: 10.2s\n",
      "717:\tlearn: 0.1612180\ttotal: 26s\tremaining: 10.2s\n",
      "718:\tlearn: 0.1611095\ttotal: 26s\tremaining: 10.2s\n",
      "719:\tlearn: 0.1609561\ttotal: 26.1s\tremaining: 10.1s\n",
      "720:\tlearn: 0.1607658\ttotal: 26.1s\tremaining: 10.1s\n",
      "721:\tlearn: 0.1605651\ttotal: 26.1s\tremaining: 10.1s\n",
      "722:\tlearn: 0.1604094\ttotal: 26.2s\tremaining: 10s\n",
      "723:\tlearn: 0.1603318\ttotal: 26.2s\tremaining: 9.99s\n",
      "724:\tlearn: 0.1601315\ttotal: 26.3s\tremaining: 9.96s\n",
      "725:\tlearn: 0.1599448\ttotal: 26.3s\tremaining: 9.92s\n",
      "726:\tlearn: 0.1598490\ttotal: 26.3s\tremaining: 9.88s\n",
      "727:\tlearn: 0.1598013\ttotal: 26.4s\tremaining: 9.85s\n",
      "728:\tlearn: 0.1597451\ttotal: 26.4s\tremaining: 9.81s\n",
      "729:\tlearn: 0.1596790\ttotal: 26.4s\tremaining: 9.78s\n",
      "730:\tlearn: 0.1595154\ttotal: 26.5s\tremaining: 9.74s\n",
      "731:\tlearn: 0.1594063\ttotal: 26.5s\tremaining: 9.71s\n",
      "732:\tlearn: 0.1593028\ttotal: 26.6s\tremaining: 9.67s\n",
      "733:\tlearn: 0.1591920\ttotal: 26.6s\tremaining: 9.63s\n",
      "734:\tlearn: 0.1591146\ttotal: 26.6s\tremaining: 9.6s\n",
      "735:\tlearn: 0.1590059\ttotal: 26.7s\tremaining: 9.56s\n",
      "736:\tlearn: 0.1589778\ttotal: 26.7s\tremaining: 9.53s\n",
      "737:\tlearn: 0.1588842\ttotal: 26.7s\tremaining: 9.49s\n",
      "738:\tlearn: 0.1587514\ttotal: 26.8s\tremaining: 9.46s\n",
      "739:\tlearn: 0.1586452\ttotal: 26.8s\tremaining: 9.42s\n",
      "740:\tlearn: 0.1585829\ttotal: 26.9s\tremaining: 9.38s\n",
      "741:\tlearn: 0.1584744\ttotal: 26.9s\tremaining: 9.35s\n",
      "742:\tlearn: 0.1583706\ttotal: 26.9s\tremaining: 9.32s\n",
      "743:\tlearn: 0.1582859\ttotal: 27s\tremaining: 9.28s\n",
      "744:\tlearn: 0.1581790\ttotal: 27s\tremaining: 9.25s\n",
      "745:\tlearn: 0.1580769\ttotal: 27s\tremaining: 9.21s\n",
      "746:\tlearn: 0.1580045\ttotal: 27.1s\tremaining: 9.17s\n",
      "747:\tlearn: 0.1578696\ttotal: 27.1s\tremaining: 9.13s\n",
      "748:\tlearn: 0.1577413\ttotal: 27.1s\tremaining: 9.1s\n",
      "749:\tlearn: 0.1576377\ttotal: 27.2s\tremaining: 9.06s\n",
      "750:\tlearn: 0.1575245\ttotal: 27.2s\tremaining: 9.02s\n",
      "751:\tlearn: 0.1574223\ttotal: 27.2s\tremaining: 8.99s\n",
      "752:\tlearn: 0.1572871\ttotal: 27.3s\tremaining: 8.95s\n",
      "753:\tlearn: 0.1571909\ttotal: 27.3s\tremaining: 8.91s\n",
      "754:\tlearn: 0.1570632\ttotal: 27.3s\tremaining: 8.87s\n",
      "755:\tlearn: 0.1570081\ttotal: 27.4s\tremaining: 8.84s\n",
      "756:\tlearn: 0.1569201\ttotal: 27.4s\tremaining: 8.81s\n",
      "757:\tlearn: 0.1568327\ttotal: 27.5s\tremaining: 8.77s\n",
      "758:\tlearn: 0.1567184\ttotal: 27.5s\tremaining: 8.74s\n",
      "759:\tlearn: 0.1566115\ttotal: 27.6s\tremaining: 8.7s\n",
      "760:\tlearn: 0.1564200\ttotal: 27.6s\tremaining: 8.66s\n",
      "761:\tlearn: 0.1563541\ttotal: 27.6s\tremaining: 8.63s\n",
      "762:\tlearn: 0.1562588\ttotal: 27.7s\tremaining: 8.59s\n",
      "763:\tlearn: 0.1562205\ttotal: 27.7s\tremaining: 8.55s\n",
      "764:\tlearn: 0.1561691\ttotal: 27.7s\tremaining: 8.52s\n",
      "765:\tlearn: 0.1560024\ttotal: 27.8s\tremaining: 8.48s\n",
      "766:\tlearn: 0.1558305\ttotal: 27.8s\tremaining: 8.45s\n",
      "767:\tlearn: 0.1556747\ttotal: 27.8s\tremaining: 8.41s\n",
      "768:\tlearn: 0.1555596\ttotal: 27.9s\tremaining: 8.37s\n",
      "769:\tlearn: 0.1555124\ttotal: 27.9s\tremaining: 8.34s\n",
      "770:\tlearn: 0.1554335\ttotal: 27.9s\tremaining: 8.3s\n",
      "771:\tlearn: 0.1551446\ttotal: 28s\tremaining: 8.26s\n",
      "772:\tlearn: 0.1548873\ttotal: 28s\tremaining: 8.23s\n",
      "773:\tlearn: 0.1548010\ttotal: 28.1s\tremaining: 8.19s\n",
      "774:\tlearn: 0.1547044\ttotal: 28.1s\tremaining: 8.16s\n",
      "775:\tlearn: 0.1546125\ttotal: 28.1s\tremaining: 8.12s\n",
      "776:\tlearn: 0.1545531\ttotal: 28.2s\tremaining: 8.09s\n",
      "777:\tlearn: 0.1544065\ttotal: 28.2s\tremaining: 8.05s\n",
      "778:\tlearn: 0.1543580\ttotal: 28.2s\tremaining: 8.01s\n",
      "779:\tlearn: 0.1542854\ttotal: 28.3s\tremaining: 7.98s\n",
      "780:\tlearn: 0.1541483\ttotal: 28.3s\tremaining: 7.94s\n",
      "781:\tlearn: 0.1540746\ttotal: 28.4s\tremaining: 7.91s\n",
      "782:\tlearn: 0.1539310\ttotal: 28.4s\tremaining: 7.87s\n",
      "783:\tlearn: 0.1537713\ttotal: 28.4s\tremaining: 7.83s\n",
      "784:\tlearn: 0.1536395\ttotal: 28.5s\tremaining: 7.8s\n",
      "785:\tlearn: 0.1535911\ttotal: 28.5s\tremaining: 7.76s\n",
      "786:\tlearn: 0.1535140\ttotal: 28.5s\tremaining: 7.72s\n",
      "787:\tlearn: 0.1534579\ttotal: 28.6s\tremaining: 7.68s\n",
      "788:\tlearn: 0.1533996\ttotal: 28.6s\tremaining: 7.65s\n",
      "789:\tlearn: 0.1531952\ttotal: 28.6s\tremaining: 7.61s\n",
      "790:\tlearn: 0.1531246\ttotal: 28.7s\tremaining: 7.58s\n",
      "791:\tlearn: 0.1530515\ttotal: 28.7s\tremaining: 7.54s\n",
      "792:\tlearn: 0.1528808\ttotal: 28.7s\tremaining: 7.5s\n",
      "793:\tlearn: 0.1527019\ttotal: 28.8s\tremaining: 7.47s\n",
      "794:\tlearn: 0.1526327\ttotal: 28.8s\tremaining: 7.43s\n",
      "795:\tlearn: 0.1525132\ttotal: 28.9s\tremaining: 7.4s\n",
      "796:\tlearn: 0.1524509\ttotal: 28.9s\tremaining: 7.36s\n",
      "797:\tlearn: 0.1523076\ttotal: 28.9s\tremaining: 7.32s\n",
      "798:\tlearn: 0.1522406\ttotal: 29s\tremaining: 7.29s\n",
      "799:\tlearn: 0.1521463\ttotal: 29s\tremaining: 7.25s\n",
      "800:\tlearn: 0.1518865\ttotal: 29s\tremaining: 7.21s\n",
      "801:\tlearn: 0.1518390\ttotal: 29.1s\tremaining: 7.18s\n",
      "802:\tlearn: 0.1517547\ttotal: 29.1s\tremaining: 7.14s\n",
      "803:\tlearn: 0.1516860\ttotal: 29.1s\tremaining: 7.1s\n",
      "804:\tlearn: 0.1515308\ttotal: 29.2s\tremaining: 7.07s\n",
      "805:\tlearn: 0.1514676\ttotal: 29.2s\tremaining: 7.03s\n",
      "806:\tlearn: 0.1513544\ttotal: 29.3s\tremaining: 7s\n",
      "807:\tlearn: 0.1512799\ttotal: 29.3s\tremaining: 6.96s\n",
      "808:\tlearn: 0.1511514\ttotal: 29.3s\tremaining: 6.93s\n",
      "809:\tlearn: 0.1510357\ttotal: 29.4s\tremaining: 6.89s\n",
      "810:\tlearn: 0.1509122\ttotal: 29.4s\tremaining: 6.85s\n",
      "811:\tlearn: 0.1507303\ttotal: 29.4s\tremaining: 6.82s\n",
      "812:\tlearn: 0.1506467\ttotal: 29.5s\tremaining: 6.78s\n",
      "813:\tlearn: 0.1505538\ttotal: 29.5s\tremaining: 6.75s\n",
      "814:\tlearn: 0.1505123\ttotal: 29.6s\tremaining: 6.71s\n",
      "815:\tlearn: 0.1503561\ttotal: 29.6s\tremaining: 6.67s\n",
      "816:\tlearn: 0.1502915\ttotal: 29.6s\tremaining: 6.64s\n",
      "817:\tlearn: 0.1501976\ttotal: 29.7s\tremaining: 6.6s\n",
      "818:\tlearn: 0.1500332\ttotal: 29.7s\tremaining: 6.56s\n",
      "819:\tlearn: 0.1499576\ttotal: 29.7s\tremaining: 6.53s\n",
      "820:\tlearn: 0.1499053\ttotal: 29.8s\tremaining: 6.49s\n",
      "821:\tlearn: 0.1498505\ttotal: 29.8s\tremaining: 6.45s\n",
      "822:\tlearn: 0.1498175\ttotal: 29.8s\tremaining: 6.42s\n",
      "823:\tlearn: 0.1496854\ttotal: 29.9s\tremaining: 6.38s\n",
      "824:\tlearn: 0.1495935\ttotal: 29.9s\tremaining: 6.35s\n",
      "825:\tlearn: 0.1494401\ttotal: 30s\tremaining: 6.31s\n",
      "826:\tlearn: 0.1492823\ttotal: 30s\tremaining: 6.27s\n",
      "827:\tlearn: 0.1491770\ttotal: 30s\tremaining: 6.24s\n",
      "828:\tlearn: 0.1490408\ttotal: 30.1s\tremaining: 6.2s\n",
      "829:\tlearn: 0.1489314\ttotal: 30.1s\tremaining: 6.16s\n",
      "830:\tlearn: 0.1488336\ttotal: 30.1s\tremaining: 6.13s\n",
      "831:\tlearn: 0.1487947\ttotal: 30.2s\tremaining: 6.09s\n",
      "832:\tlearn: 0.1486889\ttotal: 30.2s\tremaining: 6.05s\n",
      "833:\tlearn: 0.1485766\ttotal: 30.2s\tremaining: 6.02s\n",
      "834:\tlearn: 0.1484693\ttotal: 30.3s\tremaining: 5.98s\n",
      "835:\tlearn: 0.1483080\ttotal: 30.3s\tremaining: 5.94s\n",
      "836:\tlearn: 0.1481482\ttotal: 30.3s\tremaining: 5.91s\n",
      "837:\tlearn: 0.1480792\ttotal: 30.4s\tremaining: 5.87s\n",
      "838:\tlearn: 0.1480233\ttotal: 30.4s\tremaining: 5.84s\n",
      "839:\tlearn: 0.1479495\ttotal: 30.5s\tremaining: 5.8s\n",
      "840:\tlearn: 0.1478682\ttotal: 30.5s\tremaining: 5.77s\n",
      "841:\tlearn: 0.1477858\ttotal: 30.5s\tremaining: 5.73s\n",
      "842:\tlearn: 0.1476790\ttotal: 30.6s\tremaining: 5.69s\n",
      "843:\tlearn: 0.1475756\ttotal: 30.6s\tremaining: 5.66s\n",
      "844:\tlearn: 0.1474101\ttotal: 30.7s\tremaining: 5.62s\n",
      "845:\tlearn: 0.1472624\ttotal: 30.7s\tremaining: 5.59s\n",
      "846:\tlearn: 0.1471659\ttotal: 30.7s\tremaining: 5.55s\n",
      "847:\tlearn: 0.1471158\ttotal: 30.8s\tremaining: 5.51s\n",
      "848:\tlearn: 0.1470043\ttotal: 30.8s\tremaining: 5.48s\n",
      "849:\tlearn: 0.1469157\ttotal: 30.8s\tremaining: 5.44s\n",
      "850:\tlearn: 0.1468567\ttotal: 30.9s\tremaining: 5.41s\n",
      "851:\tlearn: 0.1467474\ttotal: 30.9s\tremaining: 5.37s\n",
      "852:\tlearn: 0.1466876\ttotal: 31s\tremaining: 5.33s\n",
      "853:\tlearn: 0.1466256\ttotal: 31s\tremaining: 5.3s\n",
      "854:\tlearn: 0.1465497\ttotal: 31s\tremaining: 5.26s\n",
      "855:\tlearn: 0.1464728\ttotal: 31.1s\tremaining: 5.22s\n",
      "856:\tlearn: 0.1463506\ttotal: 31.1s\tremaining: 5.19s\n",
      "857:\tlearn: 0.1463283\ttotal: 31.1s\tremaining: 5.15s\n",
      "858:\tlearn: 0.1462579\ttotal: 31.2s\tremaining: 5.12s\n",
      "859:\tlearn: 0.1462176\ttotal: 31.2s\tremaining: 5.08s\n",
      "860:\tlearn: 0.1461362\ttotal: 31.2s\tremaining: 5.04s\n",
      "861:\tlearn: 0.1459910\ttotal: 31.3s\tremaining: 5.01s\n",
      "862:\tlearn: 0.1458187\ttotal: 31.3s\tremaining: 4.97s\n",
      "863:\tlearn: 0.1457710\ttotal: 31.3s\tremaining: 4.93s\n",
      "864:\tlearn: 0.1457296\ttotal: 31.4s\tremaining: 4.9s\n",
      "865:\tlearn: 0.1456083\ttotal: 31.4s\tremaining: 4.86s\n",
      "866:\tlearn: 0.1455133\ttotal: 31.5s\tremaining: 4.83s\n",
      "867:\tlearn: 0.1454596\ttotal: 31.5s\tremaining: 4.79s\n",
      "868:\tlearn: 0.1454088\ttotal: 31.5s\tremaining: 4.75s\n",
      "869:\tlearn: 0.1452784\ttotal: 31.6s\tremaining: 4.71s\n",
      "870:\tlearn: 0.1451614\ttotal: 31.6s\tremaining: 4.68s\n",
      "871:\tlearn: 0.1450707\ttotal: 31.6s\tremaining: 4.64s\n",
      "872:\tlearn: 0.1449921\ttotal: 31.7s\tremaining: 4.61s\n",
      "873:\tlearn: 0.1449352\ttotal: 31.7s\tremaining: 4.57s\n",
      "874:\tlearn: 0.1448291\ttotal: 31.8s\tremaining: 4.54s\n",
      "875:\tlearn: 0.1447762\ttotal: 31.8s\tremaining: 4.5s\n",
      "876:\tlearn: 0.1446855\ttotal: 31.8s\tremaining: 4.46s\n",
      "877:\tlearn: 0.1446063\ttotal: 31.9s\tremaining: 4.43s\n",
      "878:\tlearn: 0.1445550\ttotal: 31.9s\tremaining: 4.39s\n",
      "879:\tlearn: 0.1444602\ttotal: 31.9s\tremaining: 4.36s\n",
      "880:\tlearn: 0.1442897\ttotal: 32s\tremaining: 4.32s\n",
      "881:\tlearn: 0.1441825\ttotal: 32s\tremaining: 4.28s\n",
      "882:\tlearn: 0.1440835\ttotal: 32.1s\tremaining: 4.25s\n",
      "883:\tlearn: 0.1440400\ttotal: 32.1s\tremaining: 4.21s\n",
      "884:\tlearn: 0.1439211\ttotal: 32.1s\tremaining: 4.17s\n",
      "885:\tlearn: 0.1438849\ttotal: 32.1s\tremaining: 4.14s\n",
      "886:\tlearn: 0.1438001\ttotal: 32.2s\tremaining: 4.1s\n",
      "887:\tlearn: 0.1437084\ttotal: 32.2s\tremaining: 4.07s\n",
      "888:\tlearn: 0.1436215\ttotal: 32.3s\tremaining: 4.03s\n",
      "889:\tlearn: 0.1435272\ttotal: 32.3s\tremaining: 3.99s\n",
      "890:\tlearn: 0.1434252\ttotal: 32.3s\tremaining: 3.96s\n",
      "891:\tlearn: 0.1433629\ttotal: 32.4s\tremaining: 3.92s\n",
      "892:\tlearn: 0.1432814\ttotal: 32.4s\tremaining: 3.88s\n",
      "893:\tlearn: 0.1431984\ttotal: 32.4s\tremaining: 3.85s\n",
      "894:\tlearn: 0.1431321\ttotal: 32.5s\tremaining: 3.81s\n",
      "895:\tlearn: 0.1430717\ttotal: 32.5s\tremaining: 3.77s\n",
      "896:\tlearn: 0.1430172\ttotal: 32.5s\tremaining: 3.74s\n",
      "897:\tlearn: 0.1429148\ttotal: 32.6s\tremaining: 3.7s\n",
      "898:\tlearn: 0.1428765\ttotal: 32.6s\tremaining: 3.66s\n",
      "899:\tlearn: 0.1428019\ttotal: 32.7s\tremaining: 3.63s\n",
      "900:\tlearn: 0.1426566\ttotal: 32.7s\tremaining: 3.59s\n",
      "901:\tlearn: 0.1425563\ttotal: 32.7s\tremaining: 3.56s\n",
      "902:\tlearn: 0.1424963\ttotal: 32.8s\tremaining: 3.52s\n",
      "903:\tlearn: 0.1423987\ttotal: 32.8s\tremaining: 3.48s\n",
      "904:\tlearn: 0.1422053\ttotal: 32.8s\tremaining: 3.45s\n",
      "905:\tlearn: 0.1420633\ttotal: 32.9s\tremaining: 3.41s\n",
      "906:\tlearn: 0.1419782\ttotal: 32.9s\tremaining: 3.37s\n",
      "907:\tlearn: 0.1419160\ttotal: 32.9s\tremaining: 3.34s\n",
      "908:\tlearn: 0.1418049\ttotal: 33s\tremaining: 3.3s\n",
      "909:\tlearn: 0.1417146\ttotal: 33s\tremaining: 3.26s\n",
      "910:\tlearn: 0.1415887\ttotal: 33s\tremaining: 3.23s\n",
      "911:\tlearn: 0.1415062\ttotal: 33.1s\tremaining: 3.19s\n",
      "912:\tlearn: 0.1414161\ttotal: 33.1s\tremaining: 3.16s\n",
      "913:\tlearn: 0.1413235\ttotal: 33.2s\tremaining: 3.12s\n",
      "914:\tlearn: 0.1411526\ttotal: 33.2s\tremaining: 3.08s\n",
      "915:\tlearn: 0.1410577\ttotal: 33.2s\tremaining: 3.05s\n",
      "916:\tlearn: 0.1410101\ttotal: 33.3s\tremaining: 3.01s\n",
      "917:\tlearn: 0.1409555\ttotal: 33.3s\tremaining: 2.97s\n",
      "918:\tlearn: 0.1408608\ttotal: 33.3s\tremaining: 2.94s\n",
      "919:\tlearn: 0.1407485\ttotal: 33.4s\tremaining: 2.9s\n",
      "920:\tlearn: 0.1406680\ttotal: 33.4s\tremaining: 2.87s\n",
      "921:\tlearn: 0.1405051\ttotal: 33.4s\tremaining: 2.83s\n",
      "922:\tlearn: 0.1403672\ttotal: 33.5s\tremaining: 2.79s\n",
      "923:\tlearn: 0.1403321\ttotal: 33.5s\tremaining: 2.76s\n",
      "924:\tlearn: 0.1402752\ttotal: 33.5s\tremaining: 2.72s\n",
      "925:\tlearn: 0.1401242\ttotal: 33.6s\tremaining: 2.68s\n",
      "926:\tlearn: 0.1400483\ttotal: 33.6s\tremaining: 2.65s\n",
      "927:\tlearn: 0.1399974\ttotal: 33.7s\tremaining: 2.61s\n",
      "928:\tlearn: 0.1398902\ttotal: 33.7s\tremaining: 2.58s\n",
      "929:\tlearn: 0.1397897\ttotal: 33.8s\tremaining: 2.54s\n",
      "930:\tlearn: 0.1396037\ttotal: 33.8s\tremaining: 2.5s\n",
      "931:\tlearn: 0.1394499\ttotal: 33.8s\tremaining: 2.47s\n",
      "932:\tlearn: 0.1392938\ttotal: 33.9s\tremaining: 2.43s\n",
      "933:\tlearn: 0.1392322\ttotal: 33.9s\tremaining: 2.4s\n",
      "934:\tlearn: 0.1391365\ttotal: 33.9s\tremaining: 2.36s\n",
      "935:\tlearn: 0.1390772\ttotal: 34s\tremaining: 2.32s\n",
      "936:\tlearn: 0.1389338\ttotal: 34s\tremaining: 2.29s\n",
      "937:\tlearn: 0.1388507\ttotal: 34.1s\tremaining: 2.25s\n",
      "938:\tlearn: 0.1387838\ttotal: 34.1s\tremaining: 2.21s\n",
      "939:\tlearn: 0.1387394\ttotal: 34.1s\tremaining: 2.18s\n",
      "940:\tlearn: 0.1386078\ttotal: 34.2s\tremaining: 2.14s\n",
      "941:\tlearn: 0.1385532\ttotal: 34.2s\tremaining: 2.1s\n",
      "942:\tlearn: 0.1384692\ttotal: 34.2s\tremaining: 2.07s\n",
      "943:\tlearn: 0.1383743\ttotal: 34.3s\tremaining: 2.03s\n",
      "944:\tlearn: 0.1383036\ttotal: 34.3s\tremaining: 2s\n",
      "945:\tlearn: 0.1382229\ttotal: 34.4s\tremaining: 1.96s\n",
      "946:\tlearn: 0.1380585\ttotal: 34.4s\tremaining: 1.92s\n",
      "947:\tlearn: 0.1380262\ttotal: 34.4s\tremaining: 1.89s\n",
      "948:\tlearn: 0.1379657\ttotal: 34.5s\tremaining: 1.85s\n",
      "949:\tlearn: 0.1379165\ttotal: 34.5s\tremaining: 1.81s\n",
      "950:\tlearn: 0.1378628\ttotal: 34.5s\tremaining: 1.78s\n",
      "951:\tlearn: 0.1377789\ttotal: 34.6s\tremaining: 1.74s\n",
      "952:\tlearn: 0.1376392\ttotal: 34.6s\tremaining: 1.71s\n",
      "953:\tlearn: 0.1375272\ttotal: 34.6s\tremaining: 1.67s\n",
      "954:\tlearn: 0.1374771\ttotal: 34.7s\tremaining: 1.63s\n",
      "955:\tlearn: 0.1374138\ttotal: 34.7s\tremaining: 1.6s\n",
      "956:\tlearn: 0.1372950\ttotal: 34.8s\tremaining: 1.56s\n",
      "957:\tlearn: 0.1372153\ttotal: 34.8s\tremaining: 1.52s\n",
      "958:\tlearn: 0.1370959\ttotal: 34.8s\tremaining: 1.49s\n",
      "959:\tlearn: 0.1370318\ttotal: 34.9s\tremaining: 1.45s\n",
      "960:\tlearn: 0.1369165\ttotal: 34.9s\tremaining: 1.42s\n",
      "961:\tlearn: 0.1368589\ttotal: 34.9s\tremaining: 1.38s\n",
      "962:\tlearn: 0.1368000\ttotal: 35s\tremaining: 1.34s\n",
      "963:\tlearn: 0.1367139\ttotal: 35s\tremaining: 1.31s\n",
      "964:\tlearn: 0.1366418\ttotal: 35s\tremaining: 1.27s\n",
      "965:\tlearn: 0.1365274\ttotal: 35.1s\tremaining: 1.23s\n",
      "966:\tlearn: 0.1364784\ttotal: 35.1s\tremaining: 1.2s\n",
      "967:\tlearn: 0.1363956\ttotal: 35.2s\tremaining: 1.16s\n",
      "968:\tlearn: 0.1363408\ttotal: 35.2s\tremaining: 1.13s\n",
      "969:\tlearn: 0.1362521\ttotal: 35.2s\tremaining: 1.09s\n",
      "970:\tlearn: 0.1362326\ttotal: 35.3s\tremaining: 1.05s\n",
      "971:\tlearn: 0.1361790\ttotal: 35.3s\tremaining: 1.02s\n",
      "972:\tlearn: 0.1360915\ttotal: 35.3s\tremaining: 980ms\n",
      "973:\tlearn: 0.1360123\ttotal: 35.4s\tremaining: 944ms\n",
      "974:\tlearn: 0.1359380\ttotal: 35.4s\tremaining: 908ms\n",
      "975:\tlearn: 0.1358281\ttotal: 35.4s\tremaining: 872ms\n",
      "976:\tlearn: 0.1356411\ttotal: 35.5s\tremaining: 835ms\n",
      "977:\tlearn: 0.1355676\ttotal: 35.5s\tremaining: 799ms\n",
      "978:\tlearn: 0.1354570\ttotal: 35.6s\tremaining: 763ms\n",
      "979:\tlearn: 0.1354285\ttotal: 35.6s\tremaining: 726ms\n",
      "980:\tlearn: 0.1353689\ttotal: 35.6s\tremaining: 690ms\n",
      "981:\tlearn: 0.1353059\ttotal: 35.7s\tremaining: 654ms\n",
      "982:\tlearn: 0.1352355\ttotal: 35.7s\tremaining: 618ms\n",
      "983:\tlearn: 0.1351430\ttotal: 35.7s\tremaining: 581ms\n",
      "984:\tlearn: 0.1350898\ttotal: 35.8s\tremaining: 545ms\n",
      "985:\tlearn: 0.1350160\ttotal: 35.8s\tremaining: 509ms\n",
      "986:\tlearn: 0.1349689\ttotal: 35.9s\tremaining: 472ms\n",
      "987:\tlearn: 0.1348461\ttotal: 35.9s\tremaining: 436ms\n",
      "988:\tlearn: 0.1347741\ttotal: 35.9s\tremaining: 400ms\n",
      "989:\tlearn: 0.1346817\ttotal: 36s\tremaining: 363ms\n",
      "990:\tlearn: 0.1346564\ttotal: 36s\tremaining: 327ms\n",
      "991:\tlearn: 0.1346122\ttotal: 36s\tremaining: 291ms\n",
      "992:\tlearn: 0.1345309\ttotal: 36.1s\tremaining: 254ms\n",
      "993:\tlearn: 0.1344827\ttotal: 36.1s\tremaining: 218ms\n",
      "994:\tlearn: 0.1344058\ttotal: 36.2s\tremaining: 182ms\n",
      "995:\tlearn: 0.1342988\ttotal: 36.2s\tremaining: 145ms\n",
      "996:\tlearn: 0.1342326\ttotal: 36.2s\tremaining: 109ms\n",
      "997:\tlearn: 0.1341114\ttotal: 36.3s\tremaining: 72.7ms\n",
      "998:\tlearn: 0.1340185\ttotal: 36.3s\tremaining: 36.3ms\n",
      "999:\tlearn: 0.1338484\ttotal: 36.3s\tremaining: 0us\n",
      "Learning rate set to 0.09175\n",
      "0:\tlearn: 1.8180474\ttotal: 36.3ms\tremaining: 36.3s\n",
      "1:\tlearn: 1.5892909\ttotal: 70.5ms\tremaining: 35.2s\n",
      "2:\tlearn: 1.4265701\ttotal: 106ms\tremaining: 35.3s\n",
      "3:\tlearn: 1.3224507\ttotal: 158ms\tremaining: 39.4s\n",
      "4:\tlearn: 1.2285163\ttotal: 201ms\tremaining: 39.9s\n",
      "5:\tlearn: 1.1609068\ttotal: 241ms\tremaining: 39.9s\n",
      "6:\tlearn: 1.0980170\ttotal: 282ms\tremaining: 40.1s\n",
      "7:\tlearn: 1.0415242\ttotal: 317ms\tremaining: 39.3s\n",
      "8:\tlearn: 0.9860302\ttotal: 353ms\tremaining: 38.8s\n",
      "9:\tlearn: 0.9483839\ttotal: 386ms\tremaining: 38.2s\n",
      "10:\tlearn: 0.9052943\ttotal: 423ms\tremaining: 38s\n",
      "11:\tlearn: 0.8676588\ttotal: 473ms\tremaining: 39s\n",
      "12:\tlearn: 0.8406385\ttotal: 523ms\tremaining: 39.7s\n",
      "13:\tlearn: 0.8107944\ttotal: 564ms\tremaining: 39.7s\n",
      "14:\tlearn: 0.7847236\ttotal: 602ms\tremaining: 39.6s\n",
      "15:\tlearn: 0.7635900\ttotal: 645ms\tremaining: 39.7s\n",
      "16:\tlearn: 0.7384403\ttotal: 689ms\tremaining: 39.8s\n",
      "17:\tlearn: 0.7181667\ttotal: 725ms\tremaining: 39.5s\n",
      "18:\tlearn: 0.6973395\ttotal: 765ms\tremaining: 39.5s\n",
      "19:\tlearn: 0.6834191\ttotal: 807ms\tremaining: 39.5s\n",
      "20:\tlearn: 0.6666048\ttotal: 855ms\tremaining: 39.9s\n",
      "21:\tlearn: 0.6502289\ttotal: 900ms\tremaining: 40s\n",
      "22:\tlearn: 0.6324951\ttotal: 938ms\tremaining: 39.8s\n",
      "23:\tlearn: 0.6199127\ttotal: 974ms\tremaining: 39.6s\n",
      "24:\tlearn: 0.6081524\ttotal: 1.02s\tremaining: 39.6s\n",
      "25:\tlearn: 0.5956008\ttotal: 1.05s\tremaining: 39.4s\n",
      "26:\tlearn: 0.5825114\ttotal: 1.09s\tremaining: 39.4s\n",
      "27:\tlearn: 0.5728717\ttotal: 1.13s\tremaining: 39.3s\n",
      "28:\tlearn: 0.5636501\ttotal: 1.18s\tremaining: 39.6s\n",
      "29:\tlearn: 0.5536135\ttotal: 1.23s\tremaining: 39.9s\n",
      "30:\tlearn: 0.5456376\ttotal: 1.27s\tremaining: 39.6s\n",
      "31:\tlearn: 0.5339731\ttotal: 1.31s\tremaining: 39.5s\n",
      "32:\tlearn: 0.5259740\ttotal: 1.34s\tremaining: 39.4s\n",
      "33:\tlearn: 0.5191328\ttotal: 1.38s\tremaining: 39.3s\n",
      "34:\tlearn: 0.5110196\ttotal: 1.42s\tremaining: 39.2s\n",
      "35:\tlearn: 0.5023578\ttotal: 1.46s\tremaining: 39.1s\n",
      "36:\tlearn: 0.4943478\ttotal: 1.5s\tremaining: 39s\n",
      "37:\tlearn: 0.4881030\ttotal: 1.53s\tremaining: 38.8s\n",
      "38:\tlearn: 0.4829372\ttotal: 1.56s\tremaining: 38.5s\n",
      "39:\tlearn: 0.4763496\ttotal: 1.6s\tremaining: 38.3s\n",
      "40:\tlearn: 0.4733933\ttotal: 1.63s\tremaining: 38.1s\n",
      "41:\tlearn: 0.4695875\ttotal: 1.67s\tremaining: 38.1s\n",
      "42:\tlearn: 0.4642704\ttotal: 1.71s\tremaining: 38.1s\n",
      "43:\tlearn: 0.4616658\ttotal: 1.75s\tremaining: 38s\n",
      "44:\tlearn: 0.4556023\ttotal: 1.78s\tremaining: 37.8s\n",
      "45:\tlearn: 0.4525385\ttotal: 1.81s\tremaining: 37.6s\n",
      "46:\tlearn: 0.4471555\ttotal: 1.85s\tremaining: 37.5s\n",
      "47:\tlearn: 0.4438378\ttotal: 1.89s\tremaining: 37.4s\n",
      "48:\tlearn: 0.4393262\ttotal: 1.92s\tremaining: 37.3s\n",
      "49:\tlearn: 0.4355677\ttotal: 1.96s\tremaining: 37.3s\n",
      "50:\tlearn: 0.4320235\ttotal: 2s\tremaining: 37.2s\n",
      "51:\tlearn: 0.4302992\ttotal: 2.03s\tremaining: 37s\n",
      "52:\tlearn: 0.4274322\ttotal: 2.06s\tremaining: 36.8s\n",
      "53:\tlearn: 0.4257763\ttotal: 2.09s\tremaining: 36.7s\n",
      "54:\tlearn: 0.4214517\ttotal: 2.13s\tremaining: 36.6s\n",
      "55:\tlearn: 0.4186009\ttotal: 2.18s\tremaining: 36.7s\n",
      "56:\tlearn: 0.4168562\ttotal: 2.22s\tremaining: 36.8s\n",
      "57:\tlearn: 0.4143333\ttotal: 2.26s\tremaining: 36.6s\n",
      "58:\tlearn: 0.4111319\ttotal: 2.29s\tremaining: 36.5s\n",
      "59:\tlearn: 0.4084466\ttotal: 2.32s\tremaining: 36.4s\n",
      "60:\tlearn: 0.4060423\ttotal: 2.35s\tremaining: 36.2s\n",
      "61:\tlearn: 0.4040769\ttotal: 2.39s\tremaining: 36.1s\n",
      "62:\tlearn: 0.4021598\ttotal: 2.42s\tremaining: 36s\n",
      "63:\tlearn: 0.3991036\ttotal: 2.46s\tremaining: 36s\n",
      "64:\tlearn: 0.3969991\ttotal: 2.5s\tremaining: 35.9s\n",
      "65:\tlearn: 0.3951593\ttotal: 2.53s\tremaining: 35.8s\n",
      "66:\tlearn: 0.3928472\ttotal: 2.56s\tremaining: 35.7s\n",
      "67:\tlearn: 0.3894482\ttotal: 2.59s\tremaining: 35.6s\n",
      "68:\tlearn: 0.3873748\ttotal: 2.63s\tremaining: 35.5s\n",
      "69:\tlearn: 0.3850957\ttotal: 2.66s\tremaining: 35.4s\n",
      "70:\tlearn: 0.3839306\ttotal: 2.71s\tremaining: 35.4s\n",
      "71:\tlearn: 0.3821716\ttotal: 2.75s\tremaining: 35.4s\n",
      "72:\tlearn: 0.3806725\ttotal: 2.78s\tremaining: 35.3s\n",
      "73:\tlearn: 0.3793081\ttotal: 2.81s\tremaining: 35.2s\n",
      "74:\tlearn: 0.3766140\ttotal: 2.86s\tremaining: 35.2s\n",
      "75:\tlearn: 0.3743855\ttotal: 2.89s\tremaining: 35.2s\n",
      "76:\tlearn: 0.3723534\ttotal: 2.93s\tremaining: 35.1s\n",
      "77:\tlearn: 0.3711433\ttotal: 2.96s\tremaining: 35s\n",
      "78:\tlearn: 0.3686052\ttotal: 3s\tremaining: 35s\n",
      "79:\tlearn: 0.3667699\ttotal: 3.05s\tremaining: 35s\n",
      "80:\tlearn: 0.3658023\ttotal: 3.08s\tremaining: 35s\n",
      "81:\tlearn: 0.3641586\ttotal: 3.12s\tremaining: 34.9s\n",
      "82:\tlearn: 0.3632890\ttotal: 3.15s\tremaining: 34.8s\n",
      "83:\tlearn: 0.3623462\ttotal: 3.18s\tremaining: 34.7s\n",
      "84:\tlearn: 0.3607176\ttotal: 3.21s\tremaining: 34.6s\n",
      "85:\tlearn: 0.3577631\ttotal: 3.25s\tremaining: 34.6s\n",
      "86:\tlearn: 0.3566229\ttotal: 3.29s\tremaining: 34.6s\n",
      "87:\tlearn: 0.3544857\ttotal: 3.33s\tremaining: 34.5s\n",
      "88:\tlearn: 0.3537809\ttotal: 3.36s\tremaining: 34.4s\n",
      "89:\tlearn: 0.3526624\ttotal: 3.4s\tremaining: 34.3s\n",
      "90:\tlearn: 0.3513738\ttotal: 3.43s\tremaining: 34.2s\n",
      "91:\tlearn: 0.3492578\ttotal: 3.46s\tremaining: 34.2s\n",
      "92:\tlearn: 0.3483776\ttotal: 3.51s\tremaining: 34.2s\n",
      "93:\tlearn: 0.3470571\ttotal: 3.55s\tremaining: 34.2s\n",
      "94:\tlearn: 0.3458598\ttotal: 3.58s\tremaining: 34.1s\n",
      "95:\tlearn: 0.3447461\ttotal: 3.62s\tremaining: 34.1s\n",
      "96:\tlearn: 0.3432822\ttotal: 3.65s\tremaining: 34s\n",
      "97:\tlearn: 0.3420673\ttotal: 3.69s\tremaining: 33.9s\n",
      "98:\tlearn: 0.3411189\ttotal: 3.73s\tremaining: 33.9s\n",
      "99:\tlearn: 0.3399132\ttotal: 3.77s\tremaining: 33.9s\n",
      "100:\tlearn: 0.3387271\ttotal: 3.8s\tremaining: 33.9s\n",
      "101:\tlearn: 0.3378171\ttotal: 3.84s\tremaining: 33.8s\n",
      "102:\tlearn: 0.3364961\ttotal: 3.87s\tremaining: 33.7s\n",
      "103:\tlearn: 0.3360791\ttotal: 3.9s\tremaining: 33.6s\n",
      "104:\tlearn: 0.3340403\ttotal: 3.94s\tremaining: 33.6s\n",
      "105:\tlearn: 0.3331484\ttotal: 3.99s\tremaining: 33.6s\n",
      "106:\tlearn: 0.3318974\ttotal: 4.03s\tremaining: 33.6s\n",
      "107:\tlearn: 0.3313917\ttotal: 4.06s\tremaining: 33.5s\n",
      "108:\tlearn: 0.3304085\ttotal: 4.09s\tremaining: 33.4s\n",
      "109:\tlearn: 0.3299229\ttotal: 4.12s\tremaining: 33.4s\n",
      "110:\tlearn: 0.3286447\ttotal: 4.16s\tremaining: 33.3s\n",
      "111:\tlearn: 0.3270331\ttotal: 4.19s\tremaining: 33.2s\n",
      "112:\tlearn: 0.3262664\ttotal: 4.23s\tremaining: 33.2s\n",
      "113:\tlearn: 0.3250591\ttotal: 4.26s\tremaining: 33.2s\n",
      "114:\tlearn: 0.3245446\ttotal: 4.3s\tremaining: 33.1s\n",
      "115:\tlearn: 0.3238549\ttotal: 4.33s\tremaining: 33s\n",
      "116:\tlearn: 0.3234331\ttotal: 4.36s\tremaining: 32.9s\n",
      "117:\tlearn: 0.3230591\ttotal: 4.39s\tremaining: 32.8s\n",
      "118:\tlearn: 0.3227203\ttotal: 4.42s\tremaining: 32.7s\n",
      "119:\tlearn: 0.3216526\ttotal: 4.46s\tremaining: 32.7s\n",
      "120:\tlearn: 0.3206191\ttotal: 4.51s\tremaining: 32.8s\n",
      "121:\tlearn: 0.3192928\ttotal: 4.55s\tremaining: 32.7s\n",
      "122:\tlearn: 0.3183816\ttotal: 4.58s\tremaining: 32.7s\n",
      "123:\tlearn: 0.3172179\ttotal: 4.61s\tremaining: 32.6s\n",
      "124:\tlearn: 0.3167462\ttotal: 4.65s\tremaining: 32.5s\n",
      "125:\tlearn: 0.3161140\ttotal: 4.68s\tremaining: 32.4s\n",
      "126:\tlearn: 0.3150319\ttotal: 4.71s\tremaining: 32.4s\n",
      "127:\tlearn: 0.3140016\ttotal: 4.75s\tremaining: 32.3s\n",
      "128:\tlearn: 0.3127624\ttotal: 4.79s\tremaining: 32.3s\n",
      "129:\tlearn: 0.3122785\ttotal: 4.82s\tremaining: 32.3s\n",
      "130:\tlearn: 0.3117914\ttotal: 4.85s\tremaining: 32.2s\n",
      "131:\tlearn: 0.3113161\ttotal: 4.89s\tremaining: 32.1s\n",
      "132:\tlearn: 0.3102356\ttotal: 4.92s\tremaining: 32.1s\n",
      "133:\tlearn: 0.3095955\ttotal: 4.95s\tremaining: 32s\n",
      "134:\tlearn: 0.3091356\ttotal: 5s\tremaining: 32s\n",
      "135:\tlearn: 0.3084301\ttotal: 5.04s\tremaining: 32s\n",
      "136:\tlearn: 0.3076858\ttotal: 5.07s\tremaining: 31.9s\n",
      "137:\tlearn: 0.3070967\ttotal: 5.11s\tremaining: 31.9s\n",
      "138:\tlearn: 0.3059461\ttotal: 5.15s\tremaining: 31.9s\n",
      "139:\tlearn: 0.3054484\ttotal: 5.18s\tremaining: 31.8s\n",
      "140:\tlearn: 0.3050059\ttotal: 5.21s\tremaining: 31.8s\n",
      "141:\tlearn: 0.3044584\ttotal: 5.25s\tremaining: 31.7s\n",
      "142:\tlearn: 0.3041634\ttotal: 5.28s\tremaining: 31.6s\n",
      "143:\tlearn: 0.3029806\ttotal: 5.33s\tremaining: 31.7s\n",
      "144:\tlearn: 0.3025965\ttotal: 5.37s\tremaining: 31.7s\n",
      "145:\tlearn: 0.3016262\ttotal: 5.4s\tremaining: 31.6s\n",
      "146:\tlearn: 0.3007060\ttotal: 5.44s\tremaining: 31.6s\n",
      "147:\tlearn: 0.3003460\ttotal: 5.47s\tremaining: 31.5s\n",
      "148:\tlearn: 0.2999116\ttotal: 5.5s\tremaining: 31.4s\n",
      "149:\tlearn: 0.2991719\ttotal: 5.54s\tremaining: 31.4s\n",
      "150:\tlearn: 0.2985419\ttotal: 5.57s\tremaining: 31.3s\n",
      "151:\tlearn: 0.2977080\ttotal: 5.61s\tremaining: 31.3s\n",
      "152:\tlearn: 0.2970884\ttotal: 5.65s\tremaining: 31.3s\n",
      "153:\tlearn: 0.2967747\ttotal: 5.68s\tremaining: 31.2s\n",
      "154:\tlearn: 0.2962482\ttotal: 5.71s\tremaining: 31.1s\n",
      "155:\tlearn: 0.2958105\ttotal: 5.74s\tremaining: 31.1s\n",
      "156:\tlearn: 0.2954685\ttotal: 5.78s\tremaining: 31s\n",
      "157:\tlearn: 0.2952503\ttotal: 5.81s\tremaining: 31s\n",
      "158:\tlearn: 0.2942958\ttotal: 5.85s\tremaining: 30.9s\n",
      "159:\tlearn: 0.2934919\ttotal: 5.89s\tremaining: 31s\n",
      "160:\tlearn: 0.2928456\ttotal: 5.93s\tremaining: 30.9s\n",
      "161:\tlearn: 0.2925924\ttotal: 5.96s\tremaining: 30.8s\n",
      "162:\tlearn: 0.2923114\ttotal: 5.99s\tremaining: 30.7s\n",
      "163:\tlearn: 0.2914822\ttotal: 6.02s\tremaining: 30.7s\n",
      "164:\tlearn: 0.2909674\ttotal: 6.05s\tremaining: 30.6s\n",
      "165:\tlearn: 0.2903026\ttotal: 6.09s\tremaining: 30.6s\n",
      "166:\tlearn: 0.2893748\ttotal: 6.13s\tremaining: 30.6s\n",
      "167:\tlearn: 0.2885810\ttotal: 6.17s\tremaining: 30.5s\n",
      "168:\tlearn: 0.2883038\ttotal: 6.2s\tremaining: 30.5s\n",
      "169:\tlearn: 0.2874206\ttotal: 6.23s\tremaining: 30.4s\n",
      "170:\tlearn: 0.2869905\ttotal: 6.26s\tremaining: 30.4s\n",
      "171:\tlearn: 0.2861118\ttotal: 6.3s\tremaining: 30.3s\n",
      "172:\tlearn: 0.2852255\ttotal: 6.34s\tremaining: 30.3s\n",
      "173:\tlearn: 0.2842507\ttotal: 6.39s\tremaining: 30.3s\n",
      "174:\tlearn: 0.2836921\ttotal: 6.43s\tremaining: 30.3s\n",
      "175:\tlearn: 0.2829549\ttotal: 6.47s\tremaining: 30.3s\n",
      "176:\tlearn: 0.2827537\ttotal: 6.5s\tremaining: 30.2s\n",
      "177:\tlearn: 0.2823462\ttotal: 6.53s\tremaining: 30.2s\n",
      "178:\tlearn: 0.2815955\ttotal: 6.56s\tremaining: 30.1s\n",
      "179:\tlearn: 0.2814593\ttotal: 6.59s\tremaining: 30s\n",
      "180:\tlearn: 0.2808687\ttotal: 6.63s\tremaining: 30s\n",
      "181:\tlearn: 0.2806603\ttotal: 6.67s\tremaining: 30s\n",
      "182:\tlearn: 0.2799785\ttotal: 6.71s\tremaining: 30s\n",
      "183:\tlearn: 0.2795033\ttotal: 6.75s\tremaining: 29.9s\n",
      "184:\tlearn: 0.2792174\ttotal: 6.78s\tremaining: 29.9s\n",
      "185:\tlearn: 0.2787456\ttotal: 6.81s\tremaining: 29.8s\n",
      "186:\tlearn: 0.2782177\ttotal: 6.84s\tremaining: 29.8s\n",
      "187:\tlearn: 0.2775444\ttotal: 6.88s\tremaining: 29.7s\n",
      "188:\tlearn: 0.2773067\ttotal: 6.91s\tremaining: 29.6s\n",
      "189:\tlearn: 0.2768746\ttotal: 6.95s\tremaining: 29.6s\n",
      "190:\tlearn: 0.2766015\ttotal: 6.99s\tremaining: 29.6s\n",
      "191:\tlearn: 0.2759029\ttotal: 7.02s\tremaining: 29.6s\n",
      "192:\tlearn: 0.2750809\ttotal: 7.05s\tremaining: 29.5s\n",
      "193:\tlearn: 0.2749145\ttotal: 7.08s\tremaining: 29.4s\n",
      "194:\tlearn: 0.2745258\ttotal: 7.12s\tremaining: 29.4s\n",
      "195:\tlearn: 0.2742895\ttotal: 7.15s\tremaining: 29.3s\n",
      "196:\tlearn: 0.2737370\ttotal: 7.19s\tremaining: 29.3s\n",
      "197:\tlearn: 0.2736105\ttotal: 7.23s\tremaining: 29.3s\n",
      "198:\tlearn: 0.2735188\ttotal: 7.27s\tremaining: 29.3s\n",
      "199:\tlearn: 0.2729666\ttotal: 7.3s\tremaining: 29.2s\n",
      "200:\tlearn: 0.2721563\ttotal: 7.33s\tremaining: 29.1s\n",
      "201:\tlearn: 0.2716758\ttotal: 7.37s\tremaining: 29.1s\n",
      "202:\tlearn: 0.2713219\ttotal: 7.4s\tremaining: 29s\n",
      "203:\tlearn: 0.2706496\ttotal: 7.43s\tremaining: 29s\n",
      "204:\tlearn: 0.2703350\ttotal: 7.47s\tremaining: 29s\n",
      "205:\tlearn: 0.2701176\ttotal: 7.51s\tremaining: 28.9s\n",
      "206:\tlearn: 0.2696309\ttotal: 7.54s\tremaining: 28.9s\n",
      "207:\tlearn: 0.2687787\ttotal: 7.58s\tremaining: 28.8s\n",
      "208:\tlearn: 0.2681506\ttotal: 7.61s\tremaining: 28.8s\n",
      "209:\tlearn: 0.2674538\ttotal: 7.64s\tremaining: 28.7s\n",
      "210:\tlearn: 0.2670809\ttotal: 7.68s\tremaining: 28.7s\n",
      "211:\tlearn: 0.2668250\ttotal: 7.72s\tremaining: 28.7s\n",
      "212:\tlearn: 0.2666016\ttotal: 7.75s\tremaining: 28.7s\n",
      "213:\tlearn: 0.2661010\ttotal: 7.79s\tremaining: 28.6s\n",
      "214:\tlearn: 0.2656426\ttotal: 7.82s\tremaining: 28.6s\n",
      "215:\tlearn: 0.2651561\ttotal: 7.86s\tremaining: 28.5s\n",
      "216:\tlearn: 0.2646062\ttotal: 7.89s\tremaining: 28.5s\n",
      "217:\tlearn: 0.2644784\ttotal: 7.92s\tremaining: 28.4s\n",
      "218:\tlearn: 0.2640067\ttotal: 7.96s\tremaining: 28.4s\n",
      "219:\tlearn: 0.2635720\ttotal: 7.99s\tremaining: 28.3s\n",
      "220:\tlearn: 0.2630333\ttotal: 8.03s\tremaining: 28.3s\n",
      "221:\tlearn: 0.2625437\ttotal: 8.06s\tremaining: 28.3s\n",
      "222:\tlearn: 0.2619428\ttotal: 8.1s\tremaining: 28.2s\n",
      "223:\tlearn: 0.2616440\ttotal: 8.13s\tremaining: 28.2s\n",
      "224:\tlearn: 0.2609235\ttotal: 8.16s\tremaining: 28.1s\n",
      "225:\tlearn: 0.2603809\ttotal: 8.2s\tremaining: 28.1s\n",
      "226:\tlearn: 0.2594670\ttotal: 8.24s\tremaining: 28s\n",
      "227:\tlearn: 0.2592017\ttotal: 8.29s\tremaining: 28.1s\n",
      "228:\tlearn: 0.2589000\ttotal: 8.32s\tremaining: 28s\n",
      "229:\tlearn: 0.2586039\ttotal: 8.35s\tremaining: 28s\n",
      "230:\tlearn: 0.2579111\ttotal: 8.38s\tremaining: 27.9s\n",
      "231:\tlearn: 0.2575503\ttotal: 8.42s\tremaining: 27.9s\n",
      "232:\tlearn: 0.2569700\ttotal: 8.46s\tremaining: 27.8s\n",
      "233:\tlearn: 0.2568367\ttotal: 8.48s\tremaining: 27.8s\n",
      "234:\tlearn: 0.2567240\ttotal: 8.53s\tremaining: 27.8s\n",
      "235:\tlearn: 0.2563506\ttotal: 8.56s\tremaining: 27.7s\n",
      "236:\tlearn: 0.2560046\ttotal: 8.59s\tremaining: 27.7s\n",
      "237:\tlearn: 0.2557118\ttotal: 8.63s\tremaining: 27.6s\n",
      "238:\tlearn: 0.2550891\ttotal: 8.66s\tremaining: 27.6s\n",
      "239:\tlearn: 0.2545400\ttotal: 8.69s\tremaining: 27.5s\n",
      "240:\tlearn: 0.2544194\ttotal: 8.73s\tremaining: 27.5s\n",
      "241:\tlearn: 0.2539943\ttotal: 8.78s\tremaining: 27.5s\n",
      "242:\tlearn: 0.2536573\ttotal: 8.81s\tremaining: 27.5s\n",
      "243:\tlearn: 0.2533797\ttotal: 8.85s\tremaining: 27.4s\n",
      "244:\tlearn: 0.2529217\ttotal: 8.89s\tremaining: 27.4s\n",
      "245:\tlearn: 0.2525689\ttotal: 8.93s\tremaining: 27.4s\n",
      "246:\tlearn: 0.2519720\ttotal: 8.96s\tremaining: 27.3s\n",
      "247:\tlearn: 0.2516084\ttotal: 8.99s\tremaining: 27.3s\n",
      "248:\tlearn: 0.2511247\ttotal: 9.02s\tremaining: 27.2s\n",
      "249:\tlearn: 0.2508664\ttotal: 9.06s\tremaining: 27.2s\n",
      "250:\tlearn: 0.2504383\ttotal: 9.1s\tremaining: 27.2s\n",
      "251:\tlearn: 0.2500402\ttotal: 9.15s\tremaining: 27.2s\n",
      "252:\tlearn: 0.2499783\ttotal: 9.18s\tremaining: 27.1s\n",
      "253:\tlearn: 0.2497803\ttotal: 9.21s\tremaining: 27s\n",
      "254:\tlearn: 0.2495535\ttotal: 9.24s\tremaining: 27s\n",
      "255:\tlearn: 0.2490025\ttotal: 9.27s\tremaining: 27s\n",
      "256:\tlearn: 0.2489046\ttotal: 9.31s\tremaining: 26.9s\n",
      "257:\tlearn: 0.2482584\ttotal: 9.34s\tremaining: 26.9s\n",
      "258:\tlearn: 0.2478236\ttotal: 9.38s\tremaining: 26.8s\n",
      "259:\tlearn: 0.2475366\ttotal: 9.42s\tremaining: 26.8s\n",
      "260:\tlearn: 0.2473323\ttotal: 9.45s\tremaining: 26.8s\n",
      "261:\tlearn: 0.2469429\ttotal: 9.48s\tremaining: 26.7s\n",
      "262:\tlearn: 0.2466292\ttotal: 9.52s\tremaining: 26.7s\n",
      "263:\tlearn: 0.2464260\ttotal: 9.55s\tremaining: 26.6s\n",
      "264:\tlearn: 0.2461303\ttotal: 9.6s\tremaining: 26.6s\n",
      "265:\tlearn: 0.2456327\ttotal: 9.64s\tremaining: 26.6s\n",
      "266:\tlearn: 0.2453319\ttotal: 9.68s\tremaining: 26.6s\n",
      "267:\tlearn: 0.2450039\ttotal: 9.71s\tremaining: 26.5s\n",
      "268:\tlearn: 0.2446371\ttotal: 9.76s\tremaining: 26.5s\n",
      "269:\tlearn: 0.2444055\ttotal: 9.79s\tremaining: 26.5s\n",
      "270:\tlearn: 0.2440478\ttotal: 9.82s\tremaining: 26.4s\n",
      "271:\tlearn: 0.2436486\ttotal: 9.86s\tremaining: 26.4s\n",
      "272:\tlearn: 0.2433046\ttotal: 9.89s\tremaining: 26.3s\n",
      "273:\tlearn: 0.2429026\ttotal: 9.93s\tremaining: 26.3s\n",
      "274:\tlearn: 0.2427653\ttotal: 9.97s\tremaining: 26.3s\n",
      "275:\tlearn: 0.2423093\ttotal: 10s\tremaining: 26.3s\n",
      "276:\tlearn: 0.2420419\ttotal: 10s\tremaining: 26.2s\n",
      "277:\tlearn: 0.2418820\ttotal: 10.1s\tremaining: 26.2s\n",
      "278:\tlearn: 0.2418163\ttotal: 10.1s\tremaining: 26.1s\n",
      "279:\tlearn: 0.2413466\ttotal: 10.2s\tremaining: 26.1s\n",
      "280:\tlearn: 0.2409868\ttotal: 10.2s\tremaining: 26.1s\n",
      "281:\tlearn: 0.2407118\ttotal: 10.2s\tremaining: 26s\n",
      "282:\tlearn: 0.2402273\ttotal: 10.3s\tremaining: 26s\n",
      "283:\tlearn: 0.2397983\ttotal: 10.3s\tremaining: 26s\n",
      "284:\tlearn: 0.2394093\ttotal: 10.3s\tremaining: 25.9s\n",
      "285:\tlearn: 0.2388850\ttotal: 10.4s\tremaining: 25.9s\n",
      "286:\tlearn: 0.2387705\ttotal: 10.4s\tremaining: 25.9s\n",
      "287:\tlearn: 0.2385904\ttotal: 10.4s\tremaining: 25.8s\n",
      "288:\tlearn: 0.2384467\ttotal: 10.5s\tremaining: 25.8s\n",
      "289:\tlearn: 0.2382358\ttotal: 10.5s\tremaining: 25.7s\n",
      "290:\tlearn: 0.2381424\ttotal: 10.5s\tremaining: 25.7s\n",
      "291:\tlearn: 0.2380277\ttotal: 10.6s\tremaining: 25.7s\n",
      "292:\tlearn: 0.2378706\ttotal: 10.6s\tremaining: 25.6s\n",
      "293:\tlearn: 0.2377197\ttotal: 10.6s\tremaining: 25.6s\n",
      "294:\tlearn: 0.2375414\ttotal: 10.7s\tremaining: 25.5s\n",
      "295:\tlearn: 0.2374776\ttotal: 10.7s\tremaining: 25.5s\n",
      "296:\tlearn: 0.2370926\ttotal: 10.7s\tremaining: 25.4s\n",
      "297:\tlearn: 0.2366307\ttotal: 10.8s\tremaining: 25.4s\n",
      "298:\tlearn: 0.2364139\ttotal: 10.8s\tremaining: 25.4s\n",
      "299:\tlearn: 0.2359877\ttotal: 10.9s\tremaining: 25.4s\n",
      "300:\tlearn: 0.2357104\ttotal: 10.9s\tremaining: 25.3s\n",
      "301:\tlearn: 0.2352750\ttotal: 10.9s\tremaining: 25.3s\n",
      "302:\tlearn: 0.2348403\ttotal: 11s\tremaining: 25.2s\n",
      "303:\tlearn: 0.2347252\ttotal: 11s\tremaining: 25.2s\n",
      "304:\tlearn: 0.2345081\ttotal: 11s\tremaining: 25.1s\n",
      "305:\tlearn: 0.2342768\ttotal: 11.1s\tremaining: 25.1s\n",
      "306:\tlearn: 0.2339866\ttotal: 11.1s\tremaining: 25.1s\n",
      "307:\tlearn: 0.2339075\ttotal: 11.1s\tremaining: 25s\n",
      "308:\tlearn: 0.2337747\ttotal: 11.2s\tremaining: 25s\n",
      "309:\tlearn: 0.2335645\ttotal: 11.2s\tremaining: 24.9s\n",
      "310:\tlearn: 0.2330782\ttotal: 11.2s\tremaining: 24.9s\n",
      "311:\tlearn: 0.2327409\ttotal: 11.3s\tremaining: 24.9s\n",
      "312:\tlearn: 0.2321605\ttotal: 11.3s\tremaining: 24.8s\n",
      "313:\tlearn: 0.2318808\ttotal: 11.3s\tremaining: 24.8s\n",
      "314:\tlearn: 0.2315087\ttotal: 11.4s\tremaining: 24.8s\n",
      "315:\tlearn: 0.2313062\ttotal: 11.4s\tremaining: 24.7s\n",
      "316:\tlearn: 0.2312023\ttotal: 11.5s\tremaining: 24.7s\n",
      "317:\tlearn: 0.2307719\ttotal: 11.5s\tremaining: 24.7s\n",
      "318:\tlearn: 0.2305227\ttotal: 11.5s\tremaining: 24.6s\n",
      "319:\tlearn: 0.2302127\ttotal: 11.6s\tremaining: 24.6s\n",
      "320:\tlearn: 0.2300187\ttotal: 11.6s\tremaining: 24.5s\n",
      "321:\tlearn: 0.2298851\ttotal: 11.6s\tremaining: 24.5s\n",
      "322:\tlearn: 0.2295769\ttotal: 11.7s\tremaining: 24.5s\n",
      "323:\tlearn: 0.2293967\ttotal: 11.7s\tremaining: 24.4s\n",
      "324:\tlearn: 0.2292843\ttotal: 11.7s\tremaining: 24.4s\n",
      "325:\tlearn: 0.2287275\ttotal: 11.8s\tremaining: 24.3s\n",
      "326:\tlearn: 0.2284833\ttotal: 11.8s\tremaining: 24.3s\n",
      "327:\tlearn: 0.2281442\ttotal: 11.8s\tremaining: 24.3s\n",
      "328:\tlearn: 0.2279056\ttotal: 11.9s\tremaining: 24.2s\n",
      "329:\tlearn: 0.2275697\ttotal: 11.9s\tremaining: 24.2s\n",
      "330:\tlearn: 0.2272816\ttotal: 12s\tremaining: 24.2s\n",
      "331:\tlearn: 0.2270033\ttotal: 12s\tremaining: 24.1s\n",
      "332:\tlearn: 0.2265168\ttotal: 12s\tremaining: 24.1s\n",
      "333:\tlearn: 0.2261250\ttotal: 12.1s\tremaining: 24s\n",
      "334:\tlearn: 0.2256733\ttotal: 12.1s\tremaining: 24s\n",
      "335:\tlearn: 0.2255195\ttotal: 12.1s\tremaining: 24s\n",
      "336:\tlearn: 0.2253261\ttotal: 12.2s\tremaining: 23.9s\n",
      "337:\tlearn: 0.2251456\ttotal: 12.2s\tremaining: 23.9s\n",
      "338:\tlearn: 0.2249921\ttotal: 12.2s\tremaining: 23.9s\n",
      "339:\tlearn: 0.2247951\ttotal: 12.3s\tremaining: 23.8s\n",
      "340:\tlearn: 0.2243378\ttotal: 12.3s\tremaining: 23.8s\n",
      "341:\tlearn: 0.2242418\ttotal: 12.3s\tremaining: 23.7s\n",
      "342:\tlearn: 0.2240704\ttotal: 12.4s\tremaining: 23.7s\n",
      "343:\tlearn: 0.2237675\ttotal: 12.4s\tremaining: 23.6s\n",
      "344:\tlearn: 0.2234825\ttotal: 12.4s\tremaining: 23.6s\n",
      "345:\tlearn: 0.2232779\ttotal: 12.5s\tremaining: 23.6s\n",
      "346:\tlearn: 0.2231498\ttotal: 12.5s\tremaining: 23.6s\n",
      "347:\tlearn: 0.2228325\ttotal: 12.6s\tremaining: 23.5s\n",
      "348:\tlearn: 0.2224436\ttotal: 12.6s\tremaining: 23.5s\n",
      "349:\tlearn: 0.2223338\ttotal: 12.6s\tremaining: 23.5s\n",
      "350:\tlearn: 0.2217571\ttotal: 12.7s\tremaining: 23.4s\n",
      "351:\tlearn: 0.2215232\ttotal: 12.7s\tremaining: 23.4s\n",
      "352:\tlearn: 0.2212727\ttotal: 12.7s\tremaining: 23.3s\n",
      "353:\tlearn: 0.2210647\ttotal: 12.8s\tremaining: 23.3s\n",
      "354:\tlearn: 0.2208598\ttotal: 12.8s\tremaining: 23.3s\n",
      "355:\tlearn: 0.2206094\ttotal: 12.9s\tremaining: 23.3s\n",
      "356:\tlearn: 0.2202540\ttotal: 12.9s\tremaining: 23.2s\n",
      "357:\tlearn: 0.2200145\ttotal: 12.9s\tremaining: 23.2s\n",
      "358:\tlearn: 0.2197262\ttotal: 13s\tremaining: 23.2s\n",
      "359:\tlearn: 0.2193959\ttotal: 13s\tremaining: 23.1s\n",
      "360:\tlearn: 0.2192744\ttotal: 13s\tremaining: 23.1s\n",
      "361:\tlearn: 0.2189177\ttotal: 13.1s\tremaining: 23s\n",
      "362:\tlearn: 0.2188025\ttotal: 13.1s\tremaining: 23s\n",
      "363:\tlearn: 0.2180260\ttotal: 13.2s\tremaining: 23s\n",
      "364:\tlearn: 0.2176854\ttotal: 13.2s\tremaining: 23s\n",
      "365:\tlearn: 0.2174089\ttotal: 13.2s\tremaining: 22.9s\n",
      "366:\tlearn: 0.2171672\ttotal: 13.3s\tremaining: 22.9s\n",
      "367:\tlearn: 0.2169213\ttotal: 13.3s\tremaining: 22.8s\n",
      "368:\tlearn: 0.2167950\ttotal: 13.3s\tremaining: 22.8s\n",
      "369:\tlearn: 0.2164129\ttotal: 13.4s\tremaining: 22.8s\n",
      "370:\tlearn: 0.2162795\ttotal: 13.4s\tremaining: 22.7s\n",
      "371:\tlearn: 0.2162093\ttotal: 13.5s\tremaining: 22.7s\n",
      "372:\tlearn: 0.2159667\ttotal: 13.5s\tremaining: 22.7s\n",
      "373:\tlearn: 0.2157700\ttotal: 13.5s\tremaining: 22.6s\n",
      "374:\tlearn: 0.2155069\ttotal: 13.6s\tremaining: 22.6s\n",
      "375:\tlearn: 0.2152086\ttotal: 13.6s\tremaining: 22.6s\n",
      "376:\tlearn: 0.2150988\ttotal: 13.6s\tremaining: 22.5s\n",
      "377:\tlearn: 0.2149282\ttotal: 13.7s\tremaining: 22.5s\n",
      "378:\tlearn: 0.2147384\ttotal: 13.7s\tremaining: 22.4s\n",
      "379:\tlearn: 0.2145153\ttotal: 13.7s\tremaining: 22.4s\n",
      "380:\tlearn: 0.2142862\ttotal: 13.8s\tremaining: 22.4s\n",
      "381:\tlearn: 0.2140201\ttotal: 13.8s\tremaining: 22.3s\n",
      "382:\tlearn: 0.2138478\ttotal: 13.8s\tremaining: 22.3s\n",
      "383:\tlearn: 0.2136370\ttotal: 13.9s\tremaining: 22.3s\n",
      "384:\tlearn: 0.2134790\ttotal: 13.9s\tremaining: 22.2s\n",
      "385:\tlearn: 0.2133417\ttotal: 13.9s\tremaining: 22.2s\n",
      "386:\tlearn: 0.2131085\ttotal: 14s\tremaining: 22.1s\n",
      "387:\tlearn: 0.2126582\ttotal: 14s\tremaining: 22.1s\n",
      "388:\tlearn: 0.2125109\ttotal: 14s\tremaining: 22.1s\n",
      "389:\tlearn: 0.2123816\ttotal: 14.1s\tremaining: 22s\n",
      "390:\tlearn: 0.2118618\ttotal: 14.1s\tremaining: 22s\n",
      "391:\tlearn: 0.2118036\ttotal: 14.1s\tremaining: 21.9s\n",
      "392:\tlearn: 0.2116580\ttotal: 14.2s\tremaining: 21.9s\n",
      "393:\tlearn: 0.2113362\ttotal: 14.2s\tremaining: 21.9s\n",
      "394:\tlearn: 0.2112032\ttotal: 14.2s\tremaining: 21.8s\n",
      "395:\tlearn: 0.2109929\ttotal: 14.3s\tremaining: 21.8s\n",
      "396:\tlearn: 0.2107561\ttotal: 14.3s\tremaining: 21.7s\n",
      "397:\tlearn: 0.2105436\ttotal: 14.4s\tremaining: 21.7s\n",
      "398:\tlearn: 0.2102345\ttotal: 14.4s\tremaining: 21.7s\n",
      "399:\tlearn: 0.2099525\ttotal: 14.4s\tremaining: 21.6s\n",
      "400:\tlearn: 0.2096667\ttotal: 14.5s\tremaining: 21.6s\n",
      "401:\tlearn: 0.2095283\ttotal: 14.5s\tremaining: 21.6s\n",
      "402:\tlearn: 0.2094200\ttotal: 14.5s\tremaining: 21.5s\n",
      "403:\tlearn: 0.2092931\ttotal: 14.6s\tremaining: 21.5s\n",
      "404:\tlearn: 0.2090507\ttotal: 14.6s\tremaining: 21.4s\n",
      "405:\tlearn: 0.2087474\ttotal: 14.6s\tremaining: 21.4s\n",
      "406:\tlearn: 0.2086577\ttotal: 14.7s\tremaining: 21.4s\n",
      "407:\tlearn: 0.2084104\ttotal: 14.7s\tremaining: 21.3s\n",
      "408:\tlearn: 0.2080202\ttotal: 14.7s\tremaining: 21.3s\n",
      "409:\tlearn: 0.2077745\ttotal: 14.8s\tremaining: 21.3s\n",
      "410:\tlearn: 0.2076470\ttotal: 14.8s\tremaining: 21.2s\n",
      "411:\tlearn: 0.2073301\ttotal: 14.8s\tremaining: 21.2s\n",
      "412:\tlearn: 0.2070202\ttotal: 14.9s\tremaining: 21.1s\n",
      "413:\tlearn: 0.2067323\ttotal: 14.9s\tremaining: 21.1s\n",
      "414:\tlearn: 0.2066191\ttotal: 15s\tremaining: 21.1s\n",
      "415:\tlearn: 0.2065252\ttotal: 15s\tremaining: 21.1s\n",
      "416:\tlearn: 0.2063725\ttotal: 15s\tremaining: 21s\n",
      "417:\tlearn: 0.2062947\ttotal: 15.1s\tremaining: 21s\n",
      "418:\tlearn: 0.2060512\ttotal: 15.1s\tremaining: 20.9s\n",
      "419:\tlearn: 0.2057377\ttotal: 15.1s\tremaining: 20.9s\n",
      "420:\tlearn: 0.2056213\ttotal: 15.2s\tremaining: 20.9s\n",
      "421:\tlearn: 0.2053047\ttotal: 15.2s\tremaining: 20.8s\n",
      "422:\tlearn: 0.2050098\ttotal: 15.2s\tremaining: 20.8s\n",
      "423:\tlearn: 0.2048959\ttotal: 15.3s\tremaining: 20.8s\n",
      "424:\tlearn: 0.2048324\ttotal: 15.3s\tremaining: 20.7s\n",
      "425:\tlearn: 0.2047145\ttotal: 15.3s\tremaining: 20.7s\n",
      "426:\tlearn: 0.2045640\ttotal: 15.4s\tremaining: 20.7s\n",
      "427:\tlearn: 0.2044680\ttotal: 15.4s\tremaining: 20.6s\n",
      "428:\tlearn: 0.2042988\ttotal: 15.5s\tremaining: 20.6s\n",
      "429:\tlearn: 0.2042594\ttotal: 15.5s\tremaining: 20.5s\n",
      "430:\tlearn: 0.2038609\ttotal: 15.6s\tremaining: 20.5s\n",
      "431:\tlearn: 0.2037350\ttotal: 15.6s\tremaining: 20.5s\n",
      "432:\tlearn: 0.2036672\ttotal: 15.6s\tremaining: 20.5s\n",
      "433:\tlearn: 0.2034626\ttotal: 15.7s\tremaining: 20.4s\n",
      "434:\tlearn: 0.2032169\ttotal: 15.7s\tremaining: 20.4s\n",
      "435:\tlearn: 0.2031033\ttotal: 15.7s\tremaining: 20.4s\n",
      "436:\tlearn: 0.2027453\ttotal: 15.8s\tremaining: 20.3s\n",
      "437:\tlearn: 0.2025903\ttotal: 15.8s\tremaining: 20.3s\n",
      "438:\tlearn: 0.2023920\ttotal: 15.8s\tremaining: 20.2s\n",
      "439:\tlearn: 0.2021700\ttotal: 15.9s\tremaining: 20.2s\n",
      "440:\tlearn: 0.2020428\ttotal: 15.9s\tremaining: 20.2s\n",
      "441:\tlearn: 0.2018411\ttotal: 16s\tremaining: 20.1s\n",
      "442:\tlearn: 0.2016358\ttotal: 16s\tremaining: 20.1s\n",
      "443:\tlearn: 0.2013177\ttotal: 16s\tremaining: 20.1s\n",
      "444:\tlearn: 0.2011641\ttotal: 16.1s\tremaining: 20s\n",
      "445:\tlearn: 0.2008623\ttotal: 16.1s\tremaining: 20s\n",
      "446:\tlearn: 0.2008150\ttotal: 16.1s\tremaining: 19.9s\n",
      "447:\tlearn: 0.2006689\ttotal: 16.2s\tremaining: 19.9s\n",
      "448:\tlearn: 0.2002526\ttotal: 16.2s\tremaining: 19.9s\n",
      "449:\tlearn: 0.1999653\ttotal: 16.2s\tremaining: 19.8s\n",
      "450:\tlearn: 0.1997944\ttotal: 16.3s\tremaining: 19.8s\n",
      "451:\tlearn: 0.1996884\ttotal: 16.3s\tremaining: 19.8s\n",
      "452:\tlearn: 0.1994947\ttotal: 16.3s\tremaining: 19.7s\n",
      "453:\tlearn: 0.1991992\ttotal: 16.4s\tremaining: 19.7s\n",
      "454:\tlearn: 0.1989190\ttotal: 16.4s\tremaining: 19.7s\n",
      "455:\tlearn: 0.1986076\ttotal: 16.5s\tremaining: 19.6s\n",
      "456:\tlearn: 0.1983713\ttotal: 16.5s\tremaining: 19.6s\n",
      "457:\tlearn: 0.1981997\ttotal: 16.5s\tremaining: 19.6s\n",
      "458:\tlearn: 0.1980007\ttotal: 16.6s\tremaining: 19.5s\n",
      "459:\tlearn: 0.1978881\ttotal: 16.6s\tremaining: 19.5s\n",
      "460:\tlearn: 0.1978246\ttotal: 16.6s\tremaining: 19.4s\n",
      "461:\tlearn: 0.1975701\ttotal: 16.7s\tremaining: 19.4s\n",
      "462:\tlearn: 0.1974861\ttotal: 16.7s\tremaining: 19.4s\n",
      "463:\tlearn: 0.1971608\ttotal: 16.7s\tremaining: 19.3s\n",
      "464:\tlearn: 0.1970831\ttotal: 16.8s\tremaining: 19.3s\n",
      "465:\tlearn: 0.1968991\ttotal: 16.8s\tremaining: 19.3s\n",
      "466:\tlearn: 0.1967605\ttotal: 16.8s\tremaining: 19.2s\n",
      "467:\tlearn: 0.1966542\ttotal: 16.9s\tremaining: 19.2s\n",
      "468:\tlearn: 0.1964230\ttotal: 16.9s\tremaining: 19.1s\n",
      "469:\tlearn: 0.1963265\ttotal: 16.9s\tremaining: 19.1s\n",
      "470:\tlearn: 0.1960532\ttotal: 17s\tremaining: 19.1s\n",
      "471:\tlearn: 0.1958372\ttotal: 17s\tremaining: 19s\n",
      "472:\tlearn: 0.1954408\ttotal: 17.1s\tremaining: 19s\n",
      "473:\tlearn: 0.1954060\ttotal: 17.1s\tremaining: 19s\n",
      "474:\tlearn: 0.1953253\ttotal: 17.1s\tremaining: 18.9s\n",
      "475:\tlearn: 0.1952180\ttotal: 17.2s\tremaining: 18.9s\n",
      "476:\tlearn: 0.1949575\ttotal: 17.2s\tremaining: 18.8s\n",
      "477:\tlearn: 0.1946527\ttotal: 17.2s\tremaining: 18.8s\n",
      "478:\tlearn: 0.1942033\ttotal: 17.3s\tremaining: 18.8s\n",
      "479:\tlearn: 0.1939950\ttotal: 17.3s\tremaining: 18.7s\n",
      "480:\tlearn: 0.1938349\ttotal: 17.3s\tremaining: 18.7s\n",
      "481:\tlearn: 0.1935971\ttotal: 17.4s\tremaining: 18.7s\n",
      "482:\tlearn: 0.1933403\ttotal: 17.4s\tremaining: 18.6s\n",
      "483:\tlearn: 0.1933032\ttotal: 17.4s\tremaining: 18.6s\n",
      "484:\tlearn: 0.1930527\ttotal: 17.5s\tremaining: 18.6s\n",
      "485:\tlearn: 0.1927768\ttotal: 17.5s\tremaining: 18.5s\n",
      "486:\tlearn: 0.1926519\ttotal: 17.6s\tremaining: 18.5s\n",
      "487:\tlearn: 0.1925648\ttotal: 17.6s\tremaining: 18.5s\n",
      "488:\tlearn: 0.1923747\ttotal: 17.7s\tremaining: 18.4s\n",
      "489:\tlearn: 0.1920637\ttotal: 17.7s\tremaining: 18.4s\n",
      "490:\tlearn: 0.1919765\ttotal: 17.7s\tremaining: 18.4s\n",
      "491:\tlearn: 0.1916935\ttotal: 17.7s\tremaining: 18.3s\n",
      "492:\tlearn: 0.1914694\ttotal: 17.8s\tremaining: 18.3s\n",
      "493:\tlearn: 0.1913902\ttotal: 17.8s\tremaining: 18.3s\n",
      "494:\tlearn: 0.1912416\ttotal: 17.9s\tremaining: 18.2s\n",
      "495:\tlearn: 0.1910489\ttotal: 17.9s\tremaining: 18.2s\n",
      "496:\tlearn: 0.1907582\ttotal: 17.9s\tremaining: 18.2s\n",
      "497:\tlearn: 0.1906684\ttotal: 18s\tremaining: 18.1s\n",
      "498:\tlearn: 0.1906046\ttotal: 18s\tremaining: 18.1s\n",
      "499:\tlearn: 0.1903983\ttotal: 18.1s\tremaining: 18.1s\n",
      "500:\tlearn: 0.1901400\ttotal: 18.1s\tremaining: 18s\n",
      "501:\tlearn: 0.1900559\ttotal: 18.1s\tremaining: 18s\n",
      "502:\tlearn: 0.1898827\ttotal: 18.1s\tremaining: 17.9s\n",
      "503:\tlearn: 0.1897189\ttotal: 18.2s\tremaining: 17.9s\n",
      "504:\tlearn: 0.1894906\ttotal: 18.2s\tremaining: 17.9s\n",
      "505:\tlearn: 0.1892043\ttotal: 18.3s\tremaining: 17.8s\n",
      "506:\tlearn: 0.1890364\ttotal: 18.3s\tremaining: 17.8s\n",
      "507:\tlearn: 0.1887961\ttotal: 18.4s\tremaining: 17.8s\n",
      "508:\tlearn: 0.1885093\ttotal: 18.4s\tremaining: 17.7s\n",
      "509:\tlearn: 0.1883458\ttotal: 18.4s\tremaining: 17.7s\n",
      "510:\tlearn: 0.1882824\ttotal: 18.5s\tremaining: 17.7s\n",
      "511:\tlearn: 0.1882036\ttotal: 18.5s\tremaining: 17.6s\n",
      "512:\tlearn: 0.1880374\ttotal: 18.5s\tremaining: 17.6s\n",
      "513:\tlearn: 0.1877524\ttotal: 18.6s\tremaining: 17.6s\n",
      "514:\tlearn: 0.1874846\ttotal: 18.6s\tremaining: 17.5s\n",
      "515:\tlearn: 0.1872484\ttotal: 18.6s\tremaining: 17.5s\n",
      "516:\tlearn: 0.1869838\ttotal: 18.7s\tremaining: 17.4s\n",
      "517:\tlearn: 0.1867741\ttotal: 18.7s\tremaining: 17.4s\n",
      "518:\tlearn: 0.1866793\ttotal: 18.7s\tremaining: 17.4s\n",
      "519:\tlearn: 0.1865979\ttotal: 18.8s\tremaining: 17.3s\n",
      "520:\tlearn: 0.1865399\ttotal: 18.8s\tremaining: 17.3s\n",
      "521:\tlearn: 0.1864279\ttotal: 18.9s\tremaining: 17.3s\n",
      "522:\tlearn: 0.1863560\ttotal: 18.9s\tremaining: 17.2s\n",
      "523:\tlearn: 0.1862082\ttotal: 18.9s\tremaining: 17.2s\n",
      "524:\tlearn: 0.1860406\ttotal: 19s\tremaining: 17.2s\n",
      "525:\tlearn: 0.1859586\ttotal: 19s\tremaining: 17.1s\n",
      "526:\tlearn: 0.1857595\ttotal: 19s\tremaining: 17.1s\n",
      "527:\tlearn: 0.1855201\ttotal: 19.1s\tremaining: 17s\n",
      "528:\tlearn: 0.1854135\ttotal: 19.1s\tremaining: 17s\n",
      "529:\tlearn: 0.1852630\ttotal: 19.1s\tremaining: 17s\n",
      "530:\tlearn: 0.1850332\ttotal: 19.2s\tremaining: 16.9s\n",
      "531:\tlearn: 0.1847764\ttotal: 19.2s\tremaining: 16.9s\n",
      "532:\tlearn: 0.1846938\ttotal: 19.2s\tremaining: 16.9s\n",
      "533:\tlearn: 0.1844134\ttotal: 19.3s\tremaining: 16.8s\n",
      "534:\tlearn: 0.1841256\ttotal: 19.3s\tremaining: 16.8s\n",
      "535:\tlearn: 0.1839482\ttotal: 19.4s\tremaining: 16.8s\n",
      "536:\tlearn: 0.1837646\ttotal: 19.4s\tremaining: 16.7s\n",
      "537:\tlearn: 0.1836756\ttotal: 19.4s\tremaining: 16.7s\n",
      "538:\tlearn: 0.1834600\ttotal: 19.5s\tremaining: 16.6s\n",
      "539:\tlearn: 0.1832841\ttotal: 19.5s\tremaining: 16.6s\n",
      "540:\tlearn: 0.1830838\ttotal: 19.5s\tremaining: 16.6s\n",
      "541:\tlearn: 0.1830118\ttotal: 19.6s\tremaining: 16.5s\n",
      "542:\tlearn: 0.1828602\ttotal: 19.6s\tremaining: 16.5s\n",
      "543:\tlearn: 0.1826266\ttotal: 19.6s\tremaining: 16.5s\n",
      "544:\tlearn: 0.1825505\ttotal: 19.7s\tremaining: 16.4s\n",
      "545:\tlearn: 0.1825013\ttotal: 19.7s\tremaining: 16.4s\n",
      "546:\tlearn: 0.1824032\ttotal: 19.8s\tremaining: 16.4s\n",
      "547:\tlearn: 0.1822478\ttotal: 19.8s\tremaining: 16.3s\n",
      "548:\tlearn: 0.1821089\ttotal: 19.8s\tremaining: 16.3s\n",
      "549:\tlearn: 0.1820189\ttotal: 19.8s\tremaining: 16.2s\n",
      "550:\tlearn: 0.1819365\ttotal: 19.9s\tremaining: 16.2s\n",
      "551:\tlearn: 0.1817242\ttotal: 19.9s\tremaining: 16.2s\n",
      "552:\tlearn: 0.1815930\ttotal: 20s\tremaining: 16.1s\n",
      "553:\tlearn: 0.1813802\ttotal: 20s\tremaining: 16.1s\n",
      "554:\tlearn: 0.1813548\ttotal: 20s\tremaining: 16.1s\n",
      "555:\tlearn: 0.1811834\ttotal: 20.1s\tremaining: 16s\n",
      "556:\tlearn: 0.1809791\ttotal: 20.1s\tremaining: 16s\n",
      "557:\tlearn: 0.1807264\ttotal: 20.1s\tremaining: 15.9s\n",
      "558:\tlearn: 0.1806276\ttotal: 20.2s\tremaining: 15.9s\n",
      "559:\tlearn: 0.1805713\ttotal: 20.2s\tremaining: 15.9s\n",
      "560:\tlearn: 0.1804204\ttotal: 20.2s\tremaining: 15.8s\n",
      "561:\tlearn: 0.1802813\ttotal: 20.3s\tremaining: 15.8s\n",
      "562:\tlearn: 0.1801429\ttotal: 20.3s\tremaining: 15.8s\n",
      "563:\tlearn: 0.1799317\ttotal: 20.4s\tremaining: 15.7s\n",
      "564:\tlearn: 0.1798183\ttotal: 20.4s\tremaining: 15.7s\n",
      "565:\tlearn: 0.1796287\ttotal: 20.4s\tremaining: 15.7s\n",
      "566:\tlearn: 0.1794478\ttotal: 20.5s\tremaining: 15.6s\n",
      "567:\tlearn: 0.1792395\ttotal: 20.5s\tremaining: 15.6s\n",
      "568:\tlearn: 0.1791515\ttotal: 20.5s\tremaining: 15.6s\n",
      "569:\tlearn: 0.1791008\ttotal: 20.6s\tremaining: 15.5s\n",
      "570:\tlearn: 0.1790184\ttotal: 20.6s\tremaining: 15.5s\n",
      "571:\tlearn: 0.1788083\ttotal: 20.6s\tremaining: 15.4s\n",
      "572:\tlearn: 0.1786861\ttotal: 20.7s\tremaining: 15.4s\n",
      "573:\tlearn: 0.1785145\ttotal: 20.7s\tremaining: 15.4s\n",
      "574:\tlearn: 0.1784758\ttotal: 20.7s\tremaining: 15.3s\n",
      "575:\tlearn: 0.1782030\ttotal: 20.8s\tremaining: 15.3s\n",
      "576:\tlearn: 0.1780660\ttotal: 20.8s\tremaining: 15.3s\n",
      "577:\tlearn: 0.1780199\ttotal: 20.9s\tremaining: 15.2s\n",
      "578:\tlearn: 0.1778879\ttotal: 20.9s\tremaining: 15.2s\n",
      "579:\tlearn: 0.1777612\ttotal: 20.9s\tremaining: 15.2s\n",
      "580:\tlearn: 0.1775547\ttotal: 21s\tremaining: 15.1s\n",
      "581:\tlearn: 0.1774573\ttotal: 21s\tremaining: 15.1s\n",
      "582:\tlearn: 0.1772894\ttotal: 21s\tremaining: 15.1s\n",
      "583:\tlearn: 0.1769644\ttotal: 21.1s\tremaining: 15s\n",
      "584:\tlearn: 0.1766970\ttotal: 21.1s\tremaining: 15s\n",
      "585:\tlearn: 0.1766041\ttotal: 21.1s\tremaining: 14.9s\n",
      "586:\tlearn: 0.1765131\ttotal: 21.2s\tremaining: 14.9s\n",
      "587:\tlearn: 0.1764484\ttotal: 21.2s\tremaining: 14.9s\n",
      "588:\tlearn: 0.1762893\ttotal: 21.3s\tremaining: 14.8s\n",
      "589:\tlearn: 0.1761867\ttotal: 21.3s\tremaining: 14.8s\n",
      "590:\tlearn: 0.1760762\ttotal: 21.3s\tremaining: 14.8s\n",
      "591:\tlearn: 0.1759178\ttotal: 21.4s\tremaining: 14.7s\n",
      "592:\tlearn: 0.1758301\ttotal: 21.4s\tremaining: 14.7s\n",
      "593:\tlearn: 0.1757275\ttotal: 21.4s\tremaining: 14.7s\n",
      "594:\tlearn: 0.1753856\ttotal: 21.5s\tremaining: 14.6s\n",
      "595:\tlearn: 0.1752502\ttotal: 21.5s\tremaining: 14.6s\n",
      "596:\tlearn: 0.1750614\ttotal: 21.6s\tremaining: 14.6s\n",
      "597:\tlearn: 0.1749454\ttotal: 21.6s\tremaining: 14.5s\n",
      "598:\tlearn: 0.1747264\ttotal: 21.6s\tremaining: 14.5s\n",
      "599:\tlearn: 0.1745284\ttotal: 21.6s\tremaining: 14.4s\n",
      "600:\tlearn: 0.1742678\ttotal: 21.7s\tremaining: 14.4s\n",
      "601:\tlearn: 0.1741004\ttotal: 21.7s\tremaining: 14.4s\n",
      "602:\tlearn: 0.1739815\ttotal: 21.8s\tremaining: 14.3s\n",
      "603:\tlearn: 0.1738990\ttotal: 21.8s\tremaining: 14.3s\n",
      "604:\tlearn: 0.1737933\ttotal: 21.8s\tremaining: 14.3s\n",
      "605:\tlearn: 0.1735994\ttotal: 21.9s\tremaining: 14.2s\n",
      "606:\tlearn: 0.1735063\ttotal: 21.9s\tremaining: 14.2s\n",
      "607:\tlearn: 0.1733644\ttotal: 22s\tremaining: 14.2s\n",
      "608:\tlearn: 0.1731915\ttotal: 22s\tremaining: 14.1s\n",
      "609:\tlearn: 0.1730559\ttotal: 22s\tremaining: 14.1s\n",
      "610:\tlearn: 0.1729581\ttotal: 22.1s\tremaining: 14s\n",
      "611:\tlearn: 0.1726743\ttotal: 22.1s\tremaining: 14s\n",
      "612:\tlearn: 0.1725640\ttotal: 22.1s\tremaining: 14s\n",
      "613:\tlearn: 0.1724166\ttotal: 22.2s\tremaining: 13.9s\n",
      "614:\tlearn: 0.1722342\ttotal: 22.2s\tremaining: 13.9s\n",
      "615:\tlearn: 0.1719939\ttotal: 22.2s\tremaining: 13.9s\n",
      "616:\tlearn: 0.1717437\ttotal: 22.3s\tremaining: 13.8s\n",
      "617:\tlearn: 0.1716129\ttotal: 22.3s\tremaining: 13.8s\n",
      "618:\tlearn: 0.1714243\ttotal: 22.4s\tremaining: 13.8s\n",
      "619:\tlearn: 0.1712246\ttotal: 22.4s\tremaining: 13.7s\n",
      "620:\tlearn: 0.1709870\ttotal: 22.4s\tremaining: 13.7s\n",
      "621:\tlearn: 0.1708768\ttotal: 22.5s\tremaining: 13.7s\n",
      "622:\tlearn: 0.1708041\ttotal: 22.5s\tremaining: 13.6s\n",
      "623:\tlearn: 0.1707096\ttotal: 22.5s\tremaining: 13.6s\n",
      "624:\tlearn: 0.1705909\ttotal: 22.6s\tremaining: 13.5s\n",
      "625:\tlearn: 0.1704986\ttotal: 22.6s\tremaining: 13.5s\n",
      "626:\tlearn: 0.1703801\ttotal: 22.6s\tremaining: 13.5s\n",
      "627:\tlearn: 0.1702008\ttotal: 22.7s\tremaining: 13.4s\n",
      "628:\tlearn: 0.1701384\ttotal: 22.7s\tremaining: 13.4s\n",
      "629:\tlearn: 0.1700645\ttotal: 22.7s\tremaining: 13.4s\n",
      "630:\tlearn: 0.1699826\ttotal: 22.8s\tremaining: 13.3s\n",
      "631:\tlearn: 0.1698899\ttotal: 22.8s\tremaining: 13.3s\n",
      "632:\tlearn: 0.1698005\ttotal: 22.9s\tremaining: 13.3s\n",
      "633:\tlearn: 0.1696970\ttotal: 22.9s\tremaining: 13.2s\n",
      "634:\tlearn: 0.1695938\ttotal: 22.9s\tremaining: 13.2s\n",
      "635:\tlearn: 0.1695095\ttotal: 23s\tremaining: 13.1s\n",
      "636:\tlearn: 0.1694492\ttotal: 23s\tremaining: 13.1s\n",
      "637:\tlearn: 0.1693459\ttotal: 23s\tremaining: 13.1s\n",
      "638:\tlearn: 0.1691928\ttotal: 23.1s\tremaining: 13s\n",
      "639:\tlearn: 0.1689985\ttotal: 23.1s\tremaining: 13s\n",
      "640:\tlearn: 0.1688777\ttotal: 23.1s\tremaining: 13s\n",
      "641:\tlearn: 0.1687158\ttotal: 23.2s\tremaining: 12.9s\n",
      "642:\tlearn: 0.1685517\ttotal: 23.2s\tremaining: 12.9s\n",
      "643:\tlearn: 0.1684582\ttotal: 23.2s\tremaining: 12.8s\n",
      "644:\tlearn: 0.1682819\ttotal: 23.3s\tremaining: 12.8s\n",
      "645:\tlearn: 0.1680247\ttotal: 23.3s\tremaining: 12.8s\n",
      "646:\tlearn: 0.1679457\ttotal: 23.4s\tremaining: 12.7s\n",
      "647:\tlearn: 0.1677520\ttotal: 23.4s\tremaining: 12.7s\n",
      "648:\tlearn: 0.1676514\ttotal: 23.4s\tremaining: 12.7s\n",
      "649:\tlearn: 0.1674998\ttotal: 23.5s\tremaining: 12.6s\n",
      "650:\tlearn: 0.1673152\ttotal: 23.5s\tremaining: 12.6s\n",
      "651:\tlearn: 0.1672329\ttotal: 23.5s\tremaining: 12.6s\n",
      "652:\tlearn: 0.1671275\ttotal: 23.6s\tremaining: 12.5s\n",
      "653:\tlearn: 0.1670242\ttotal: 23.6s\tremaining: 12.5s\n",
      "654:\tlearn: 0.1669126\ttotal: 23.7s\tremaining: 12.5s\n",
      "655:\tlearn: 0.1667623\ttotal: 23.7s\tremaining: 12.4s\n",
      "656:\tlearn: 0.1666911\ttotal: 23.7s\tremaining: 12.4s\n",
      "657:\tlearn: 0.1663635\ttotal: 23.8s\tremaining: 12.3s\n",
      "658:\tlearn: 0.1662716\ttotal: 23.8s\tremaining: 12.3s\n",
      "659:\tlearn: 0.1660658\ttotal: 23.8s\tremaining: 12.3s\n",
      "660:\tlearn: 0.1659349\ttotal: 23.9s\tremaining: 12.2s\n",
      "661:\tlearn: 0.1658789\ttotal: 23.9s\tremaining: 12.2s\n",
      "662:\tlearn: 0.1657212\ttotal: 23.9s\tremaining: 12.2s\n",
      "663:\tlearn: 0.1655368\ttotal: 24s\tremaining: 12.1s\n",
      "664:\tlearn: 0.1654267\ttotal: 24s\tremaining: 12.1s\n",
      "665:\tlearn: 0.1652682\ttotal: 24.1s\tremaining: 12.1s\n",
      "666:\tlearn: 0.1651992\ttotal: 24.1s\tremaining: 12s\n",
      "667:\tlearn: 0.1649944\ttotal: 24.1s\tremaining: 12s\n",
      "668:\tlearn: 0.1647929\ttotal: 24.2s\tremaining: 12s\n",
      "669:\tlearn: 0.1646662\ttotal: 24.2s\tremaining: 11.9s\n",
      "670:\tlearn: 0.1645737\ttotal: 24.2s\tremaining: 11.9s\n",
      "671:\tlearn: 0.1644917\ttotal: 24.3s\tremaining: 11.9s\n",
      "672:\tlearn: 0.1643102\ttotal: 24.3s\tremaining: 11.8s\n",
      "673:\tlearn: 0.1641516\ttotal: 24.4s\tremaining: 11.8s\n",
      "674:\tlearn: 0.1640505\ttotal: 24.4s\tremaining: 11.7s\n",
      "675:\tlearn: 0.1639738\ttotal: 24.4s\tremaining: 11.7s\n",
      "676:\tlearn: 0.1639156\ttotal: 24.5s\tremaining: 11.7s\n",
      "677:\tlearn: 0.1638041\ttotal: 24.5s\tremaining: 11.6s\n",
      "678:\tlearn: 0.1636381\ttotal: 24.5s\tremaining: 11.6s\n",
      "679:\tlearn: 0.1635329\ttotal: 24.6s\tremaining: 11.6s\n",
      "680:\tlearn: 0.1634242\ttotal: 24.6s\tremaining: 11.5s\n",
      "681:\tlearn: 0.1633764\ttotal: 24.6s\tremaining: 11.5s\n",
      "682:\tlearn: 0.1631737\ttotal: 24.7s\tremaining: 11.5s\n",
      "683:\tlearn: 0.1630670\ttotal: 24.7s\tremaining: 11.4s\n",
      "684:\tlearn: 0.1629784\ttotal: 24.7s\tremaining: 11.4s\n",
      "685:\tlearn: 0.1629078\ttotal: 24.8s\tremaining: 11.3s\n",
      "686:\tlearn: 0.1628758\ttotal: 24.8s\tremaining: 11.3s\n",
      "687:\tlearn: 0.1627567\ttotal: 24.8s\tremaining: 11.3s\n",
      "688:\tlearn: 0.1626395\ttotal: 24.9s\tremaining: 11.2s\n",
      "689:\tlearn: 0.1625093\ttotal: 24.9s\tremaining: 11.2s\n",
      "690:\tlearn: 0.1623064\ttotal: 25s\tremaining: 11.2s\n",
      "691:\tlearn: 0.1621761\ttotal: 25s\tremaining: 11.1s\n",
      "692:\tlearn: 0.1619303\ttotal: 25s\tremaining: 11.1s\n",
      "693:\tlearn: 0.1618166\ttotal: 25.1s\tremaining: 11.1s\n",
      "694:\tlearn: 0.1616334\ttotal: 25.1s\tremaining: 11s\n",
      "695:\tlearn: 0.1615122\ttotal: 25.1s\tremaining: 11s\n",
      "696:\tlearn: 0.1613679\ttotal: 25.2s\tremaining: 10.9s\n",
      "697:\tlearn: 0.1612573\ttotal: 25.2s\tremaining: 10.9s\n",
      "698:\tlearn: 0.1611837\ttotal: 25.3s\tremaining: 10.9s\n",
      "699:\tlearn: 0.1610288\ttotal: 25.3s\tremaining: 10.8s\n",
      "700:\tlearn: 0.1608957\ttotal: 25.3s\tremaining: 10.8s\n",
      "701:\tlearn: 0.1607861\ttotal: 25.4s\tremaining: 10.8s\n",
      "702:\tlearn: 0.1607438\ttotal: 25.4s\tremaining: 10.7s\n",
      "703:\tlearn: 0.1605145\ttotal: 25.5s\tremaining: 10.7s\n",
      "704:\tlearn: 0.1603310\ttotal: 25.5s\tremaining: 10.7s\n",
      "705:\tlearn: 0.1602078\ttotal: 25.5s\tremaining: 10.6s\n",
      "706:\tlearn: 0.1600773\ttotal: 25.6s\tremaining: 10.6s\n",
      "707:\tlearn: 0.1599704\ttotal: 25.6s\tremaining: 10.6s\n",
      "708:\tlearn: 0.1598158\ttotal: 25.6s\tremaining: 10.5s\n",
      "709:\tlearn: 0.1596951\ttotal: 25.7s\tremaining: 10.5s\n",
      "710:\tlearn: 0.1595515\ttotal: 25.7s\tremaining: 10.5s\n",
      "711:\tlearn: 0.1594352\ttotal: 25.8s\tremaining: 10.4s\n",
      "712:\tlearn: 0.1593904\ttotal: 25.8s\tremaining: 10.4s\n",
      "713:\tlearn: 0.1592642\ttotal: 25.8s\tremaining: 10.3s\n",
      "714:\tlearn: 0.1591418\ttotal: 25.9s\tremaining: 10.3s\n",
      "715:\tlearn: 0.1589863\ttotal: 25.9s\tremaining: 10.3s\n",
      "716:\tlearn: 0.1589283\ttotal: 25.9s\tremaining: 10.2s\n",
      "717:\tlearn: 0.1587802\ttotal: 26s\tremaining: 10.2s\n",
      "718:\tlearn: 0.1586876\ttotal: 26s\tremaining: 10.2s\n",
      "719:\tlearn: 0.1586171\ttotal: 26s\tremaining: 10.1s\n",
      "720:\tlearn: 0.1584660\ttotal: 26.1s\tremaining: 10.1s\n",
      "721:\tlearn: 0.1584187\ttotal: 26.1s\tremaining: 10.1s\n",
      "722:\tlearn: 0.1583592\ttotal: 26.1s\tremaining: 10s\n",
      "723:\tlearn: 0.1582265\ttotal: 26.2s\tremaining: 9.98s\n",
      "724:\tlearn: 0.1582010\ttotal: 26.2s\tremaining: 9.94s\n",
      "725:\tlearn: 0.1580818\ttotal: 26.2s\tremaining: 9.91s\n",
      "726:\tlearn: 0.1580466\ttotal: 26.3s\tremaining: 9.87s\n",
      "727:\tlearn: 0.1579211\ttotal: 26.3s\tremaining: 9.83s\n",
      "728:\tlearn: 0.1578765\ttotal: 26.4s\tremaining: 9.8s\n",
      "729:\tlearn: 0.1577141\ttotal: 26.4s\tremaining: 9.76s\n",
      "730:\tlearn: 0.1575541\ttotal: 26.4s\tremaining: 9.72s\n",
      "731:\tlearn: 0.1574135\ttotal: 26.5s\tremaining: 9.69s\n",
      "732:\tlearn: 0.1572956\ttotal: 26.5s\tremaining: 9.65s\n",
      "733:\tlearn: 0.1571708\ttotal: 26.5s\tremaining: 9.61s\n",
      "734:\tlearn: 0.1570603\ttotal: 26.6s\tremaining: 9.57s\n",
      "735:\tlearn: 0.1569698\ttotal: 26.6s\tremaining: 9.54s\n",
      "736:\tlearn: 0.1569167\ttotal: 26.6s\tremaining: 9.51s\n",
      "737:\tlearn: 0.1568395\ttotal: 26.7s\tremaining: 9.47s\n",
      "738:\tlearn: 0.1567094\ttotal: 26.7s\tremaining: 9.43s\n",
      "739:\tlearn: 0.1565563\ttotal: 26.7s\tremaining: 9.39s\n",
      "740:\tlearn: 0.1565370\ttotal: 26.8s\tremaining: 9.36s\n",
      "741:\tlearn: 0.1563884\ttotal: 26.8s\tremaining: 9.32s\n",
      "742:\tlearn: 0.1562370\ttotal: 26.8s\tremaining: 9.28s\n",
      "743:\tlearn: 0.1560717\ttotal: 26.9s\tremaining: 9.25s\n",
      "744:\tlearn: 0.1559440\ttotal: 26.9s\tremaining: 9.21s\n",
      "745:\tlearn: 0.1558493\ttotal: 27s\tremaining: 9.18s\n",
      "746:\tlearn: 0.1557825\ttotal: 27s\tremaining: 9.14s\n",
      "747:\tlearn: 0.1556416\ttotal: 27s\tremaining: 9.1s\n",
      "748:\tlearn: 0.1555488\ttotal: 27.1s\tremaining: 9.07s\n",
      "749:\tlearn: 0.1554982\ttotal: 27.1s\tremaining: 9.03s\n",
      "750:\tlearn: 0.1553255\ttotal: 27.1s\tremaining: 8.99s\n",
      "751:\tlearn: 0.1552135\ttotal: 27.2s\tremaining: 8.96s\n",
      "752:\tlearn: 0.1550958\ttotal: 27.2s\tremaining: 8.92s\n",
      "753:\tlearn: 0.1549574\ttotal: 27.2s\tremaining: 8.89s\n",
      "754:\tlearn: 0.1548518\ttotal: 27.3s\tremaining: 8.86s\n",
      "755:\tlearn: 0.1547917\ttotal: 27.3s\tremaining: 8.82s\n",
      "756:\tlearn: 0.1546849\ttotal: 27.4s\tremaining: 8.79s\n",
      "757:\tlearn: 0.1546042\ttotal: 27.4s\tremaining: 8.75s\n",
      "758:\tlearn: 0.1545088\ttotal: 27.5s\tremaining: 8.72s\n",
      "759:\tlearn: 0.1544545\ttotal: 27.5s\tremaining: 8.68s\n",
      "760:\tlearn: 0.1543735\ttotal: 27.5s\tremaining: 8.64s\n",
      "761:\tlearn: 0.1542252\ttotal: 27.6s\tremaining: 8.61s\n",
      "762:\tlearn: 0.1541846\ttotal: 27.6s\tremaining: 8.57s\n",
      "763:\tlearn: 0.1540040\ttotal: 27.6s\tremaining: 8.53s\n",
      "764:\tlearn: 0.1538851\ttotal: 27.7s\tremaining: 8.5s\n",
      "765:\tlearn: 0.1538338\ttotal: 27.7s\tremaining: 8.46s\n",
      "766:\tlearn: 0.1536388\ttotal: 27.7s\tremaining: 8.43s\n",
      "767:\tlearn: 0.1534826\ttotal: 27.8s\tremaining: 8.39s\n",
      "768:\tlearn: 0.1532901\ttotal: 27.8s\tremaining: 8.35s\n",
      "769:\tlearn: 0.1531247\ttotal: 27.8s\tremaining: 8.32s\n",
      "770:\tlearn: 0.1529579\ttotal: 27.9s\tremaining: 8.28s\n",
      "771:\tlearn: 0.1528657\ttotal: 27.9s\tremaining: 8.24s\n",
      "772:\tlearn: 0.1528220\ttotal: 27.9s\tremaining: 8.21s\n",
      "773:\tlearn: 0.1527368\ttotal: 28s\tremaining: 8.17s\n",
      "774:\tlearn: 0.1526463\ttotal: 28s\tremaining: 8.13s\n",
      "775:\tlearn: 0.1524806\ttotal: 28.1s\tremaining: 8.1s\n",
      "776:\tlearn: 0.1523403\ttotal: 28.1s\tremaining: 8.06s\n",
      "777:\tlearn: 0.1522900\ttotal: 28.1s\tremaining: 8.03s\n",
      "778:\tlearn: 0.1521798\ttotal: 28.2s\tremaining: 7.99s\n",
      "779:\tlearn: 0.1520652\ttotal: 28.2s\tremaining: 7.95s\n",
      "780:\tlearn: 0.1520119\ttotal: 28.2s\tremaining: 7.92s\n",
      "781:\tlearn: 0.1518829\ttotal: 28.3s\tremaining: 7.88s\n",
      "782:\tlearn: 0.1517457\ttotal: 28.3s\tremaining: 7.85s\n",
      "783:\tlearn: 0.1514591\ttotal: 28.4s\tremaining: 7.81s\n",
      "784:\tlearn: 0.1513204\ttotal: 28.4s\tremaining: 7.78s\n",
      "785:\tlearn: 0.1512321\ttotal: 28.4s\tremaining: 7.74s\n",
      "786:\tlearn: 0.1511905\ttotal: 28.5s\tremaining: 7.7s\n",
      "787:\tlearn: 0.1511119\ttotal: 28.5s\tremaining: 7.67s\n",
      "788:\tlearn: 0.1510350\ttotal: 28.5s\tremaining: 7.63s\n",
      "789:\tlearn: 0.1509569\ttotal: 28.6s\tremaining: 7.59s\n",
      "790:\tlearn: 0.1509058\ttotal: 28.6s\tremaining: 7.55s\n",
      "791:\tlearn: 0.1507254\ttotal: 28.6s\tremaining: 7.52s\n",
      "792:\tlearn: 0.1506091\ttotal: 28.7s\tremaining: 7.48s\n",
      "793:\tlearn: 0.1505172\ttotal: 28.7s\tremaining: 7.45s\n",
      "794:\tlearn: 0.1504315\ttotal: 28.8s\tremaining: 7.41s\n",
      "795:\tlearn: 0.1503116\ttotal: 28.8s\tremaining: 7.38s\n",
      "796:\tlearn: 0.1501432\ttotal: 28.8s\tremaining: 7.34s\n",
      "797:\tlearn: 0.1500462\ttotal: 28.9s\tremaining: 7.3s\n",
      "798:\tlearn: 0.1499327\ttotal: 28.9s\tremaining: 7.26s\n",
      "799:\tlearn: 0.1498635\ttotal: 28.9s\tremaining: 7.23s\n",
      "800:\tlearn: 0.1497961\ttotal: 29s\tremaining: 7.19s\n",
      "801:\tlearn: 0.1496625\ttotal: 29s\tremaining: 7.16s\n",
      "802:\tlearn: 0.1494694\ttotal: 29s\tremaining: 7.12s\n",
      "803:\tlearn: 0.1493963\ttotal: 29.1s\tremaining: 7.09s\n",
      "804:\tlearn: 0.1493283\ttotal: 29.1s\tremaining: 7.05s\n",
      "805:\tlearn: 0.1492817\ttotal: 29.1s\tremaining: 7.01s\n",
      "806:\tlearn: 0.1492184\ttotal: 29.2s\tremaining: 6.97s\n",
      "807:\tlearn: 0.1491774\ttotal: 29.2s\tremaining: 6.94s\n",
      "808:\tlearn: 0.1489762\ttotal: 29.2s\tremaining: 6.9s\n",
      "809:\tlearn: 0.1488330\ttotal: 29.3s\tremaining: 6.87s\n",
      "810:\tlearn: 0.1487391\ttotal: 29.3s\tremaining: 6.83s\n",
      "811:\tlearn: 0.1486669\ttotal: 29.4s\tremaining: 6.79s\n",
      "812:\tlearn: 0.1486002\ttotal: 29.4s\tremaining: 6.76s\n",
      "813:\tlearn: 0.1485145\ttotal: 29.4s\tremaining: 6.72s\n",
      "814:\tlearn: 0.1483779\ttotal: 29.5s\tremaining: 6.69s\n",
      "815:\tlearn: 0.1481616\ttotal: 29.5s\tremaining: 6.65s\n",
      "816:\tlearn: 0.1480083\ttotal: 29.5s\tremaining: 6.62s\n",
      "817:\tlearn: 0.1478552\ttotal: 29.6s\tremaining: 6.58s\n",
      "818:\tlearn: 0.1477911\ttotal: 29.6s\tremaining: 6.54s\n",
      "819:\tlearn: 0.1476600\ttotal: 29.6s\tremaining: 6.51s\n",
      "820:\tlearn: 0.1475919\ttotal: 29.7s\tremaining: 6.47s\n",
      "821:\tlearn: 0.1475493\ttotal: 29.7s\tremaining: 6.44s\n",
      "822:\tlearn: 0.1474100\ttotal: 29.8s\tremaining: 6.4s\n",
      "823:\tlearn: 0.1473304\ttotal: 29.8s\tremaining: 6.36s\n",
      "824:\tlearn: 0.1472316\ttotal: 29.8s\tremaining: 6.33s\n",
      "825:\tlearn: 0.1470888\ttotal: 29.9s\tremaining: 6.29s\n",
      "826:\tlearn: 0.1470123\ttotal: 29.9s\tremaining: 6.25s\n",
      "827:\tlearn: 0.1468968\ttotal: 29.9s\tremaining: 6.22s\n",
      "828:\tlearn: 0.1467889\ttotal: 30s\tremaining: 6.18s\n",
      "829:\tlearn: 0.1466672\ttotal: 30s\tremaining: 6.15s\n",
      "830:\tlearn: 0.1465621\ttotal: 30s\tremaining: 6.11s\n",
      "831:\tlearn: 0.1464921\ttotal: 30.1s\tremaining: 6.07s\n",
      "832:\tlearn: 0.1464339\ttotal: 30.1s\tremaining: 6.04s\n",
      "833:\tlearn: 0.1463864\ttotal: 30.1s\tremaining: 6s\n",
      "834:\tlearn: 0.1463142\ttotal: 30.2s\tremaining: 5.96s\n",
      "835:\tlearn: 0.1462634\ttotal: 30.2s\tremaining: 5.92s\n",
      "836:\tlearn: 0.1461591\ttotal: 30.2s\tremaining: 5.89s\n",
      "837:\tlearn: 0.1460788\ttotal: 30.3s\tremaining: 5.85s\n",
      "838:\tlearn: 0.1459933\ttotal: 30.3s\tremaining: 5.82s\n",
      "839:\tlearn: 0.1459006\ttotal: 30.4s\tremaining: 5.78s\n",
      "840:\tlearn: 0.1457823\ttotal: 30.4s\tremaining: 5.75s\n",
      "841:\tlearn: 0.1457001\ttotal: 30.4s\tremaining: 5.71s\n",
      "842:\tlearn: 0.1456041\ttotal: 30.5s\tremaining: 5.67s\n",
      "843:\tlearn: 0.1454838\ttotal: 30.5s\tremaining: 5.64s\n",
      "844:\tlearn: 0.1453663\ttotal: 30.5s\tremaining: 5.6s\n",
      "845:\tlearn: 0.1453147\ttotal: 30.6s\tremaining: 5.56s\n",
      "846:\tlearn: 0.1451510\ttotal: 30.6s\tremaining: 5.53s\n",
      "847:\tlearn: 0.1450873\ttotal: 30.6s\tremaining: 5.49s\n",
      "848:\tlearn: 0.1450230\ttotal: 30.7s\tremaining: 5.46s\n",
      "849:\tlearn: 0.1448971\ttotal: 30.7s\tremaining: 5.42s\n",
      "850:\tlearn: 0.1448091\ttotal: 30.8s\tremaining: 5.38s\n",
      "851:\tlearn: 0.1446809\ttotal: 30.8s\tremaining: 5.35s\n",
      "852:\tlearn: 0.1445619\ttotal: 30.8s\tremaining: 5.31s\n",
      "853:\tlearn: 0.1443727\ttotal: 30.9s\tremaining: 5.27s\n",
      "854:\tlearn: 0.1443231\ttotal: 30.9s\tremaining: 5.24s\n",
      "855:\tlearn: 0.1442800\ttotal: 30.9s\tremaining: 5.2s\n",
      "856:\tlearn: 0.1441868\ttotal: 31s\tremaining: 5.17s\n",
      "857:\tlearn: 0.1440509\ttotal: 31s\tremaining: 5.13s\n",
      "858:\tlearn: 0.1439807\ttotal: 31s\tremaining: 5.09s\n",
      "859:\tlearn: 0.1439004\ttotal: 31.1s\tremaining: 5.06s\n",
      "860:\tlearn: 0.1437582\ttotal: 31.1s\tremaining: 5.02s\n",
      "861:\tlearn: 0.1436258\ttotal: 31.1s\tremaining: 4.99s\n",
      "862:\tlearn: 0.1435476\ttotal: 31.2s\tremaining: 4.95s\n",
      "863:\tlearn: 0.1434580\ttotal: 31.2s\tremaining: 4.91s\n",
      "864:\tlearn: 0.1433753\ttotal: 31.3s\tremaining: 4.88s\n",
      "865:\tlearn: 0.1432399\ttotal: 31.3s\tremaining: 4.84s\n",
      "866:\tlearn: 0.1430383\ttotal: 31.3s\tremaining: 4.81s\n",
      "867:\tlearn: 0.1429481\ttotal: 31.4s\tremaining: 4.77s\n",
      "868:\tlearn: 0.1428694\ttotal: 31.4s\tremaining: 4.74s\n",
      "869:\tlearn: 0.1427668\ttotal: 31.5s\tremaining: 4.7s\n",
      "870:\tlearn: 0.1426814\ttotal: 31.5s\tremaining: 4.66s\n",
      "871:\tlearn: 0.1425251\ttotal: 31.5s\tremaining: 4.63s\n",
      "872:\tlearn: 0.1424404\ttotal: 31.6s\tremaining: 4.59s\n",
      "873:\tlearn: 0.1423280\ttotal: 31.6s\tremaining: 4.55s\n",
      "874:\tlearn: 0.1422562\ttotal: 31.6s\tremaining: 4.52s\n",
      "875:\tlearn: 0.1420889\ttotal: 31.7s\tremaining: 4.48s\n",
      "876:\tlearn: 0.1419771\ttotal: 31.7s\tremaining: 4.45s\n",
      "877:\tlearn: 0.1418816\ttotal: 31.8s\tremaining: 4.41s\n",
      "878:\tlearn: 0.1418323\ttotal: 31.8s\tremaining: 4.38s\n",
      "879:\tlearn: 0.1417612\ttotal: 31.8s\tremaining: 4.34s\n",
      "880:\tlearn: 0.1416458\ttotal: 31.9s\tremaining: 4.3s\n",
      "881:\tlearn: 0.1415493\ttotal: 31.9s\tremaining: 4.27s\n",
      "882:\tlearn: 0.1414509\ttotal: 31.9s\tremaining: 4.23s\n",
      "883:\tlearn: 0.1413843\ttotal: 32s\tremaining: 4.19s\n",
      "884:\tlearn: 0.1412277\ttotal: 32s\tremaining: 4.16s\n",
      "885:\tlearn: 0.1410956\ttotal: 32s\tremaining: 4.12s\n",
      "886:\tlearn: 0.1409888\ttotal: 32.1s\tremaining: 4.09s\n",
      "887:\tlearn: 0.1409254\ttotal: 32.1s\tremaining: 4.05s\n",
      "888:\tlearn: 0.1408848\ttotal: 32.2s\tremaining: 4.01s\n",
      "889:\tlearn: 0.1407723\ttotal: 32.2s\tremaining: 3.98s\n",
      "890:\tlearn: 0.1406548\ttotal: 32.2s\tremaining: 3.94s\n",
      "891:\tlearn: 0.1405811\ttotal: 32.3s\tremaining: 3.9s\n",
      "892:\tlearn: 0.1405596\ttotal: 32.3s\tremaining: 3.87s\n",
      "893:\tlearn: 0.1404033\ttotal: 32.3s\tremaining: 3.83s\n",
      "894:\tlearn: 0.1403175\ttotal: 32.4s\tremaining: 3.8s\n",
      "895:\tlearn: 0.1402159\ttotal: 32.4s\tremaining: 3.76s\n",
      "896:\tlearn: 0.1401302\ttotal: 32.4s\tremaining: 3.72s\n",
      "897:\tlearn: 0.1400335\ttotal: 32.5s\tremaining: 3.69s\n",
      "898:\tlearn: 0.1399862\ttotal: 32.5s\tremaining: 3.65s\n",
      "899:\tlearn: 0.1398839\ttotal: 32.5s\tremaining: 3.62s\n",
      "900:\tlearn: 0.1398094\ttotal: 32.6s\tremaining: 3.58s\n",
      "901:\tlearn: 0.1397519\ttotal: 32.6s\tremaining: 3.54s\n",
      "902:\tlearn: 0.1396456\ttotal: 32.7s\tremaining: 3.51s\n",
      "903:\tlearn: 0.1396173\ttotal: 32.7s\tremaining: 3.47s\n",
      "904:\tlearn: 0.1394884\ttotal: 32.7s\tremaining: 3.44s\n",
      "905:\tlearn: 0.1393575\ttotal: 32.8s\tremaining: 3.4s\n",
      "906:\tlearn: 0.1392302\ttotal: 32.8s\tremaining: 3.36s\n",
      "907:\tlearn: 0.1391375\ttotal: 32.8s\tremaining: 3.33s\n",
      "908:\tlearn: 0.1390805\ttotal: 32.9s\tremaining: 3.29s\n",
      "909:\tlearn: 0.1389692\ttotal: 32.9s\tremaining: 3.25s\n",
      "910:\tlearn: 0.1388507\ttotal: 32.9s\tremaining: 3.22s\n",
      "911:\tlearn: 0.1387226\ttotal: 33s\tremaining: 3.18s\n",
      "912:\tlearn: 0.1386351\ttotal: 33s\tremaining: 3.15s\n",
      "913:\tlearn: 0.1385423\ttotal: 33s\tremaining: 3.11s\n",
      "914:\tlearn: 0.1383764\ttotal: 33.1s\tremaining: 3.07s\n",
      "915:\tlearn: 0.1383314\ttotal: 33.1s\tremaining: 3.04s\n",
      "916:\tlearn: 0.1382967\ttotal: 33.1s\tremaining: 3s\n",
      "917:\tlearn: 0.1382768\ttotal: 33.2s\tremaining: 2.96s\n",
      "918:\tlearn: 0.1381893\ttotal: 33.2s\tremaining: 2.93s\n",
      "919:\tlearn: 0.1380635\ttotal: 33.3s\tremaining: 2.89s\n",
      "920:\tlearn: 0.1379977\ttotal: 33.3s\tremaining: 2.86s\n",
      "921:\tlearn: 0.1379298\ttotal: 33.3s\tremaining: 2.82s\n",
      "922:\tlearn: 0.1378573\ttotal: 33.4s\tremaining: 2.78s\n",
      "923:\tlearn: 0.1377497\ttotal: 33.4s\tremaining: 2.75s\n",
      "924:\tlearn: 0.1376098\ttotal: 33.4s\tremaining: 2.71s\n",
      "925:\tlearn: 0.1374949\ttotal: 33.5s\tremaining: 2.67s\n",
      "926:\tlearn: 0.1374242\ttotal: 33.5s\tremaining: 2.64s\n",
      "927:\tlearn: 0.1373619\ttotal: 33.5s\tremaining: 2.6s\n",
      "928:\tlearn: 0.1372468\ttotal: 33.6s\tremaining: 2.57s\n",
      "929:\tlearn: 0.1371895\ttotal: 33.6s\tremaining: 2.53s\n",
      "930:\tlearn: 0.1371209\ttotal: 33.6s\tremaining: 2.49s\n",
      "931:\tlearn: 0.1369936\ttotal: 33.7s\tremaining: 2.46s\n",
      "932:\tlearn: 0.1368444\ttotal: 33.7s\tremaining: 2.42s\n",
      "933:\tlearn: 0.1367454\ttotal: 33.7s\tremaining: 2.38s\n",
      "934:\tlearn: 0.1366405\ttotal: 33.8s\tremaining: 2.35s\n",
      "935:\tlearn: 0.1365703\ttotal: 33.8s\tremaining: 2.31s\n",
      "936:\tlearn: 0.1364875\ttotal: 33.9s\tremaining: 2.28s\n",
      "937:\tlearn: 0.1363670\ttotal: 33.9s\tremaining: 2.24s\n",
      "938:\tlearn: 0.1362661\ttotal: 33.9s\tremaining: 2.21s\n",
      "939:\tlearn: 0.1361821\ttotal: 34s\tremaining: 2.17s\n",
      "940:\tlearn: 0.1361116\ttotal: 34s\tremaining: 2.13s\n",
      "941:\tlearn: 0.1360168\ttotal: 34.1s\tremaining: 2.1s\n",
      "942:\tlearn: 0.1359046\ttotal: 34.1s\tremaining: 2.06s\n",
      "943:\tlearn: 0.1357689\ttotal: 34.1s\tremaining: 2.02s\n",
      "944:\tlearn: 0.1356698\ttotal: 34.2s\tremaining: 1.99s\n",
      "945:\tlearn: 0.1356416\ttotal: 34.2s\tremaining: 1.95s\n",
      "946:\tlearn: 0.1354594\ttotal: 34.2s\tremaining: 1.92s\n",
      "947:\tlearn: 0.1353347\ttotal: 34.3s\tremaining: 1.88s\n",
      "948:\tlearn: 0.1352916\ttotal: 34.3s\tremaining: 1.84s\n",
      "949:\tlearn: 0.1352099\ttotal: 34.3s\tremaining: 1.81s\n",
      "950:\tlearn: 0.1351476\ttotal: 34.4s\tremaining: 1.77s\n",
      "951:\tlearn: 0.1350963\ttotal: 34.4s\tremaining: 1.73s\n",
      "952:\tlearn: 0.1349799\ttotal: 34.4s\tremaining: 1.7s\n",
      "953:\tlearn: 0.1349031\ttotal: 34.5s\tremaining: 1.66s\n",
      "954:\tlearn: 0.1348459\ttotal: 34.5s\tremaining: 1.63s\n",
      "955:\tlearn: 0.1347767\ttotal: 34.5s\tremaining: 1.59s\n",
      "956:\tlearn: 0.1346527\ttotal: 34.6s\tremaining: 1.55s\n",
      "957:\tlearn: 0.1345783\ttotal: 34.6s\tremaining: 1.52s\n",
      "958:\tlearn: 0.1345514\ttotal: 34.7s\tremaining: 1.48s\n",
      "959:\tlearn: 0.1344478\ttotal: 34.7s\tremaining: 1.45s\n",
      "960:\tlearn: 0.1343890\ttotal: 34.7s\tremaining: 1.41s\n",
      "961:\tlearn: 0.1342767\ttotal: 34.8s\tremaining: 1.37s\n",
      "962:\tlearn: 0.1341675\ttotal: 34.8s\tremaining: 1.34s\n",
      "963:\tlearn: 0.1340352\ttotal: 34.8s\tremaining: 1.3s\n",
      "964:\tlearn: 0.1339643\ttotal: 34.9s\tremaining: 1.26s\n",
      "965:\tlearn: 0.1339089\ttotal: 34.9s\tremaining: 1.23s\n",
      "966:\tlearn: 0.1337707\ttotal: 35s\tremaining: 1.19s\n",
      "967:\tlearn: 0.1337228\ttotal: 35s\tremaining: 1.16s\n",
      "968:\tlearn: 0.1335552\ttotal: 35s\tremaining: 1.12s\n",
      "969:\tlearn: 0.1334874\ttotal: 35.1s\tremaining: 1.08s\n",
      "970:\tlearn: 0.1333922\ttotal: 35.1s\tremaining: 1.05s\n",
      "971:\tlearn: 0.1333403\ttotal: 35.1s\tremaining: 1.01s\n",
      "972:\tlearn: 0.1332272\ttotal: 35.2s\tremaining: 976ms\n",
      "973:\tlearn: 0.1331054\ttotal: 35.2s\tremaining: 940ms\n",
      "974:\tlearn: 0.1330452\ttotal: 35.3s\tremaining: 904ms\n",
      "975:\tlearn: 0.1329721\ttotal: 35.3s\tremaining: 868ms\n",
      "976:\tlearn: 0.1329489\ttotal: 35.3s\tremaining: 832ms\n",
      "977:\tlearn: 0.1328377\ttotal: 35.4s\tremaining: 796ms\n",
      "978:\tlearn: 0.1327703\ttotal: 35.4s\tremaining: 759ms\n",
      "979:\tlearn: 0.1327222\ttotal: 35.4s\tremaining: 723ms\n",
      "980:\tlearn: 0.1325772\ttotal: 35.5s\tremaining: 687ms\n",
      "981:\tlearn: 0.1324731\ttotal: 35.5s\tremaining: 651ms\n",
      "982:\tlearn: 0.1324506\ttotal: 35.5s\tremaining: 615ms\n",
      "983:\tlearn: 0.1324227\ttotal: 35.6s\tremaining: 579ms\n",
      "984:\tlearn: 0.1323725\ttotal: 35.6s\tremaining: 542ms\n",
      "985:\tlearn: 0.1323259\ttotal: 35.6s\tremaining: 506ms\n",
      "986:\tlearn: 0.1322656\ttotal: 35.7s\tremaining: 470ms\n",
      "987:\tlearn: 0.1321074\ttotal: 35.7s\tremaining: 434ms\n",
      "988:\tlearn: 0.1320001\ttotal: 35.8s\tremaining: 398ms\n",
      "989:\tlearn: 0.1318855\ttotal: 35.8s\tremaining: 362ms\n",
      "990:\tlearn: 0.1318367\ttotal: 35.8s\tremaining: 325ms\n",
      "991:\tlearn: 0.1317208\ttotal: 35.9s\tremaining: 289ms\n",
      "992:\tlearn: 0.1316128\ttotal: 35.9s\tremaining: 253ms\n",
      "993:\tlearn: 0.1315753\ttotal: 35.9s\tremaining: 217ms\n",
      "994:\tlearn: 0.1315478\ttotal: 36s\tremaining: 181ms\n",
      "995:\tlearn: 0.1314938\ttotal: 36s\tremaining: 145ms\n",
      "996:\tlearn: 0.1314119\ttotal: 36s\tremaining: 108ms\n",
      "997:\tlearn: 0.1313295\ttotal: 36.1s\tremaining: 72.3ms\n",
      "998:\tlearn: 0.1312498\ttotal: 36.1s\tremaining: 36.1ms\n",
      "999:\tlearn: 0.1311273\ttotal: 36.1s\tremaining: 0us\n",
      "Learning rate set to 0.09175\n",
      "0:\tlearn: 1.8192874\ttotal: 46.7ms\tremaining: 46.7s\n",
      "1:\tlearn: 1.6320400\ttotal: 84.8ms\tremaining: 42.3s\n",
      "2:\tlearn: 1.4706482\ttotal: 119ms\tremaining: 39.7s\n",
      "3:\tlearn: 1.3631927\ttotal: 142ms\tremaining: 35.3s\n",
      "4:\tlearn: 1.2644398\ttotal: 175ms\tremaining: 34.9s\n",
      "5:\tlearn: 1.1778524\ttotal: 213ms\tremaining: 35.3s\n",
      "6:\tlearn: 1.1085705\ttotal: 265ms\tremaining: 37.6s\n",
      "7:\tlearn: 1.0437162\ttotal: 306ms\tremaining: 37.9s\n",
      "8:\tlearn: 0.9856806\ttotal: 343ms\tremaining: 37.8s\n",
      "9:\tlearn: 0.9435042\ttotal: 378ms\tremaining: 37.4s\n",
      "10:\tlearn: 0.8986250\ttotal: 416ms\tremaining: 37.4s\n",
      "11:\tlearn: 0.8630583\ttotal: 452ms\tremaining: 37.2s\n",
      "12:\tlearn: 0.8301623\ttotal: 486ms\tremaining: 36.9s\n",
      "13:\tlearn: 0.8002511\ttotal: 523ms\tremaining: 36.9s\n",
      "14:\tlearn: 0.7750749\ttotal: 565ms\tremaining: 37.1s\n",
      "15:\tlearn: 0.7489516\ttotal: 599ms\tremaining: 36.9s\n",
      "16:\tlearn: 0.7275817\ttotal: 643ms\tremaining: 37.2s\n",
      "17:\tlearn: 0.7075834\ttotal: 678ms\tremaining: 37s\n",
      "18:\tlearn: 0.6869278\ttotal: 714ms\tremaining: 36.8s\n",
      "19:\tlearn: 0.6701289\ttotal: 748ms\tremaining: 36.7s\n",
      "20:\tlearn: 0.6573454\ttotal: 782ms\tremaining: 36.4s\n",
      "21:\tlearn: 0.6442533\ttotal: 816ms\tremaining: 36.3s\n",
      "22:\tlearn: 0.6306482\ttotal: 860ms\tremaining: 36.5s\n",
      "23:\tlearn: 0.6193102\ttotal: 909ms\tremaining: 37s\n",
      "24:\tlearn: 0.6078678\ttotal: 951ms\tremaining: 37.1s\n",
      "25:\tlearn: 0.5948332\ttotal: 983ms\tremaining: 36.8s\n",
      "26:\tlearn: 0.5798241\ttotal: 1.02s\tremaining: 36.7s\n",
      "27:\tlearn: 0.5687546\ttotal: 1.06s\tremaining: 36.8s\n",
      "28:\tlearn: 0.5594598\ttotal: 1.09s\tremaining: 36.7s\n",
      "29:\tlearn: 0.5507929\ttotal: 1.13s\tremaining: 36.5s\n",
      "30:\tlearn: 0.5408698\ttotal: 1.16s\tremaining: 36.2s\n",
      "31:\tlearn: 0.5328208\ttotal: 1.2s\tremaining: 36.2s\n",
      "32:\tlearn: 0.5266990\ttotal: 1.23s\tremaining: 36s\n",
      "33:\tlearn: 0.5217965\ttotal: 1.27s\tremaining: 36.2s\n",
      "34:\tlearn: 0.5145972\ttotal: 1.32s\tremaining: 36.3s\n",
      "35:\tlearn: 0.5079152\ttotal: 1.35s\tremaining: 36.2s\n",
      "36:\tlearn: 0.5014287\ttotal: 1.38s\tremaining: 36s\n",
      "37:\tlearn: 0.4919032\ttotal: 1.42s\tremaining: 35.9s\n",
      "38:\tlearn: 0.4850831\ttotal: 1.45s\tremaining: 35.7s\n",
      "39:\tlearn: 0.4794948\ttotal: 1.48s\tremaining: 35.6s\n",
      "40:\tlearn: 0.4744411\ttotal: 1.52s\tremaining: 35.5s\n",
      "41:\tlearn: 0.4712344\ttotal: 1.56s\tremaining: 35.5s\n",
      "42:\tlearn: 0.4646910\ttotal: 1.59s\tremaining: 35.4s\n",
      "43:\tlearn: 0.4615645\ttotal: 1.63s\tremaining: 35.4s\n",
      "44:\tlearn: 0.4582574\ttotal: 1.67s\tremaining: 35.4s\n",
      "45:\tlearn: 0.4540504\ttotal: 1.7s\tremaining: 35.3s\n",
      "46:\tlearn: 0.4496092\ttotal: 1.73s\tremaining: 35.2s\n",
      "47:\tlearn: 0.4464176\ttotal: 1.77s\tremaining: 35s\n",
      "48:\tlearn: 0.4435145\ttotal: 1.8s\tremaining: 34.9s\n",
      "49:\tlearn: 0.4387437\ttotal: 1.83s\tremaining: 34.8s\n",
      "50:\tlearn: 0.4343077\ttotal: 1.87s\tremaining: 34.8s\n",
      "51:\tlearn: 0.4304563\ttotal: 1.92s\tremaining: 34.9s\n",
      "52:\tlearn: 0.4267540\ttotal: 1.96s\tremaining: 35s\n",
      "53:\tlearn: 0.4245851\ttotal: 1.99s\tremaining: 34.9s\n",
      "54:\tlearn: 0.4203316\ttotal: 2.03s\tremaining: 34.8s\n",
      "55:\tlearn: 0.4178542\ttotal: 2.06s\tremaining: 34.7s\n",
      "56:\tlearn: 0.4137550\ttotal: 2.09s\tremaining: 34.6s\n",
      "57:\tlearn: 0.4111122\ttotal: 2.13s\tremaining: 34.5s\n",
      "58:\tlearn: 0.4087896\ttotal: 2.16s\tremaining: 34.4s\n",
      "59:\tlearn: 0.4072344\ttotal: 2.19s\tremaining: 34.4s\n",
      "60:\tlearn: 0.4035229\ttotal: 2.23s\tremaining: 34.3s\n",
      "61:\tlearn: 0.4019088\ttotal: 2.27s\tremaining: 34.3s\n",
      "62:\tlearn: 0.3984611\ttotal: 2.31s\tremaining: 34.4s\n",
      "63:\tlearn: 0.3957833\ttotal: 2.34s\tremaining: 34.3s\n",
      "64:\tlearn: 0.3934468\ttotal: 2.38s\tremaining: 34.2s\n",
      "65:\tlearn: 0.3904182\ttotal: 2.42s\tremaining: 34.2s\n",
      "66:\tlearn: 0.3886328\ttotal: 2.45s\tremaining: 34.1s\n",
      "67:\tlearn: 0.3872058\ttotal: 2.48s\tremaining: 34s\n",
      "68:\tlearn: 0.3848833\ttotal: 2.52s\tremaining: 33.9s\n",
      "69:\tlearn: 0.3832981\ttotal: 2.56s\tremaining: 34s\n",
      "70:\tlearn: 0.3807456\ttotal: 2.6s\tremaining: 34.1s\n",
      "71:\tlearn: 0.3783642\ttotal: 2.64s\tremaining: 34s\n",
      "72:\tlearn: 0.3756638\ttotal: 2.67s\tremaining: 34s\n",
      "73:\tlearn: 0.3742417\ttotal: 2.71s\tremaining: 33.9s\n",
      "74:\tlearn: 0.3722903\ttotal: 2.74s\tremaining: 33.8s\n",
      "75:\tlearn: 0.3696498\ttotal: 2.78s\tremaining: 33.8s\n",
      "76:\tlearn: 0.3681265\ttotal: 2.81s\tremaining: 33.7s\n",
      "77:\tlearn: 0.3657732\ttotal: 2.85s\tremaining: 33.7s\n",
      "78:\tlearn: 0.3638768\ttotal: 2.89s\tremaining: 33.6s\n",
      "79:\tlearn: 0.3624992\ttotal: 2.93s\tremaining: 33.7s\n",
      "80:\tlearn: 0.3604941\ttotal: 2.97s\tremaining: 33.7s\n",
      "81:\tlearn: 0.3587571\ttotal: 3s\tremaining: 33.6s\n",
      "82:\tlearn: 0.3578288\ttotal: 3.03s\tremaining: 33.5s\n",
      "83:\tlearn: 0.3556773\ttotal: 3.07s\tremaining: 33.4s\n",
      "84:\tlearn: 0.3543151\ttotal: 3.1s\tremaining: 33.4s\n",
      "85:\tlearn: 0.3534762\ttotal: 3.13s\tremaining: 33.3s\n",
      "86:\tlearn: 0.3523264\ttotal: 3.18s\tremaining: 33.3s\n",
      "87:\tlearn: 0.3516329\ttotal: 3.22s\tremaining: 33.4s\n",
      "88:\tlearn: 0.3500812\ttotal: 3.27s\tremaining: 33.4s\n",
      "89:\tlearn: 0.3482141\ttotal: 3.3s\tremaining: 33.3s\n",
      "90:\tlearn: 0.3475873\ttotal: 3.33s\tremaining: 33.2s\n",
      "91:\tlearn: 0.3459211\ttotal: 3.36s\tremaining: 33.2s\n",
      "92:\tlearn: 0.3443698\ttotal: 3.4s\tremaining: 33.1s\n",
      "93:\tlearn: 0.3429747\ttotal: 3.43s\tremaining: 33.1s\n",
      "94:\tlearn: 0.3425707\ttotal: 3.47s\tremaining: 33s\n",
      "95:\tlearn: 0.3413144\ttotal: 3.5s\tremaining: 33s\n",
      "96:\tlearn: 0.3402483\ttotal: 3.53s\tremaining: 32.9s\n",
      "97:\tlearn: 0.3391102\ttotal: 3.58s\tremaining: 32.9s\n",
      "98:\tlearn: 0.3371411\ttotal: 3.62s\tremaining: 32.9s\n",
      "99:\tlearn: 0.3362465\ttotal: 3.65s\tremaining: 32.9s\n",
      "100:\tlearn: 0.3345689\ttotal: 3.69s\tremaining: 32.8s\n",
      "101:\tlearn: 0.3341137\ttotal: 3.71s\tremaining: 32.7s\n",
      "102:\tlearn: 0.3334600\ttotal: 3.75s\tremaining: 32.7s\n",
      "103:\tlearn: 0.3317647\ttotal: 3.79s\tremaining: 32.7s\n",
      "104:\tlearn: 0.3307551\ttotal: 3.83s\tremaining: 32.6s\n",
      "105:\tlearn: 0.3294326\ttotal: 3.87s\tremaining: 32.6s\n",
      "106:\tlearn: 0.3280889\ttotal: 3.9s\tremaining: 32.6s\n",
      "107:\tlearn: 0.3272996\ttotal: 3.95s\tremaining: 32.6s\n",
      "108:\tlearn: 0.3264915\ttotal: 3.98s\tremaining: 32.5s\n",
      "109:\tlearn: 0.3251786\ttotal: 4.02s\tremaining: 32.5s\n",
      "110:\tlearn: 0.3246667\ttotal: 4.06s\tremaining: 32.5s\n",
      "111:\tlearn: 0.3240752\ttotal: 4.09s\tremaining: 32.5s\n",
      "112:\tlearn: 0.3229805\ttotal: 4.13s\tremaining: 32.4s\n",
      "113:\tlearn: 0.3217277\ttotal: 4.16s\tremaining: 32.3s\n",
      "114:\tlearn: 0.3211569\ttotal: 4.19s\tremaining: 32.3s\n",
      "115:\tlearn: 0.3203507\ttotal: 4.23s\tremaining: 32.2s\n",
      "116:\tlearn: 0.3194116\ttotal: 4.27s\tremaining: 32.2s\n",
      "117:\tlearn: 0.3188334\ttotal: 4.31s\tremaining: 32.2s\n",
      "118:\tlearn: 0.3183654\ttotal: 4.35s\tremaining: 32.2s\n",
      "119:\tlearn: 0.3177432\ttotal: 4.38s\tremaining: 32.1s\n",
      "120:\tlearn: 0.3164622\ttotal: 4.41s\tremaining: 32.1s\n",
      "121:\tlearn: 0.3149320\ttotal: 4.45s\tremaining: 32s\n",
      "122:\tlearn: 0.3143643\ttotal: 4.48s\tremaining: 31.9s\n",
      "123:\tlearn: 0.3138386\ttotal: 4.51s\tremaining: 31.9s\n",
      "124:\tlearn: 0.3128417\ttotal: 4.54s\tremaining: 31.8s\n",
      "125:\tlearn: 0.3119600\ttotal: 4.58s\tremaining: 31.8s\n",
      "126:\tlearn: 0.3115919\ttotal: 4.61s\tremaining: 31.7s\n",
      "127:\tlearn: 0.3111201\ttotal: 4.66s\tremaining: 31.7s\n",
      "128:\tlearn: 0.3100830\ttotal: 4.69s\tremaining: 31.7s\n",
      "129:\tlearn: 0.3098042\ttotal: 4.72s\tremaining: 31.6s\n",
      "130:\tlearn: 0.3087311\ttotal: 4.76s\tremaining: 31.6s\n",
      "131:\tlearn: 0.3080466\ttotal: 4.79s\tremaining: 31.5s\n",
      "132:\tlearn: 0.3069327\ttotal: 4.83s\tremaining: 31.5s\n",
      "133:\tlearn: 0.3060121\ttotal: 4.86s\tremaining: 31.4s\n",
      "134:\tlearn: 0.3055795\ttotal: 4.91s\tremaining: 31.5s\n",
      "135:\tlearn: 0.3048831\ttotal: 4.95s\tremaining: 31.4s\n",
      "136:\tlearn: 0.3043003\ttotal: 4.98s\tremaining: 31.4s\n",
      "137:\tlearn: 0.3035538\ttotal: 5.02s\tremaining: 31.3s\n",
      "138:\tlearn: 0.3028521\ttotal: 5.05s\tremaining: 31.3s\n",
      "139:\tlearn: 0.3024669\ttotal: 5.08s\tremaining: 31.2s\n",
      "140:\tlearn: 0.3021907\ttotal: 5.11s\tremaining: 31.1s\n",
      "141:\tlearn: 0.3013264\ttotal: 5.14s\tremaining: 31.1s\n",
      "142:\tlearn: 0.3007304\ttotal: 5.18s\tremaining: 31s\n",
      "143:\tlearn: 0.3001683\ttotal: 5.21s\tremaining: 31s\n",
      "144:\tlearn: 0.2991903\ttotal: 5.25s\tremaining: 30.9s\n",
      "145:\tlearn: 0.2986379\ttotal: 5.28s\tremaining: 30.9s\n",
      "146:\tlearn: 0.2981399\ttotal: 5.32s\tremaining: 30.9s\n",
      "147:\tlearn: 0.2976075\ttotal: 5.36s\tremaining: 30.9s\n",
      "148:\tlearn: 0.2968169\ttotal: 5.39s\tremaining: 30.8s\n",
      "149:\tlearn: 0.2965276\ttotal: 5.42s\tremaining: 30.7s\n",
      "150:\tlearn: 0.2956867\ttotal: 5.46s\tremaining: 30.7s\n",
      "151:\tlearn: 0.2950904\ttotal: 5.49s\tremaining: 30.6s\n",
      "152:\tlearn: 0.2943828\ttotal: 5.52s\tremaining: 30.6s\n",
      "153:\tlearn: 0.2929809\ttotal: 5.57s\tremaining: 30.6s\n",
      "154:\tlearn: 0.2925289\ttotal: 5.61s\tremaining: 30.6s\n",
      "155:\tlearn: 0.2921854\ttotal: 5.65s\tremaining: 30.6s\n",
      "156:\tlearn: 0.2917154\ttotal: 5.68s\tremaining: 30.5s\n",
      "157:\tlearn: 0.2908989\ttotal: 5.71s\tremaining: 30.5s\n",
      "158:\tlearn: 0.2902646\ttotal: 5.75s\tremaining: 30.4s\n",
      "159:\tlearn: 0.2895040\ttotal: 5.78s\tremaining: 30.4s\n",
      "160:\tlearn: 0.2890520\ttotal: 5.82s\tremaining: 30.3s\n",
      "161:\tlearn: 0.2881915\ttotal: 5.85s\tremaining: 30.3s\n",
      "162:\tlearn: 0.2875930\ttotal: 5.88s\tremaining: 30.2s\n",
      "163:\tlearn: 0.2867481\ttotal: 5.92s\tremaining: 30.2s\n",
      "164:\tlearn: 0.2858613\ttotal: 5.96s\tremaining: 30.2s\n",
      "165:\tlearn: 0.2853752\ttotal: 6s\tremaining: 30.1s\n",
      "166:\tlearn: 0.2848750\ttotal: 6.03s\tremaining: 30.1s\n",
      "167:\tlearn: 0.2844366\ttotal: 6.06s\tremaining: 30s\n",
      "168:\tlearn: 0.2839354\ttotal: 6.09s\tremaining: 30s\n",
      "169:\tlearn: 0.2831180\ttotal: 6.13s\tremaining: 29.9s\n",
      "170:\tlearn: 0.2827055\ttotal: 6.16s\tremaining: 29.9s\n",
      "171:\tlearn: 0.2824541\ttotal: 6.2s\tremaining: 29.9s\n",
      "172:\tlearn: 0.2817955\ttotal: 6.25s\tremaining: 29.9s\n",
      "173:\tlearn: 0.2811167\ttotal: 6.29s\tremaining: 29.8s\n",
      "174:\tlearn: 0.2807174\ttotal: 6.32s\tremaining: 29.8s\n",
      "175:\tlearn: 0.2796857\ttotal: 6.35s\tremaining: 29.7s\n",
      "176:\tlearn: 0.2788288\ttotal: 6.39s\tremaining: 29.7s\n",
      "177:\tlearn: 0.2781034\ttotal: 6.43s\tremaining: 29.7s\n",
      "178:\tlearn: 0.2777930\ttotal: 6.46s\tremaining: 29.6s\n",
      "179:\tlearn: 0.2773115\ttotal: 6.49s\tremaining: 29.6s\n",
      "180:\tlearn: 0.2771396\ttotal: 6.52s\tremaining: 29.5s\n",
      "181:\tlearn: 0.2768159\ttotal: 6.55s\tremaining: 29.5s\n",
      "182:\tlearn: 0.2765373\ttotal: 6.59s\tremaining: 29.4s\n",
      "183:\tlearn: 0.2759760\ttotal: 6.63s\tremaining: 29.4s\n",
      "184:\tlearn: 0.2754335\ttotal: 6.67s\tremaining: 29.4s\n",
      "185:\tlearn: 0.2750090\ttotal: 6.71s\tremaining: 29.4s\n",
      "186:\tlearn: 0.2744644\ttotal: 6.74s\tremaining: 29.3s\n",
      "187:\tlearn: 0.2738904\ttotal: 6.77s\tremaining: 29.2s\n",
      "188:\tlearn: 0.2728842\ttotal: 6.8s\tremaining: 29.2s\n",
      "189:\tlearn: 0.2725955\ttotal: 6.84s\tremaining: 29.1s\n",
      "190:\tlearn: 0.2718241\ttotal: 6.87s\tremaining: 29.1s\n",
      "191:\tlearn: 0.2712299\ttotal: 6.9s\tremaining: 29s\n",
      "192:\tlearn: 0.2708754\ttotal: 6.94s\tremaining: 29s\n",
      "193:\tlearn: 0.2698764\ttotal: 6.97s\tremaining: 29s\n",
      "194:\tlearn: 0.2697076\ttotal: 7s\tremaining: 28.9s\n",
      "195:\tlearn: 0.2693692\ttotal: 7.05s\tremaining: 28.9s\n",
      "196:\tlearn: 0.2687697\ttotal: 7.08s\tremaining: 28.9s\n",
      "197:\tlearn: 0.2683944\ttotal: 7.12s\tremaining: 28.8s\n",
      "198:\tlearn: 0.2677626\ttotal: 7.15s\tremaining: 28.8s\n",
      "199:\tlearn: 0.2676067\ttotal: 7.18s\tremaining: 28.7s\n",
      "200:\tlearn: 0.2667247\ttotal: 7.21s\tremaining: 28.7s\n",
      "201:\tlearn: 0.2660064\ttotal: 7.25s\tremaining: 28.6s\n",
      "202:\tlearn: 0.2656993\ttotal: 7.29s\tremaining: 28.6s\n",
      "203:\tlearn: 0.2655723\ttotal: 7.33s\tremaining: 28.6s\n",
      "204:\tlearn: 0.2651099\ttotal: 7.37s\tremaining: 28.6s\n",
      "205:\tlearn: 0.2644283\ttotal: 7.41s\tremaining: 28.5s\n",
      "206:\tlearn: 0.2639458\ttotal: 7.44s\tremaining: 28.5s\n",
      "207:\tlearn: 0.2633149\ttotal: 7.47s\tremaining: 28.4s\n",
      "208:\tlearn: 0.2630985\ttotal: 7.5s\tremaining: 28.4s\n",
      "209:\tlearn: 0.2624609\ttotal: 7.54s\tremaining: 28.3s\n",
      "210:\tlearn: 0.2621165\ttotal: 7.57s\tremaining: 28.3s\n",
      "211:\tlearn: 0.2619381\ttotal: 7.61s\tremaining: 28.3s\n",
      "212:\tlearn: 0.2616316\ttotal: 7.64s\tremaining: 28.2s\n",
      "213:\tlearn: 0.2611699\ttotal: 7.68s\tremaining: 28.2s\n",
      "214:\tlearn: 0.2606193\ttotal: 7.72s\tremaining: 28.2s\n",
      "215:\tlearn: 0.2600594\ttotal: 7.75s\tremaining: 28.1s\n",
      "216:\tlearn: 0.2597523\ttotal: 7.78s\tremaining: 28.1s\n",
      "217:\tlearn: 0.2593115\ttotal: 7.82s\tremaining: 28s\n",
      "218:\tlearn: 0.2590713\ttotal: 7.85s\tremaining: 28s\n",
      "219:\tlearn: 0.2587761\ttotal: 7.88s\tremaining: 27.9s\n",
      "220:\tlearn: 0.2584802\ttotal: 7.91s\tremaining: 27.9s\n",
      "221:\tlearn: 0.2581114\ttotal: 7.96s\tremaining: 27.9s\n",
      "222:\tlearn: 0.2576896\ttotal: 8s\tremaining: 27.9s\n",
      "223:\tlearn: 0.2569799\ttotal: 8.04s\tremaining: 27.8s\n",
      "224:\tlearn: 0.2565795\ttotal: 8.07s\tremaining: 27.8s\n",
      "225:\tlearn: 0.2564449\ttotal: 8.1s\tremaining: 27.7s\n",
      "226:\tlearn: 0.2561354\ttotal: 8.13s\tremaining: 27.7s\n",
      "227:\tlearn: 0.2558551\ttotal: 8.16s\tremaining: 27.6s\n",
      "228:\tlearn: 0.2555946\ttotal: 8.19s\tremaining: 27.6s\n",
      "229:\tlearn: 0.2553240\ttotal: 8.23s\tremaining: 27.6s\n",
      "230:\tlearn: 0.2550702\ttotal: 8.27s\tremaining: 27.5s\n",
      "231:\tlearn: 0.2545452\ttotal: 8.3s\tremaining: 27.5s\n",
      "232:\tlearn: 0.2542850\ttotal: 8.35s\tremaining: 27.5s\n",
      "233:\tlearn: 0.2541136\ttotal: 8.39s\tremaining: 27.5s\n",
      "234:\tlearn: 0.2538059\ttotal: 8.43s\tremaining: 27.4s\n",
      "235:\tlearn: 0.2535925\ttotal: 8.46s\tremaining: 27.4s\n",
      "236:\tlearn: 0.2531640\ttotal: 8.49s\tremaining: 27.3s\n",
      "237:\tlearn: 0.2525898\ttotal: 8.53s\tremaining: 27.3s\n",
      "238:\tlearn: 0.2522917\ttotal: 8.56s\tremaining: 27.3s\n",
      "239:\tlearn: 0.2519908\ttotal: 8.6s\tremaining: 27.2s\n",
      "240:\tlearn: 0.2517049\ttotal: 8.63s\tremaining: 27.2s\n",
      "241:\tlearn: 0.2515101\ttotal: 8.67s\tremaining: 27.2s\n",
      "242:\tlearn: 0.2509855\ttotal: 8.72s\tremaining: 27.2s\n",
      "243:\tlearn: 0.2505676\ttotal: 8.76s\tremaining: 27.1s\n",
      "244:\tlearn: 0.2500237\ttotal: 8.79s\tremaining: 27.1s\n",
      "245:\tlearn: 0.2496714\ttotal: 8.82s\tremaining: 27s\n",
      "246:\tlearn: 0.2493273\ttotal: 8.85s\tremaining: 27s\n",
      "247:\tlearn: 0.2489940\ttotal: 8.88s\tremaining: 26.9s\n",
      "248:\tlearn: 0.2488187\ttotal: 8.91s\tremaining: 26.9s\n",
      "249:\tlearn: 0.2485323\ttotal: 8.95s\tremaining: 26.8s\n",
      "250:\tlearn: 0.2483210\ttotal: 8.99s\tremaining: 26.8s\n",
      "251:\tlearn: 0.2479182\ttotal: 9.02s\tremaining: 26.8s\n",
      "252:\tlearn: 0.2476701\ttotal: 9.06s\tremaining: 26.7s\n",
      "253:\tlearn: 0.2473532\ttotal: 9.1s\tremaining: 26.7s\n",
      "254:\tlearn: 0.2469668\ttotal: 9.13s\tremaining: 26.7s\n",
      "255:\tlearn: 0.2467165\ttotal: 9.17s\tremaining: 26.6s\n",
      "256:\tlearn: 0.2464470\ttotal: 9.2s\tremaining: 26.6s\n",
      "257:\tlearn: 0.2460835\ttotal: 9.23s\tremaining: 26.5s\n",
      "258:\tlearn: 0.2456453\ttotal: 9.27s\tremaining: 26.5s\n",
      "259:\tlearn: 0.2455037\ttotal: 9.3s\tremaining: 26.5s\n",
      "260:\tlearn: 0.2452794\ttotal: 9.34s\tremaining: 26.5s\n",
      "261:\tlearn: 0.2450257\ttotal: 9.38s\tremaining: 26.4s\n",
      "262:\tlearn: 0.2445852\ttotal: 9.43s\tremaining: 26.4s\n",
      "263:\tlearn: 0.2443095\ttotal: 9.46s\tremaining: 26.4s\n",
      "264:\tlearn: 0.2440016\ttotal: 9.5s\tremaining: 26.4s\n",
      "265:\tlearn: 0.2437093\ttotal: 9.54s\tremaining: 26.3s\n",
      "266:\tlearn: 0.2430813\ttotal: 9.58s\tremaining: 26.3s\n",
      "267:\tlearn: 0.2428951\ttotal: 9.61s\tremaining: 26.2s\n",
      "268:\tlearn: 0.2427820\ttotal: 9.64s\tremaining: 26.2s\n",
      "269:\tlearn: 0.2423576\ttotal: 9.68s\tremaining: 26.2s\n",
      "270:\tlearn: 0.2418115\ttotal: 9.71s\tremaining: 26.1s\n",
      "271:\tlearn: 0.2416602\ttotal: 9.75s\tremaining: 26.1s\n",
      "272:\tlearn: 0.2414515\ttotal: 9.8s\tremaining: 26.1s\n",
      "273:\tlearn: 0.2412871\ttotal: 9.83s\tremaining: 26s\n",
      "274:\tlearn: 0.2410783\ttotal: 9.86s\tremaining: 26s\n",
      "275:\tlearn: 0.2408675\ttotal: 9.89s\tremaining: 26s\n",
      "276:\tlearn: 0.2403739\ttotal: 9.93s\tremaining: 25.9s\n",
      "277:\tlearn: 0.2399638\ttotal: 9.96s\tremaining: 25.9s\n",
      "278:\tlearn: 0.2395247\ttotal: 9.99s\tremaining: 25.8s\n",
      "279:\tlearn: 0.2391822\ttotal: 10s\tremaining: 25.8s\n",
      "280:\tlearn: 0.2389976\ttotal: 10.1s\tremaining: 25.8s\n",
      "281:\tlearn: 0.2386224\ttotal: 10.1s\tremaining: 25.7s\n",
      "282:\tlearn: 0.2381586\ttotal: 10.1s\tremaining: 25.7s\n",
      "283:\tlearn: 0.2379564\ttotal: 10.2s\tremaining: 25.7s\n",
      "284:\tlearn: 0.2374901\ttotal: 10.2s\tremaining: 25.6s\n",
      "285:\tlearn: 0.2373598\ttotal: 10.2s\tremaining: 25.6s\n",
      "286:\tlearn: 0.2369611\ttotal: 10.3s\tremaining: 25.5s\n",
      "287:\tlearn: 0.2368230\ttotal: 10.3s\tremaining: 25.5s\n",
      "288:\tlearn: 0.2365838\ttotal: 10.3s\tremaining: 25.5s\n",
      "289:\tlearn: 0.2362627\ttotal: 10.4s\tremaining: 25.4s\n",
      "290:\tlearn: 0.2360612\ttotal: 10.4s\tremaining: 25.4s\n",
      "291:\tlearn: 0.2356669\ttotal: 10.5s\tremaining: 25.4s\n",
      "292:\tlearn: 0.2353627\ttotal: 10.5s\tremaining: 25.3s\n",
      "293:\tlearn: 0.2350979\ttotal: 10.5s\tremaining: 25.3s\n",
      "294:\tlearn: 0.2349865\ttotal: 10.6s\tremaining: 25.2s\n",
      "295:\tlearn: 0.2345263\ttotal: 10.6s\tremaining: 25.2s\n",
      "296:\tlearn: 0.2342193\ttotal: 10.6s\tremaining: 25.2s\n",
      "297:\tlearn: 0.2338866\ttotal: 10.7s\tremaining: 25.1s\n",
      "298:\tlearn: 0.2334748\ttotal: 10.7s\tremaining: 25.1s\n",
      "299:\tlearn: 0.2333491\ttotal: 10.7s\tremaining: 25s\n",
      "300:\tlearn: 0.2329526\ttotal: 10.8s\tremaining: 25s\n",
      "301:\tlearn: 0.2328259\ttotal: 10.8s\tremaining: 25s\n",
      "302:\tlearn: 0.2325447\ttotal: 10.8s\tremaining: 24.9s\n",
      "303:\tlearn: 0.2322689\ttotal: 10.9s\tremaining: 24.9s\n",
      "304:\tlearn: 0.2317900\ttotal: 10.9s\tremaining: 24.9s\n",
      "305:\tlearn: 0.2316463\ttotal: 10.9s\tremaining: 24.8s\n",
      "306:\tlearn: 0.2313152\ttotal: 11s\tremaining: 24.8s\n",
      "307:\tlearn: 0.2311956\ttotal: 11s\tremaining: 24.7s\n",
      "308:\tlearn: 0.2310719\ttotal: 11s\tremaining: 24.7s\n",
      "309:\tlearn: 0.2309560\ttotal: 11.1s\tremaining: 24.7s\n",
      "310:\tlearn: 0.2305734\ttotal: 11.1s\tremaining: 24.7s\n",
      "311:\tlearn: 0.2301193\ttotal: 11.2s\tremaining: 24.6s\n",
      "312:\tlearn: 0.2299465\ttotal: 11.2s\tremaining: 24.6s\n",
      "313:\tlearn: 0.2297660\ttotal: 11.3s\tremaining: 24.6s\n",
      "314:\tlearn: 0.2296700\ttotal: 11.3s\tremaining: 24.5s\n",
      "315:\tlearn: 0.2295536\ttotal: 11.3s\tremaining: 24.5s\n",
      "316:\tlearn: 0.2293840\ttotal: 11.4s\tremaining: 24.5s\n",
      "317:\tlearn: 0.2291735\ttotal: 11.4s\tremaining: 24.4s\n",
      "318:\tlearn: 0.2288552\ttotal: 11.4s\tremaining: 24.4s\n",
      "319:\tlearn: 0.2286534\ttotal: 11.5s\tremaining: 24.3s\n",
      "320:\tlearn: 0.2279813\ttotal: 11.5s\tremaining: 24.3s\n",
      "321:\tlearn: 0.2277572\ttotal: 11.5s\tremaining: 24.3s\n",
      "322:\tlearn: 0.2276345\ttotal: 11.6s\tremaining: 24.3s\n",
      "323:\tlearn: 0.2273114\ttotal: 11.6s\tremaining: 24.3s\n",
      "324:\tlearn: 0.2272073\ttotal: 11.7s\tremaining: 24.2s\n",
      "325:\tlearn: 0.2268778\ttotal: 11.7s\tremaining: 24.2s\n",
      "326:\tlearn: 0.2267420\ttotal: 11.7s\tremaining: 24.1s\n",
      "327:\tlearn: 0.2264458\ttotal: 11.8s\tremaining: 24.1s\n",
      "328:\tlearn: 0.2262787\ttotal: 11.8s\tremaining: 24.1s\n",
      "329:\tlearn: 0.2261587\ttotal: 11.8s\tremaining: 24s\n",
      "330:\tlearn: 0.2259798\ttotal: 11.9s\tremaining: 24s\n",
      "331:\tlearn: 0.2258136\ttotal: 11.9s\tremaining: 24s\n",
      "332:\tlearn: 0.2255296\ttotal: 12s\tremaining: 23.9s\n",
      "333:\tlearn: 0.2254073\ttotal: 12s\tremaining: 23.9s\n",
      "334:\tlearn: 0.2250391\ttotal: 12s\tremaining: 23.9s\n",
      "335:\tlearn: 0.2246751\ttotal: 12.1s\tremaining: 23.8s\n",
      "336:\tlearn: 0.2243264\ttotal: 12.1s\tremaining: 23.8s\n",
      "337:\tlearn: 0.2241338\ttotal: 12.1s\tremaining: 23.8s\n",
      "338:\tlearn: 0.2240173\ttotal: 12.2s\tremaining: 23.7s\n",
      "339:\tlearn: 0.2237340\ttotal: 12.2s\tremaining: 23.7s\n",
      "340:\tlearn: 0.2234526\ttotal: 12.2s\tremaining: 23.6s\n",
      "341:\tlearn: 0.2229510\ttotal: 12.3s\tremaining: 23.6s\n",
      "342:\tlearn: 0.2225800\ttotal: 12.3s\tremaining: 23.6s\n",
      "343:\tlearn: 0.2223119\ttotal: 12.4s\tremaining: 23.6s\n",
      "344:\tlearn: 0.2222164\ttotal: 12.4s\tremaining: 23.5s\n",
      "345:\tlearn: 0.2218753\ttotal: 12.4s\tremaining: 23.5s\n",
      "346:\tlearn: 0.2217682\ttotal: 12.5s\tremaining: 23.5s\n",
      "347:\tlearn: 0.2216429\ttotal: 12.5s\tremaining: 23.4s\n",
      "348:\tlearn: 0.2212511\ttotal: 12.5s\tremaining: 23.4s\n",
      "349:\tlearn: 0.2211774\ttotal: 12.6s\tremaining: 23.4s\n",
      "350:\tlearn: 0.2210383\ttotal: 12.6s\tremaining: 23.3s\n",
      "351:\tlearn: 0.2206611\ttotal: 12.6s\tremaining: 23.3s\n",
      "352:\tlearn: 0.2205674\ttotal: 12.7s\tremaining: 23.3s\n",
      "353:\tlearn: 0.2200313\ttotal: 12.7s\tremaining: 23.2s\n",
      "354:\tlearn: 0.2197190\ttotal: 12.8s\tremaining: 23.2s\n",
      "355:\tlearn: 0.2194887\ttotal: 12.8s\tremaining: 23.2s\n",
      "356:\tlearn: 0.2191930\ttotal: 12.8s\tremaining: 23.1s\n",
      "357:\tlearn: 0.2191301\ttotal: 12.9s\tremaining: 23.1s\n",
      "358:\tlearn: 0.2188524\ttotal: 12.9s\tremaining: 23s\n",
      "359:\tlearn: 0.2186506\ttotal: 12.9s\tremaining: 23s\n",
      "360:\tlearn: 0.2183573\ttotal: 13s\tremaining: 23s\n",
      "361:\tlearn: 0.2179131\ttotal: 13s\tremaining: 22.9s\n",
      "362:\tlearn: 0.2177260\ttotal: 13s\tremaining: 22.9s\n",
      "363:\tlearn: 0.2176435\ttotal: 13.1s\tremaining: 22.9s\n",
      "364:\tlearn: 0.2174769\ttotal: 13.1s\tremaining: 22.8s\n",
      "365:\tlearn: 0.2170351\ttotal: 13.2s\tremaining: 22.8s\n",
      "366:\tlearn: 0.2168950\ttotal: 13.2s\tremaining: 22.8s\n",
      "367:\tlearn: 0.2167855\ttotal: 13.2s\tremaining: 22.7s\n",
      "368:\tlearn: 0.2163411\ttotal: 13.3s\tremaining: 22.7s\n",
      "369:\tlearn: 0.2162806\ttotal: 13.3s\tremaining: 22.6s\n",
      "370:\tlearn: 0.2161164\ttotal: 13.3s\tremaining: 22.6s\n",
      "371:\tlearn: 0.2158686\ttotal: 13.4s\tremaining: 22.5s\n",
      "372:\tlearn: 0.2157314\ttotal: 13.4s\tremaining: 22.5s\n",
      "373:\tlearn: 0.2155440\ttotal: 13.4s\tremaining: 22.5s\n",
      "374:\tlearn: 0.2154080\ttotal: 13.5s\tremaining: 22.5s\n",
      "375:\tlearn: 0.2150855\ttotal: 13.5s\tremaining: 22.4s\n",
      "376:\tlearn: 0.2149805\ttotal: 13.5s\tremaining: 22.4s\n",
      "377:\tlearn: 0.2149324\ttotal: 13.6s\tremaining: 22.3s\n",
      "378:\tlearn: 0.2147814\ttotal: 13.6s\tremaining: 22.3s\n",
      "379:\tlearn: 0.2145451\ttotal: 13.6s\tremaining: 22.3s\n",
      "380:\tlearn: 0.2144351\ttotal: 13.7s\tremaining: 22.2s\n",
      "381:\tlearn: 0.2143192\ttotal: 13.7s\tremaining: 22.2s\n",
      "382:\tlearn: 0.2141373\ttotal: 13.8s\tremaining: 22.2s\n",
      "383:\tlearn: 0.2139487\ttotal: 13.8s\tremaining: 22.1s\n",
      "384:\tlearn: 0.2138711\ttotal: 13.8s\tremaining: 22.1s\n",
      "385:\tlearn: 0.2134652\ttotal: 13.9s\tremaining: 22.1s\n",
      "386:\tlearn: 0.2130512\ttotal: 13.9s\tremaining: 22s\n",
      "387:\tlearn: 0.2129799\ttotal: 13.9s\tremaining: 22s\n",
      "388:\tlearn: 0.2128666\ttotal: 14s\tremaining: 21.9s\n",
      "389:\tlearn: 0.2127459\ttotal: 14s\tremaining: 21.9s\n",
      "390:\tlearn: 0.2126035\ttotal: 14s\tremaining: 21.8s\n",
      "391:\tlearn: 0.2125200\ttotal: 14.1s\tremaining: 21.8s\n",
      "392:\tlearn: 0.2124029\ttotal: 14.1s\tremaining: 21.8s\n",
      "393:\tlearn: 0.2123030\ttotal: 14.1s\tremaining: 21.8s\n",
      "394:\tlearn: 0.2121332\ttotal: 14.2s\tremaining: 21.7s\n",
      "395:\tlearn: 0.2117948\ttotal: 14.2s\tremaining: 21.7s\n",
      "396:\tlearn: 0.2114824\ttotal: 14.2s\tremaining: 21.6s\n",
      "397:\tlearn: 0.2112929\ttotal: 14.3s\tremaining: 21.6s\n",
      "398:\tlearn: 0.2111588\ttotal: 14.3s\tremaining: 21.6s\n",
      "399:\tlearn: 0.2110096\ttotal: 14.3s\tremaining: 21.5s\n",
      "400:\tlearn: 0.2108362\ttotal: 14.4s\tremaining: 21.5s\n",
      "401:\tlearn: 0.2106687\ttotal: 14.4s\tremaining: 21.4s\n",
      "402:\tlearn: 0.2104347\ttotal: 14.5s\tremaining: 21.4s\n",
      "403:\tlearn: 0.2102453\ttotal: 14.5s\tremaining: 21.4s\n",
      "404:\tlearn: 0.2098451\ttotal: 14.5s\tremaining: 21.3s\n",
      "405:\tlearn: 0.2096826\ttotal: 14.6s\tremaining: 21.3s\n",
      "406:\tlearn: 0.2094259\ttotal: 14.6s\tremaining: 21.3s\n",
      "407:\tlearn: 0.2091800\ttotal: 14.6s\tremaining: 21.2s\n",
      "408:\tlearn: 0.2090858\ttotal: 14.7s\tremaining: 21.2s\n",
      "409:\tlearn: 0.2089561\ttotal: 14.7s\tremaining: 21.2s\n",
      "410:\tlearn: 0.2088615\ttotal: 14.8s\tremaining: 21.1s\n",
      "411:\tlearn: 0.2086604\ttotal: 14.8s\tremaining: 21.1s\n",
      "412:\tlearn: 0.2083182\ttotal: 14.8s\tremaining: 21.1s\n",
      "413:\tlearn: 0.2081351\ttotal: 14.9s\tremaining: 21s\n",
      "414:\tlearn: 0.2079744\ttotal: 14.9s\tremaining: 21s\n",
      "415:\tlearn: 0.2078256\ttotal: 14.9s\tremaining: 20.9s\n",
      "416:\tlearn: 0.2077110\ttotal: 15s\tremaining: 20.9s\n",
      "417:\tlearn: 0.2075328\ttotal: 15s\tremaining: 20.9s\n",
      "418:\tlearn: 0.2074644\ttotal: 15s\tremaining: 20.8s\n",
      "419:\tlearn: 0.2072859\ttotal: 15.1s\tremaining: 20.8s\n",
      "420:\tlearn: 0.2071471\ttotal: 15.1s\tremaining: 20.8s\n",
      "421:\tlearn: 0.2070342\ttotal: 15.1s\tremaining: 20.7s\n",
      "422:\tlearn: 0.2068840\ttotal: 15.2s\tremaining: 20.7s\n",
      "423:\tlearn: 0.2066921\ttotal: 15.2s\tremaining: 20.7s\n",
      "424:\tlearn: 0.2063665\ttotal: 15.2s\tremaining: 20.6s\n",
      "425:\tlearn: 0.2061919\ttotal: 15.3s\tremaining: 20.6s\n",
      "426:\tlearn: 0.2060840\ttotal: 15.3s\tremaining: 20.5s\n",
      "427:\tlearn: 0.2059168\ttotal: 15.3s\tremaining: 20.5s\n",
      "428:\tlearn: 0.2057050\ttotal: 15.4s\tremaining: 20.5s\n",
      "429:\tlearn: 0.2053867\ttotal: 15.4s\tremaining: 20.5s\n",
      "430:\tlearn: 0.2052820\ttotal: 15.5s\tremaining: 20.4s\n",
      "431:\tlearn: 0.2051700\ttotal: 15.5s\tremaining: 20.4s\n",
      "432:\tlearn: 0.2047131\ttotal: 15.5s\tremaining: 20.3s\n",
      "433:\tlearn: 0.2042966\ttotal: 15.6s\tremaining: 20.3s\n",
      "434:\tlearn: 0.2041515\ttotal: 15.6s\tremaining: 20.3s\n",
      "435:\tlearn: 0.2039280\ttotal: 15.6s\tremaining: 20.2s\n",
      "436:\tlearn: 0.2036783\ttotal: 15.7s\tremaining: 20.2s\n",
      "437:\tlearn: 0.2035685\ttotal: 15.7s\tremaining: 20.1s\n",
      "438:\tlearn: 0.2034402\ttotal: 15.7s\tremaining: 20.1s\n",
      "439:\tlearn: 0.2029791\ttotal: 15.8s\tremaining: 20.1s\n",
      "440:\tlearn: 0.2027714\ttotal: 15.8s\tremaining: 20s\n",
      "441:\tlearn: 0.2026767\ttotal: 15.8s\tremaining: 20s\n",
      "442:\tlearn: 0.2024714\ttotal: 15.9s\tremaining: 20s\n",
      "443:\tlearn: 0.2023545\ttotal: 15.9s\tremaining: 19.9s\n",
      "444:\tlearn: 0.2022174\ttotal: 15.9s\tremaining: 19.9s\n",
      "445:\tlearn: 0.2020859\ttotal: 16s\tremaining: 19.8s\n",
      "446:\tlearn: 0.2019095\ttotal: 16s\tremaining: 19.8s\n",
      "447:\tlearn: 0.2017334\ttotal: 16s\tremaining: 19.8s\n",
      "448:\tlearn: 0.2015533\ttotal: 16.1s\tremaining: 19.7s\n",
      "449:\tlearn: 0.2013871\ttotal: 16.1s\tremaining: 19.7s\n",
      "450:\tlearn: 0.2013058\ttotal: 16.2s\tremaining: 19.7s\n",
      "451:\tlearn: 0.2009881\ttotal: 16.2s\tremaining: 19.6s\n",
      "452:\tlearn: 0.2006727\ttotal: 16.2s\tremaining: 19.6s\n",
      "453:\tlearn: 0.2004957\ttotal: 16.3s\tremaining: 19.6s\n",
      "454:\tlearn: 0.2001582\ttotal: 16.3s\tremaining: 19.5s\n",
      "455:\tlearn: 0.1999552\ttotal: 16.3s\tremaining: 19.5s\n",
      "456:\tlearn: 0.1997805\ttotal: 16.4s\tremaining: 19.4s\n",
      "457:\tlearn: 0.1997204\ttotal: 16.4s\tremaining: 19.4s\n",
      "458:\tlearn: 0.1995156\ttotal: 16.4s\tremaining: 19.4s\n",
      "459:\tlearn: 0.1992994\ttotal: 16.5s\tremaining: 19.3s\n",
      "460:\tlearn: 0.1991387\ttotal: 16.5s\tremaining: 19.3s\n",
      "461:\tlearn: 0.1990309\ttotal: 16.5s\tremaining: 19.3s\n",
      "462:\tlearn: 0.1988842\ttotal: 16.6s\tremaining: 19.2s\n",
      "463:\tlearn: 0.1988148\ttotal: 16.6s\tremaining: 19.2s\n",
      "464:\tlearn: 0.1986579\ttotal: 16.6s\tremaining: 19.1s\n",
      "465:\tlearn: 0.1984996\ttotal: 16.7s\tremaining: 19.1s\n",
      "466:\tlearn: 0.1984165\ttotal: 16.7s\tremaining: 19.1s\n",
      "467:\tlearn: 0.1983010\ttotal: 16.8s\tremaining: 19s\n",
      "468:\tlearn: 0.1982189\ttotal: 16.8s\tremaining: 19s\n",
      "469:\tlearn: 0.1980672\ttotal: 16.8s\tremaining: 19s\n",
      "470:\tlearn: 0.1977635\ttotal: 16.9s\tremaining: 18.9s\n",
      "471:\tlearn: 0.1974142\ttotal: 16.9s\tremaining: 18.9s\n",
      "472:\tlearn: 0.1971561\ttotal: 16.9s\tremaining: 18.9s\n",
      "473:\tlearn: 0.1966992\ttotal: 17s\tremaining: 18.8s\n",
      "474:\tlearn: 0.1965138\ttotal: 17s\tremaining: 18.8s\n",
      "475:\tlearn: 0.1964132\ttotal: 17s\tremaining: 18.7s\n",
      "476:\tlearn: 0.1962206\ttotal: 17.1s\tremaining: 18.7s\n",
      "477:\tlearn: 0.1961392\ttotal: 17.1s\tremaining: 18.7s\n",
      "478:\tlearn: 0.1960562\ttotal: 17.1s\tremaining: 18.6s\n",
      "479:\tlearn: 0.1959616\ttotal: 17.2s\tremaining: 18.6s\n",
      "480:\tlearn: 0.1957589\ttotal: 17.2s\tremaining: 18.6s\n",
      "481:\tlearn: 0.1955050\ttotal: 17.2s\tremaining: 18.5s\n",
      "482:\tlearn: 0.1952987\ttotal: 17.3s\tremaining: 18.5s\n",
      "483:\tlearn: 0.1950687\ttotal: 17.3s\tremaining: 18.5s\n",
      "484:\tlearn: 0.1948502\ttotal: 17.3s\tremaining: 18.4s\n",
      "485:\tlearn: 0.1947241\ttotal: 17.4s\tremaining: 18.4s\n",
      "486:\tlearn: 0.1946427\ttotal: 17.4s\tremaining: 18.3s\n",
      "487:\tlearn: 0.1944561\ttotal: 17.4s\tremaining: 18.3s\n",
      "488:\tlearn: 0.1942062\ttotal: 17.5s\tremaining: 18.3s\n",
      "489:\tlearn: 0.1939154\ttotal: 17.5s\tremaining: 18.2s\n",
      "490:\tlearn: 0.1937331\ttotal: 17.6s\tremaining: 18.2s\n",
      "491:\tlearn: 0.1934624\ttotal: 17.6s\tremaining: 18.2s\n",
      "492:\tlearn: 0.1932975\ttotal: 17.6s\tremaining: 18.1s\n",
      "493:\tlearn: 0.1931001\ttotal: 17.7s\tremaining: 18.1s\n",
      "494:\tlearn: 0.1929258\ttotal: 17.7s\tremaining: 18s\n",
      "495:\tlearn: 0.1927979\ttotal: 17.7s\tremaining: 18s\n",
      "496:\tlearn: 0.1926038\ttotal: 17.7s\tremaining: 18s\n",
      "497:\tlearn: 0.1924418\ttotal: 17.8s\tremaining: 17.9s\n",
      "498:\tlearn: 0.1922743\ttotal: 17.8s\tremaining: 17.9s\n",
      "499:\tlearn: 0.1922160\ttotal: 17.9s\tremaining: 17.9s\n",
      "500:\tlearn: 0.1921009\ttotal: 17.9s\tremaining: 17.8s\n",
      "501:\tlearn: 0.1919839\ttotal: 17.9s\tremaining: 17.8s\n",
      "502:\tlearn: 0.1916198\ttotal: 18s\tremaining: 17.8s\n",
      "503:\tlearn: 0.1914733\ttotal: 18s\tremaining: 17.7s\n",
      "504:\tlearn: 0.1914041\ttotal: 18s\tremaining: 17.7s\n",
      "505:\tlearn: 0.1912445\ttotal: 18.1s\tremaining: 17.6s\n",
      "506:\tlearn: 0.1910967\ttotal: 18.1s\tremaining: 17.6s\n",
      "507:\tlearn: 0.1910091\ttotal: 18.2s\tremaining: 17.6s\n",
      "508:\tlearn: 0.1908929\ttotal: 18.2s\tremaining: 17.6s\n",
      "509:\tlearn: 0.1907495\ttotal: 18.2s\tremaining: 17.5s\n",
      "510:\tlearn: 0.1906654\ttotal: 18.3s\tremaining: 17.5s\n",
      "511:\tlearn: 0.1905280\ttotal: 18.3s\tremaining: 17.4s\n",
      "512:\tlearn: 0.1903525\ttotal: 18.3s\tremaining: 17.4s\n",
      "513:\tlearn: 0.1902563\ttotal: 18.4s\tremaining: 17.4s\n",
      "514:\tlearn: 0.1900045\ttotal: 18.4s\tremaining: 17.3s\n",
      "515:\tlearn: 0.1898304\ttotal: 18.4s\tremaining: 17.3s\n",
      "516:\tlearn: 0.1896504\ttotal: 18.5s\tremaining: 17.2s\n",
      "517:\tlearn: 0.1895497\ttotal: 18.5s\tremaining: 17.2s\n",
      "518:\tlearn: 0.1894915\ttotal: 18.5s\tremaining: 17.2s\n",
      "519:\tlearn: 0.1892533\ttotal: 18.6s\tremaining: 17.1s\n",
      "520:\tlearn: 0.1890268\ttotal: 18.6s\tremaining: 17.1s\n",
      "521:\tlearn: 0.1889307\ttotal: 18.6s\tremaining: 17.1s\n",
      "522:\tlearn: 0.1887635\ttotal: 18.7s\tremaining: 17s\n",
      "523:\tlearn: 0.1886820\ttotal: 18.7s\tremaining: 17s\n",
      "524:\tlearn: 0.1886231\ttotal: 18.7s\tremaining: 16.9s\n",
      "525:\tlearn: 0.1883959\ttotal: 18.8s\tremaining: 16.9s\n",
      "526:\tlearn: 0.1882845\ttotal: 18.8s\tremaining: 16.9s\n",
      "527:\tlearn: 0.1880627\ttotal: 18.9s\tremaining: 16.9s\n",
      "528:\tlearn: 0.1879208\ttotal: 18.9s\tremaining: 16.8s\n",
      "529:\tlearn: 0.1877588\ttotal: 18.9s\tremaining: 16.8s\n",
      "530:\tlearn: 0.1875760\ttotal: 19s\tremaining: 16.7s\n",
      "531:\tlearn: 0.1874429\ttotal: 19s\tremaining: 16.7s\n",
      "532:\tlearn: 0.1872466\ttotal: 19s\tremaining: 16.7s\n",
      "533:\tlearn: 0.1871169\ttotal: 19.1s\tremaining: 16.6s\n",
      "534:\tlearn: 0.1869093\ttotal: 19.1s\tremaining: 16.6s\n",
      "535:\tlearn: 0.1867813\ttotal: 19.1s\tremaining: 16.6s\n",
      "536:\tlearn: 0.1865764\ttotal: 19.2s\tremaining: 16.5s\n",
      "537:\tlearn: 0.1864622\ttotal: 19.2s\tremaining: 16.5s\n",
      "538:\tlearn: 0.1863229\ttotal: 19.2s\tremaining: 16.5s\n",
      "539:\tlearn: 0.1859976\ttotal: 19.3s\tremaining: 16.4s\n",
      "540:\tlearn: 0.1857825\ttotal: 19.3s\tremaining: 16.4s\n",
      "541:\tlearn: 0.1855232\ttotal: 19.3s\tremaining: 16.3s\n",
      "542:\tlearn: 0.1854311\ttotal: 19.4s\tremaining: 16.3s\n",
      "543:\tlearn: 0.1853394\ttotal: 19.4s\tremaining: 16.3s\n",
      "544:\tlearn: 0.1851761\ttotal: 19.4s\tremaining: 16.2s\n",
      "545:\tlearn: 0.1849824\ttotal: 19.5s\tremaining: 16.2s\n",
      "546:\tlearn: 0.1848763\ttotal: 19.5s\tremaining: 16.2s\n",
      "547:\tlearn: 0.1847449\ttotal: 19.6s\tremaining: 16.1s\n",
      "548:\tlearn: 0.1844025\ttotal: 19.6s\tremaining: 16.1s\n",
      "549:\tlearn: 0.1842628\ttotal: 19.6s\tremaining: 16.1s\n",
      "550:\tlearn: 0.1841544\ttotal: 19.7s\tremaining: 16s\n",
      "551:\tlearn: 0.1839417\ttotal: 19.7s\tremaining: 16s\n",
      "552:\tlearn: 0.1837590\ttotal: 19.7s\tremaining: 15.9s\n",
      "553:\tlearn: 0.1834506\ttotal: 19.8s\tremaining: 15.9s\n",
      "554:\tlearn: 0.1831942\ttotal: 19.8s\tremaining: 15.9s\n",
      "555:\tlearn: 0.1831429\ttotal: 19.8s\tremaining: 15.8s\n",
      "556:\tlearn: 0.1829471\ttotal: 19.9s\tremaining: 15.8s\n",
      "557:\tlearn: 0.1827812\ttotal: 19.9s\tremaining: 15.8s\n",
      "558:\tlearn: 0.1826560\ttotal: 20s\tremaining: 15.7s\n",
      "559:\tlearn: 0.1825739\ttotal: 20s\tremaining: 15.7s\n",
      "560:\tlearn: 0.1824804\ttotal: 20s\tremaining: 15.7s\n",
      "561:\tlearn: 0.1823069\ttotal: 20.1s\tremaining: 15.6s\n",
      "562:\tlearn: 0.1822687\ttotal: 20.1s\tremaining: 15.6s\n",
      "563:\tlearn: 0.1820800\ttotal: 20.1s\tremaining: 15.6s\n",
      "564:\tlearn: 0.1819499\ttotal: 20.2s\tremaining: 15.5s\n",
      "565:\tlearn: 0.1817862\ttotal: 20.2s\tremaining: 15.5s\n",
      "566:\tlearn: 0.1817208\ttotal: 20.3s\tremaining: 15.5s\n",
      "567:\tlearn: 0.1815825\ttotal: 20.3s\tremaining: 15.4s\n",
      "568:\tlearn: 0.1814416\ttotal: 20.3s\tremaining: 15.4s\n",
      "569:\tlearn: 0.1813415\ttotal: 20.3s\tremaining: 15.3s\n",
      "570:\tlearn: 0.1811726\ttotal: 20.4s\tremaining: 15.3s\n",
      "571:\tlearn: 0.1810785\ttotal: 20.4s\tremaining: 15.3s\n",
      "572:\tlearn: 0.1810144\ttotal: 20.4s\tremaining: 15.2s\n",
      "573:\tlearn: 0.1809414\ttotal: 20.5s\tremaining: 15.2s\n",
      "574:\tlearn: 0.1808663\ttotal: 20.5s\tremaining: 15.2s\n",
      "575:\tlearn: 0.1806805\ttotal: 20.5s\tremaining: 15.1s\n",
      "576:\tlearn: 0.1806220\ttotal: 20.6s\tremaining: 15.1s\n",
      "577:\tlearn: 0.1804422\ttotal: 20.6s\tremaining: 15.1s\n",
      "578:\tlearn: 0.1802430\ttotal: 20.7s\tremaining: 15s\n",
      "579:\tlearn: 0.1801144\ttotal: 20.7s\tremaining: 15s\n",
      "580:\tlearn: 0.1798879\ttotal: 20.7s\tremaining: 14.9s\n",
      "581:\tlearn: 0.1798438\ttotal: 20.8s\tremaining: 14.9s\n",
      "582:\tlearn: 0.1797676\ttotal: 20.8s\tremaining: 14.9s\n",
      "583:\tlearn: 0.1797036\ttotal: 20.8s\tremaining: 14.8s\n",
      "584:\tlearn: 0.1796151\ttotal: 20.9s\tremaining: 14.8s\n",
      "585:\tlearn: 0.1795275\ttotal: 20.9s\tremaining: 14.8s\n",
      "586:\tlearn: 0.1794795\ttotal: 20.9s\tremaining: 14.7s\n",
      "587:\tlearn: 0.1793758\ttotal: 21s\tremaining: 14.7s\n",
      "588:\tlearn: 0.1793256\ttotal: 21s\tremaining: 14.7s\n",
      "589:\tlearn: 0.1792983\ttotal: 21s\tremaining: 14.6s\n",
      "590:\tlearn: 0.1790271\ttotal: 21.1s\tremaining: 14.6s\n",
      "591:\tlearn: 0.1789293\ttotal: 21.1s\tremaining: 14.5s\n",
      "592:\tlearn: 0.1788590\ttotal: 21.1s\tremaining: 14.5s\n",
      "593:\tlearn: 0.1787507\ttotal: 21.2s\tremaining: 14.5s\n",
      "594:\tlearn: 0.1785707\ttotal: 21.2s\tremaining: 14.4s\n",
      "595:\tlearn: 0.1785358\ttotal: 21.2s\tremaining: 14.4s\n",
      "596:\tlearn: 0.1784764\ttotal: 21.3s\tremaining: 14.4s\n",
      "597:\tlearn: 0.1784255\ttotal: 21.3s\tremaining: 14.3s\n",
      "598:\tlearn: 0.1783088\ttotal: 21.4s\tremaining: 14.3s\n",
      "599:\tlearn: 0.1782238\ttotal: 21.4s\tremaining: 14.3s\n",
      "600:\tlearn: 0.1780362\ttotal: 21.4s\tremaining: 14.2s\n",
      "601:\tlearn: 0.1778762\ttotal: 21.4s\tremaining: 14.2s\n",
      "602:\tlearn: 0.1777339\ttotal: 21.5s\tremaining: 14.1s\n",
      "603:\tlearn: 0.1774852\ttotal: 21.5s\tremaining: 14.1s\n",
      "604:\tlearn: 0.1774006\ttotal: 21.6s\tremaining: 14.1s\n",
      "605:\tlearn: 0.1772623\ttotal: 21.6s\tremaining: 14s\n",
      "606:\tlearn: 0.1771184\ttotal: 21.6s\tremaining: 14s\n",
      "607:\tlearn: 0.1770009\ttotal: 21.7s\tremaining: 14s\n",
      "608:\tlearn: 0.1768449\ttotal: 21.7s\tremaining: 13.9s\n",
      "609:\tlearn: 0.1766186\ttotal: 21.8s\tremaining: 13.9s\n",
      "610:\tlearn: 0.1764143\ttotal: 21.8s\tremaining: 13.9s\n",
      "611:\tlearn: 0.1763303\ttotal: 21.8s\tremaining: 13.8s\n",
      "612:\tlearn: 0.1761427\ttotal: 21.9s\tremaining: 13.8s\n",
      "613:\tlearn: 0.1760891\ttotal: 21.9s\tremaining: 13.8s\n",
      "614:\tlearn: 0.1759833\ttotal: 21.9s\tremaining: 13.7s\n",
      "615:\tlearn: 0.1757850\ttotal: 22s\tremaining: 13.7s\n",
      "616:\tlearn: 0.1756028\ttotal: 22s\tremaining: 13.7s\n",
      "617:\tlearn: 0.1755382\ttotal: 22.1s\tremaining: 13.6s\n",
      "618:\tlearn: 0.1754366\ttotal: 22.1s\tremaining: 13.6s\n",
      "619:\tlearn: 0.1753920\ttotal: 22.1s\tremaining: 13.6s\n",
      "620:\tlearn: 0.1753073\ttotal: 22.2s\tremaining: 13.5s\n",
      "621:\tlearn: 0.1752298\ttotal: 22.2s\tremaining: 13.5s\n",
      "622:\tlearn: 0.1751044\ttotal: 22.2s\tremaining: 13.4s\n",
      "623:\tlearn: 0.1749531\ttotal: 22.3s\tremaining: 13.4s\n",
      "624:\tlearn: 0.1747763\ttotal: 22.3s\tremaining: 13.4s\n",
      "625:\tlearn: 0.1747120\ttotal: 22.3s\tremaining: 13.3s\n",
      "626:\tlearn: 0.1745123\ttotal: 22.4s\tremaining: 13.3s\n",
      "627:\tlearn: 0.1743542\ttotal: 22.4s\tremaining: 13.3s\n",
      "628:\tlearn: 0.1741219\ttotal: 22.4s\tremaining: 13.2s\n",
      "629:\tlearn: 0.1739919\ttotal: 22.5s\tremaining: 13.2s\n",
      "630:\tlearn: 0.1739239\ttotal: 22.5s\tremaining: 13.2s\n",
      "631:\tlearn: 0.1737920\ttotal: 22.5s\tremaining: 13.1s\n",
      "632:\tlearn: 0.1737646\ttotal: 22.6s\tremaining: 13.1s\n",
      "633:\tlearn: 0.1735497\ttotal: 22.6s\tremaining: 13.1s\n",
      "634:\tlearn: 0.1735045\ttotal: 22.6s\tremaining: 13s\n",
      "635:\tlearn: 0.1734084\ttotal: 22.7s\tremaining: 13s\n",
      "636:\tlearn: 0.1732815\ttotal: 22.7s\tremaining: 12.9s\n",
      "637:\tlearn: 0.1731314\ttotal: 22.8s\tremaining: 12.9s\n",
      "638:\tlearn: 0.1730443\ttotal: 22.8s\tremaining: 12.9s\n",
      "639:\tlearn: 0.1728475\ttotal: 22.8s\tremaining: 12.8s\n",
      "640:\tlearn: 0.1727308\ttotal: 22.9s\tremaining: 12.8s\n",
      "641:\tlearn: 0.1725741\ttotal: 22.9s\tremaining: 12.8s\n",
      "642:\tlearn: 0.1724266\ttotal: 22.9s\tremaining: 12.7s\n",
      "643:\tlearn: 0.1723824\ttotal: 23s\tremaining: 12.7s\n",
      "644:\tlearn: 0.1722529\ttotal: 23s\tremaining: 12.7s\n",
      "645:\tlearn: 0.1720281\ttotal: 23s\tremaining: 12.6s\n",
      "646:\tlearn: 0.1718823\ttotal: 23.1s\tremaining: 12.6s\n",
      "647:\tlearn: 0.1717754\ttotal: 23.1s\tremaining: 12.6s\n",
      "648:\tlearn: 0.1716614\ttotal: 23.1s\tremaining: 12.5s\n",
      "649:\tlearn: 0.1715334\ttotal: 23.2s\tremaining: 12.5s\n",
      "650:\tlearn: 0.1714491\ttotal: 23.2s\tremaining: 12.4s\n",
      "651:\tlearn: 0.1713153\ttotal: 23.2s\tremaining: 12.4s\n",
      "652:\tlearn: 0.1711289\ttotal: 23.3s\tremaining: 12.4s\n",
      "653:\tlearn: 0.1710142\ttotal: 23.3s\tremaining: 12.3s\n",
      "654:\tlearn: 0.1709576\ttotal: 23.4s\tremaining: 12.3s\n",
      "655:\tlearn: 0.1708678\ttotal: 23.4s\tremaining: 12.3s\n",
      "656:\tlearn: 0.1707022\ttotal: 23.4s\tremaining: 12.2s\n",
      "657:\tlearn: 0.1705731\ttotal: 23.5s\tremaining: 12.2s\n",
      "658:\tlearn: 0.1703388\ttotal: 23.5s\tremaining: 12.2s\n",
      "659:\tlearn: 0.1701875\ttotal: 23.6s\tremaining: 12.1s\n",
      "660:\tlearn: 0.1700261\ttotal: 23.6s\tremaining: 12.1s\n",
      "661:\tlearn: 0.1699882\ttotal: 23.6s\tremaining: 12.1s\n",
      "662:\tlearn: 0.1697987\ttotal: 23.7s\tremaining: 12s\n",
      "663:\tlearn: 0.1697565\ttotal: 23.7s\tremaining: 12s\n",
      "664:\tlearn: 0.1696300\ttotal: 23.7s\tremaining: 12s\n",
      "665:\tlearn: 0.1695511\ttotal: 23.8s\tremaining: 11.9s\n",
      "666:\tlearn: 0.1693352\ttotal: 23.8s\tremaining: 11.9s\n",
      "667:\tlearn: 0.1692859\ttotal: 23.8s\tremaining: 11.9s\n",
      "668:\tlearn: 0.1690836\ttotal: 23.9s\tremaining: 11.8s\n",
      "669:\tlearn: 0.1689227\ttotal: 23.9s\tremaining: 11.8s\n",
      "670:\tlearn: 0.1688216\ttotal: 23.9s\tremaining: 11.7s\n",
      "671:\tlearn: 0.1687608\ttotal: 24s\tremaining: 11.7s\n",
      "672:\tlearn: 0.1686646\ttotal: 24s\tremaining: 11.7s\n",
      "673:\tlearn: 0.1685760\ttotal: 24.1s\tremaining: 11.6s\n",
      "674:\tlearn: 0.1684422\ttotal: 24.1s\tremaining: 11.6s\n",
      "675:\tlearn: 0.1683182\ttotal: 24.1s\tremaining: 11.6s\n",
      "676:\tlearn: 0.1682546\ttotal: 24.2s\tremaining: 11.5s\n",
      "677:\tlearn: 0.1682066\ttotal: 24.2s\tremaining: 11.5s\n",
      "678:\tlearn: 0.1680151\ttotal: 24.2s\tremaining: 11.5s\n",
      "679:\tlearn: 0.1678914\ttotal: 24.3s\tremaining: 11.4s\n",
      "680:\tlearn: 0.1677219\ttotal: 24.3s\tremaining: 11.4s\n",
      "681:\tlearn: 0.1675920\ttotal: 24.4s\tremaining: 11.4s\n",
      "682:\tlearn: 0.1675383\ttotal: 24.4s\tremaining: 11.3s\n",
      "683:\tlearn: 0.1673478\ttotal: 24.4s\tremaining: 11.3s\n",
      "684:\tlearn: 0.1672863\ttotal: 24.5s\tremaining: 11.2s\n",
      "685:\tlearn: 0.1670799\ttotal: 24.5s\tremaining: 11.2s\n",
      "686:\tlearn: 0.1668963\ttotal: 24.5s\tremaining: 11.2s\n",
      "687:\tlearn: 0.1667792\ttotal: 24.6s\tremaining: 11.1s\n",
      "688:\tlearn: 0.1667270\ttotal: 24.6s\tremaining: 11.1s\n",
      "689:\tlearn: 0.1666866\ttotal: 24.7s\tremaining: 11.1s\n",
      "690:\tlearn: 0.1666034\ttotal: 24.7s\tremaining: 11s\n",
      "691:\tlearn: 0.1664388\ttotal: 24.7s\tremaining: 11s\n",
      "692:\tlearn: 0.1663802\ttotal: 24.8s\tremaining: 11s\n",
      "693:\tlearn: 0.1663134\ttotal: 24.8s\tremaining: 10.9s\n",
      "694:\tlearn: 0.1661273\ttotal: 24.8s\tremaining: 10.9s\n",
      "695:\tlearn: 0.1660348\ttotal: 24.9s\tremaining: 10.9s\n",
      "696:\tlearn: 0.1659185\ttotal: 24.9s\tremaining: 10.8s\n",
      "697:\tlearn: 0.1656617\ttotal: 24.9s\tremaining: 10.8s\n",
      "698:\tlearn: 0.1655721\ttotal: 25s\tremaining: 10.8s\n",
      "699:\tlearn: 0.1654881\ttotal: 25s\tremaining: 10.7s\n",
      "700:\tlearn: 0.1654141\ttotal: 25.1s\tremaining: 10.7s\n",
      "701:\tlearn: 0.1652864\ttotal: 25.1s\tremaining: 10.7s\n",
      "702:\tlearn: 0.1651554\ttotal: 25.1s\tremaining: 10.6s\n",
      "703:\tlearn: 0.1650594\ttotal: 25.2s\tremaining: 10.6s\n",
      "704:\tlearn: 0.1648873\ttotal: 25.2s\tremaining: 10.5s\n",
      "705:\tlearn: 0.1647994\ttotal: 25.2s\tremaining: 10.5s\n",
      "706:\tlearn: 0.1647349\ttotal: 25.3s\tremaining: 10.5s\n",
      "707:\tlearn: 0.1646590\ttotal: 25.3s\tremaining: 10.4s\n",
      "708:\tlearn: 0.1646000\ttotal: 25.3s\tremaining: 10.4s\n",
      "709:\tlearn: 0.1643950\ttotal: 25.4s\tremaining: 10.4s\n",
      "710:\tlearn: 0.1642695\ttotal: 25.4s\tremaining: 10.3s\n",
      "711:\tlearn: 0.1641417\ttotal: 25.4s\tremaining: 10.3s\n",
      "712:\tlearn: 0.1639750\ttotal: 25.5s\tremaining: 10.3s\n",
      "713:\tlearn: 0.1639351\ttotal: 25.5s\tremaining: 10.2s\n",
      "714:\tlearn: 0.1638172\ttotal: 25.5s\tremaining: 10.2s\n",
      "715:\tlearn: 0.1636922\ttotal: 25.6s\tremaining: 10.1s\n",
      "716:\tlearn: 0.1635381\ttotal: 25.6s\tremaining: 10.1s\n",
      "717:\tlearn: 0.1634028\ttotal: 25.7s\tremaining: 10.1s\n",
      "718:\tlearn: 0.1633326\ttotal: 25.7s\tremaining: 10s\n",
      "719:\tlearn: 0.1632172\ttotal: 25.7s\tremaining: 10s\n",
      "720:\tlearn: 0.1629772\ttotal: 25.8s\tremaining: 9.97s\n",
      "721:\tlearn: 0.1628834\ttotal: 25.8s\tremaining: 9.93s\n",
      "722:\tlearn: 0.1627598\ttotal: 25.8s\tremaining: 9.9s\n",
      "723:\tlearn: 0.1626473\ttotal: 25.9s\tremaining: 9.86s\n",
      "724:\tlearn: 0.1624810\ttotal: 25.9s\tremaining: 9.82s\n",
      "725:\tlearn: 0.1623399\ttotal: 25.9s\tremaining: 9.79s\n",
      "726:\tlearn: 0.1622393\ttotal: 26s\tremaining: 9.75s\n",
      "727:\tlearn: 0.1621912\ttotal: 26s\tremaining: 9.72s\n",
      "728:\tlearn: 0.1621218\ttotal: 26s\tremaining: 9.68s\n",
      "729:\tlearn: 0.1620493\ttotal: 26.1s\tremaining: 9.64s\n",
      "730:\tlearn: 0.1619735\ttotal: 26.1s\tremaining: 9.61s\n",
      "731:\tlearn: 0.1618399\ttotal: 26.1s\tremaining: 9.57s\n",
      "732:\tlearn: 0.1617413\ttotal: 26.2s\tremaining: 9.54s\n",
      "733:\tlearn: 0.1615806\ttotal: 26.2s\tremaining: 9.5s\n",
      "734:\tlearn: 0.1614700\ttotal: 26.2s\tremaining: 9.46s\n",
      "735:\tlearn: 0.1613142\ttotal: 26.3s\tremaining: 9.43s\n",
      "736:\tlearn: 0.1612086\ttotal: 26.3s\tremaining: 9.39s\n",
      "737:\tlearn: 0.1611098\ttotal: 26.4s\tremaining: 9.36s\n",
      "738:\tlearn: 0.1608754\ttotal: 26.4s\tremaining: 9.32s\n",
      "739:\tlearn: 0.1607659\ttotal: 26.4s\tremaining: 9.29s\n",
      "740:\tlearn: 0.1607176\ttotal: 26.5s\tremaining: 9.25s\n",
      "741:\tlearn: 0.1606868\ttotal: 26.5s\tremaining: 9.21s\n",
      "742:\tlearn: 0.1605760\ttotal: 26.5s\tremaining: 9.18s\n",
      "743:\tlearn: 0.1604745\ttotal: 26.6s\tremaining: 9.14s\n",
      "744:\tlearn: 0.1603091\ttotal: 26.6s\tremaining: 9.1s\n",
      "745:\tlearn: 0.1601535\ttotal: 26.6s\tremaining: 9.07s\n",
      "746:\tlearn: 0.1600552\ttotal: 26.7s\tremaining: 9.03s\n",
      "747:\tlearn: 0.1599138\ttotal: 26.7s\tremaining: 9s\n",
      "748:\tlearn: 0.1597785\ttotal: 26.7s\tremaining: 8.96s\n",
      "749:\tlearn: 0.1595657\ttotal: 26.8s\tremaining: 8.93s\n",
      "750:\tlearn: 0.1595049\ttotal: 26.8s\tremaining: 8.89s\n",
      "751:\tlearn: 0.1593771\ttotal: 26.8s\tremaining: 8.85s\n",
      "752:\tlearn: 0.1592760\ttotal: 26.9s\tremaining: 8.82s\n",
      "753:\tlearn: 0.1592128\ttotal: 26.9s\tremaining: 8.78s\n",
      "754:\tlearn: 0.1590124\ttotal: 26.9s\tremaining: 8.74s\n",
      "755:\tlearn: 0.1588935\ttotal: 27s\tremaining: 8.71s\n",
      "756:\tlearn: 0.1587597\ttotal: 27s\tremaining: 8.67s\n",
      "757:\tlearn: 0.1586464\ttotal: 27.1s\tremaining: 8.64s\n",
      "758:\tlearn: 0.1585657\ttotal: 27.1s\tremaining: 8.61s\n",
      "759:\tlearn: 0.1584140\ttotal: 27.1s\tremaining: 8.57s\n",
      "760:\tlearn: 0.1582946\ttotal: 27.2s\tremaining: 8.53s\n",
      "761:\tlearn: 0.1582307\ttotal: 27.2s\tremaining: 8.5s\n",
      "762:\tlearn: 0.1580828\ttotal: 27.2s\tremaining: 8.46s\n",
      "763:\tlearn: 0.1579435\ttotal: 27.3s\tremaining: 8.42s\n",
      "764:\tlearn: 0.1579076\ttotal: 27.3s\tremaining: 8.39s\n",
      "765:\tlearn: 0.1578497\ttotal: 27.3s\tremaining: 8.35s\n",
      "766:\tlearn: 0.1577635\ttotal: 27.4s\tremaining: 8.32s\n",
      "767:\tlearn: 0.1576599\ttotal: 27.4s\tremaining: 8.28s\n",
      "768:\tlearn: 0.1575996\ttotal: 27.4s\tremaining: 8.24s\n",
      "769:\tlearn: 0.1575276\ttotal: 27.5s\tremaining: 8.21s\n",
      "770:\tlearn: 0.1574527\ttotal: 27.5s\tremaining: 8.17s\n",
      "771:\tlearn: 0.1574038\ttotal: 27.6s\tremaining: 8.14s\n",
      "772:\tlearn: 0.1571555\ttotal: 27.6s\tremaining: 8.1s\n",
      "773:\tlearn: 0.1570310\ttotal: 27.6s\tremaining: 8.06s\n",
      "774:\tlearn: 0.1569751\ttotal: 27.7s\tremaining: 8.03s\n",
      "775:\tlearn: 0.1567314\ttotal: 27.7s\tremaining: 7.99s\n",
      "776:\tlearn: 0.1566436\ttotal: 27.7s\tremaining: 7.96s\n",
      "777:\tlearn: 0.1565055\ttotal: 27.8s\tremaining: 7.93s\n",
      "778:\tlearn: 0.1563650\ttotal: 27.8s\tremaining: 7.89s\n",
      "779:\tlearn: 0.1562914\ttotal: 27.9s\tremaining: 7.86s\n",
      "780:\tlearn: 0.1561795\ttotal: 27.9s\tremaining: 7.82s\n",
      "781:\tlearn: 0.1560647\ttotal: 27.9s\tremaining: 7.79s\n",
      "782:\tlearn: 0.1559134\ttotal: 28s\tremaining: 7.75s\n",
      "783:\tlearn: 0.1557468\ttotal: 28s\tremaining: 7.71s\n",
      "784:\tlearn: 0.1555630\ttotal: 28s\tremaining: 7.68s\n",
      "785:\tlearn: 0.1555278\ttotal: 28.1s\tremaining: 7.64s\n",
      "786:\tlearn: 0.1554524\ttotal: 28.1s\tremaining: 7.61s\n",
      "787:\tlearn: 0.1553401\ttotal: 28.1s\tremaining: 7.57s\n",
      "788:\tlearn: 0.1552845\ttotal: 28.2s\tremaining: 7.54s\n",
      "789:\tlearn: 0.1551597\ttotal: 28.2s\tremaining: 7.5s\n",
      "790:\tlearn: 0.1550966\ttotal: 28.3s\tremaining: 7.47s\n",
      "791:\tlearn: 0.1550632\ttotal: 28.3s\tremaining: 7.43s\n",
      "792:\tlearn: 0.1548886\ttotal: 28.3s\tremaining: 7.4s\n",
      "793:\tlearn: 0.1547845\ttotal: 28.4s\tremaining: 7.36s\n",
      "794:\tlearn: 0.1546223\ttotal: 28.4s\tremaining: 7.33s\n",
      "795:\tlearn: 0.1545665\ttotal: 28.4s\tremaining: 7.29s\n",
      "796:\tlearn: 0.1544927\ttotal: 28.5s\tremaining: 7.25s\n",
      "797:\tlearn: 0.1543998\ttotal: 28.5s\tremaining: 7.22s\n",
      "798:\tlearn: 0.1543568\ttotal: 28.6s\tremaining: 7.18s\n",
      "799:\tlearn: 0.1542848\ttotal: 28.6s\tremaining: 7.15s\n",
      "800:\tlearn: 0.1541030\ttotal: 28.6s\tremaining: 7.12s\n",
      "801:\tlearn: 0.1539747\ttotal: 28.7s\tremaining: 7.08s\n",
      "802:\tlearn: 0.1538661\ttotal: 28.7s\tremaining: 7.05s\n",
      "803:\tlearn: 0.1537659\ttotal: 28.8s\tremaining: 7.01s\n",
      "804:\tlearn: 0.1536325\ttotal: 28.8s\tremaining: 6.97s\n",
      "805:\tlearn: 0.1535304\ttotal: 28.8s\tremaining: 6.94s\n",
      "806:\tlearn: 0.1533525\ttotal: 28.9s\tremaining: 6.9s\n",
      "807:\tlearn: 0.1532586\ttotal: 28.9s\tremaining: 6.87s\n",
      "808:\tlearn: 0.1531332\ttotal: 28.9s\tremaining: 6.83s\n",
      "809:\tlearn: 0.1529688\ttotal: 29s\tremaining: 6.79s\n",
      "810:\tlearn: 0.1529496\ttotal: 29s\tremaining: 6.76s\n",
      "811:\tlearn: 0.1528145\ttotal: 29.1s\tremaining: 6.73s\n",
      "812:\tlearn: 0.1527888\ttotal: 29.1s\tremaining: 6.69s\n",
      "813:\tlearn: 0.1527606\ttotal: 29.1s\tremaining: 6.65s\n",
      "814:\tlearn: 0.1526523\ttotal: 29.2s\tremaining: 6.62s\n",
      "815:\tlearn: 0.1525500\ttotal: 29.2s\tremaining: 6.58s\n",
      "816:\tlearn: 0.1524523\ttotal: 29.2s\tremaining: 6.54s\n",
      "817:\tlearn: 0.1523665\ttotal: 29.3s\tremaining: 6.51s\n",
      "818:\tlearn: 0.1522723\ttotal: 29.3s\tremaining: 6.47s\n",
      "819:\tlearn: 0.1521628\ttotal: 29.3s\tremaining: 6.44s\n",
      "820:\tlearn: 0.1521191\ttotal: 29.4s\tremaining: 6.4s\n",
      "821:\tlearn: 0.1520534\ttotal: 29.4s\tremaining: 6.37s\n",
      "822:\tlearn: 0.1520101\ttotal: 29.4s\tremaining: 6.33s\n",
      "823:\tlearn: 0.1519173\ttotal: 29.5s\tremaining: 6.3s\n",
      "824:\tlearn: 0.1518100\ttotal: 29.5s\tremaining: 6.26s\n",
      "825:\tlearn: 0.1517432\ttotal: 29.5s\tremaining: 6.22s\n",
      "826:\tlearn: 0.1516161\ttotal: 29.6s\tremaining: 6.19s\n",
      "827:\tlearn: 0.1515092\ttotal: 29.6s\tremaining: 6.15s\n",
      "828:\tlearn: 0.1514769\ttotal: 29.6s\tremaining: 6.12s\n",
      "829:\tlearn: 0.1513636\ttotal: 29.7s\tremaining: 6.08s\n",
      "830:\tlearn: 0.1512680\ttotal: 29.7s\tremaining: 6.05s\n",
      "831:\tlearn: 0.1511586\ttotal: 29.8s\tremaining: 6.01s\n",
      "832:\tlearn: 0.1510590\ttotal: 29.8s\tremaining: 5.97s\n",
      "833:\tlearn: 0.1509957\ttotal: 29.8s\tremaining: 5.94s\n",
      "834:\tlearn: 0.1509273\ttotal: 29.9s\tremaining: 5.9s\n",
      "835:\tlearn: 0.1509002\ttotal: 29.9s\tremaining: 5.86s\n",
      "836:\tlearn: 0.1508046\ttotal: 29.9s\tremaining: 5.83s\n",
      "837:\tlearn: 0.1507752\ttotal: 30s\tremaining: 5.79s\n",
      "838:\tlearn: 0.1505818\ttotal: 30s\tremaining: 5.76s\n",
      "839:\tlearn: 0.1505341\ttotal: 30s\tremaining: 5.72s\n",
      "840:\tlearn: 0.1504897\ttotal: 30.1s\tremaining: 5.68s\n",
      "841:\tlearn: 0.1504344\ttotal: 30.1s\tremaining: 5.65s\n",
      "842:\tlearn: 0.1503385\ttotal: 30.1s\tremaining: 5.61s\n",
      "843:\tlearn: 0.1502496\ttotal: 30.2s\tremaining: 5.58s\n",
      "844:\tlearn: 0.1501637\ttotal: 30.2s\tremaining: 5.54s\n",
      "845:\tlearn: 0.1500808\ttotal: 30.2s\tremaining: 5.5s\n",
      "846:\tlearn: 0.1500561\ttotal: 30.3s\tremaining: 5.47s\n",
      "847:\tlearn: 0.1499436\ttotal: 30.3s\tremaining: 5.43s\n",
      "848:\tlearn: 0.1497686\ttotal: 30.3s\tremaining: 5.4s\n",
      "849:\tlearn: 0.1496887\ttotal: 30.4s\tremaining: 5.36s\n",
      "850:\tlearn: 0.1495682\ttotal: 30.4s\tremaining: 5.33s\n",
      "851:\tlearn: 0.1495166\ttotal: 30.5s\tremaining: 5.29s\n",
      "852:\tlearn: 0.1493486\ttotal: 30.5s\tremaining: 5.25s\n",
      "853:\tlearn: 0.1491827\ttotal: 30.5s\tremaining: 5.22s\n",
      "854:\tlearn: 0.1490916\ttotal: 30.6s\tremaining: 5.18s\n",
      "855:\tlearn: 0.1490256\ttotal: 30.6s\tremaining: 5.15s\n",
      "856:\tlearn: 0.1489125\ttotal: 30.6s\tremaining: 5.11s\n",
      "857:\tlearn: 0.1487962\ttotal: 30.7s\tremaining: 5.08s\n",
      "858:\tlearn: 0.1486246\ttotal: 30.7s\tremaining: 5.04s\n",
      "859:\tlearn: 0.1485227\ttotal: 30.7s\tremaining: 5s\n",
      "860:\tlearn: 0.1484591\ttotal: 30.8s\tremaining: 4.97s\n",
      "861:\tlearn: 0.1483883\ttotal: 30.8s\tremaining: 4.93s\n",
      "862:\tlearn: 0.1483229\ttotal: 30.9s\tremaining: 4.9s\n",
      "863:\tlearn: 0.1481574\ttotal: 30.9s\tremaining: 4.86s\n",
      "864:\tlearn: 0.1480867\ttotal: 30.9s\tremaining: 4.83s\n",
      "865:\tlearn: 0.1480517\ttotal: 30.9s\tremaining: 4.79s\n",
      "866:\tlearn: 0.1479965\ttotal: 31s\tremaining: 4.75s\n",
      "867:\tlearn: 0.1479273\ttotal: 31s\tremaining: 4.72s\n",
      "868:\tlearn: 0.1478759\ttotal: 31.1s\tremaining: 4.68s\n",
      "869:\tlearn: 0.1478408\ttotal: 31.1s\tremaining: 4.65s\n",
      "870:\tlearn: 0.1477891\ttotal: 31.1s\tremaining: 4.61s\n",
      "871:\tlearn: 0.1476756\ttotal: 31.2s\tremaining: 4.58s\n",
      "872:\tlearn: 0.1475985\ttotal: 31.2s\tremaining: 4.54s\n",
      "873:\tlearn: 0.1475612\ttotal: 31.2s\tremaining: 4.5s\n",
      "874:\tlearn: 0.1475032\ttotal: 31.3s\tremaining: 4.47s\n",
      "875:\tlearn: 0.1474354\ttotal: 31.3s\tremaining: 4.43s\n",
      "876:\tlearn: 0.1473389\ttotal: 31.3s\tremaining: 4.39s\n",
      "877:\tlearn: 0.1471565\ttotal: 31.4s\tremaining: 4.36s\n",
      "878:\tlearn: 0.1470796\ttotal: 31.4s\tremaining: 4.32s\n",
      "879:\tlearn: 0.1470211\ttotal: 31.4s\tremaining: 4.29s\n",
      "880:\tlearn: 0.1469057\ttotal: 31.5s\tremaining: 4.25s\n",
      "881:\tlearn: 0.1467462\ttotal: 31.5s\tremaining: 4.22s\n",
      "882:\tlearn: 0.1466950\ttotal: 31.6s\tremaining: 4.18s\n",
      "883:\tlearn: 0.1465141\ttotal: 31.6s\tremaining: 4.14s\n",
      "884:\tlearn: 0.1463879\ttotal: 31.6s\tremaining: 4.11s\n",
      "885:\tlearn: 0.1462916\ttotal: 31.7s\tremaining: 4.07s\n",
      "886:\tlearn: 0.1462028\ttotal: 31.7s\tremaining: 4.04s\n",
      "887:\tlearn: 0.1461199\ttotal: 31.7s\tremaining: 4s\n",
      "888:\tlearn: 0.1460657\ttotal: 31.8s\tremaining: 3.97s\n",
      "889:\tlearn: 0.1460015\ttotal: 31.8s\tremaining: 3.93s\n",
      "890:\tlearn: 0.1458637\ttotal: 31.9s\tremaining: 3.9s\n",
      "891:\tlearn: 0.1458234\ttotal: 31.9s\tremaining: 3.86s\n",
      "892:\tlearn: 0.1456871\ttotal: 31.9s\tremaining: 3.82s\n",
      "893:\tlearn: 0.1456439\ttotal: 31.9s\tremaining: 3.79s\n",
      "894:\tlearn: 0.1455396\ttotal: 32s\tremaining: 3.75s\n",
      "895:\tlearn: 0.1454035\ttotal: 32s\tremaining: 3.71s\n",
      "896:\tlearn: 0.1452813\ttotal: 32s\tremaining: 3.68s\n",
      "897:\tlearn: 0.1452457\ttotal: 32.1s\tremaining: 3.64s\n",
      "898:\tlearn: 0.1451812\ttotal: 32.1s\tremaining: 3.61s\n",
      "899:\tlearn: 0.1450040\ttotal: 32.2s\tremaining: 3.57s\n",
      "900:\tlearn: 0.1449266\ttotal: 32.2s\tremaining: 3.54s\n",
      "901:\tlearn: 0.1448549\ttotal: 32.2s\tremaining: 3.5s\n",
      "902:\tlearn: 0.1446833\ttotal: 32.3s\tremaining: 3.47s\n",
      "903:\tlearn: 0.1446246\ttotal: 32.3s\tremaining: 3.43s\n",
      "904:\tlearn: 0.1444726\ttotal: 32.3s\tremaining: 3.39s\n",
      "905:\tlearn: 0.1443933\ttotal: 32.4s\tremaining: 3.36s\n",
      "906:\tlearn: 0.1442453\ttotal: 32.4s\tremaining: 3.32s\n",
      "907:\tlearn: 0.1441511\ttotal: 32.4s\tremaining: 3.29s\n",
      "908:\tlearn: 0.1440616\ttotal: 32.5s\tremaining: 3.25s\n",
      "909:\tlearn: 0.1439236\ttotal: 32.5s\tremaining: 3.22s\n",
      "910:\tlearn: 0.1437654\ttotal: 32.6s\tremaining: 3.18s\n",
      "911:\tlearn: 0.1436440\ttotal: 32.6s\tremaining: 3.14s\n",
      "912:\tlearn: 0.1435507\ttotal: 32.6s\tremaining: 3.11s\n",
      "913:\tlearn: 0.1434465\ttotal: 32.7s\tremaining: 3.07s\n",
      "914:\tlearn: 0.1432816\ttotal: 32.7s\tremaining: 3.04s\n",
      "915:\tlearn: 0.1431611\ttotal: 32.7s\tremaining: 3s\n",
      "916:\tlearn: 0.1430735\ttotal: 32.8s\tremaining: 2.96s\n",
      "917:\tlearn: 0.1429541\ttotal: 32.8s\tremaining: 2.93s\n",
      "918:\tlearn: 0.1429254\ttotal: 32.8s\tremaining: 2.89s\n",
      "919:\tlearn: 0.1428744\ttotal: 32.9s\tremaining: 2.86s\n",
      "920:\tlearn: 0.1427152\ttotal: 32.9s\tremaining: 2.82s\n",
      "921:\tlearn: 0.1426746\ttotal: 32.9s\tremaining: 2.79s\n",
      "922:\tlearn: 0.1425644\ttotal: 33s\tremaining: 2.75s\n",
      "923:\tlearn: 0.1425268\ttotal: 33s\tremaining: 2.71s\n",
      "924:\tlearn: 0.1424700\ttotal: 33s\tremaining: 2.68s\n",
      "925:\tlearn: 0.1424263\ttotal: 33.1s\tremaining: 2.64s\n",
      "926:\tlearn: 0.1423874\ttotal: 33.1s\tremaining: 2.61s\n",
      "927:\tlearn: 0.1422371\ttotal: 33.2s\tremaining: 2.57s\n",
      "928:\tlearn: 0.1420836\ttotal: 33.2s\tremaining: 2.54s\n",
      "929:\tlearn: 0.1420029\ttotal: 33.2s\tremaining: 2.5s\n",
      "930:\tlearn: 0.1418971\ttotal: 33.3s\tremaining: 2.46s\n",
      "931:\tlearn: 0.1417806\ttotal: 33.3s\tremaining: 2.43s\n",
      "932:\tlearn: 0.1417034\ttotal: 33.3s\tremaining: 2.39s\n",
      "933:\tlearn: 0.1416560\ttotal: 33.4s\tremaining: 2.36s\n",
      "934:\tlearn: 0.1415327\ttotal: 33.4s\tremaining: 2.32s\n",
      "935:\tlearn: 0.1414587\ttotal: 33.4s\tremaining: 2.29s\n",
      "936:\tlearn: 0.1413224\ttotal: 33.5s\tremaining: 2.25s\n",
      "937:\tlearn: 0.1412771\ttotal: 33.5s\tremaining: 2.21s\n",
      "938:\tlearn: 0.1411814\ttotal: 33.5s\tremaining: 2.18s\n",
      "939:\tlearn: 0.1411172\ttotal: 33.6s\tremaining: 2.14s\n",
      "940:\tlearn: 0.1410735\ttotal: 33.6s\tremaining: 2.11s\n",
      "941:\tlearn: 0.1409616\ttotal: 33.7s\tremaining: 2.07s\n",
      "942:\tlearn: 0.1408663\ttotal: 33.7s\tremaining: 2.04s\n",
      "943:\tlearn: 0.1408138\ttotal: 33.7s\tremaining: 2s\n",
      "944:\tlearn: 0.1407574\ttotal: 33.8s\tremaining: 1.96s\n",
      "945:\tlearn: 0.1407069\ttotal: 33.8s\tremaining: 1.93s\n",
      "946:\tlearn: 0.1405975\ttotal: 33.8s\tremaining: 1.89s\n",
      "947:\tlearn: 0.1404547\ttotal: 33.9s\tremaining: 1.86s\n",
      "948:\tlearn: 0.1404236\ttotal: 33.9s\tremaining: 1.82s\n",
      "949:\tlearn: 0.1403578\ttotal: 33.9s\tremaining: 1.79s\n",
      "950:\tlearn: 0.1402057\ttotal: 34s\tremaining: 1.75s\n",
      "951:\tlearn: 0.1400732\ttotal: 34s\tremaining: 1.72s\n",
      "952:\tlearn: 0.1399682\ttotal: 34.1s\tremaining: 1.68s\n",
      "953:\tlearn: 0.1398304\ttotal: 34.1s\tremaining: 1.64s\n",
      "954:\tlearn: 0.1397355\ttotal: 34.1s\tremaining: 1.61s\n",
      "955:\tlearn: 0.1396174\ttotal: 34.2s\tremaining: 1.57s\n",
      "956:\tlearn: 0.1394767\ttotal: 34.2s\tremaining: 1.54s\n",
      "957:\tlearn: 0.1393912\ttotal: 34.2s\tremaining: 1.5s\n",
      "958:\tlearn: 0.1393425\ttotal: 34.3s\tremaining: 1.47s\n",
      "959:\tlearn: 0.1392672\ttotal: 34.3s\tremaining: 1.43s\n",
      "960:\tlearn: 0.1391671\ttotal: 34.3s\tremaining: 1.39s\n",
      "961:\tlearn: 0.1391263\ttotal: 34.4s\tremaining: 1.36s\n",
      "962:\tlearn: 0.1390506\ttotal: 34.4s\tremaining: 1.32s\n",
      "963:\tlearn: 0.1389952\ttotal: 34.5s\tremaining: 1.29s\n",
      "964:\tlearn: 0.1389314\ttotal: 34.5s\tremaining: 1.25s\n",
      "965:\tlearn: 0.1388780\ttotal: 34.5s\tremaining: 1.22s\n",
      "966:\tlearn: 0.1387791\ttotal: 34.6s\tremaining: 1.18s\n",
      "967:\tlearn: 0.1386961\ttotal: 34.6s\tremaining: 1.14s\n",
      "968:\tlearn: 0.1386033\ttotal: 34.7s\tremaining: 1.11s\n",
      "969:\tlearn: 0.1385495\ttotal: 34.7s\tremaining: 1.07s\n",
      "970:\tlearn: 0.1385031\ttotal: 34.7s\tremaining: 1.04s\n",
      "971:\tlearn: 0.1384053\ttotal: 34.8s\tremaining: 1s\n",
      "972:\tlearn: 0.1383353\ttotal: 34.8s\tremaining: 966ms\n",
      "973:\tlearn: 0.1382738\ttotal: 34.9s\tremaining: 930ms\n",
      "974:\tlearn: 0.1381745\ttotal: 34.9s\tremaining: 895ms\n",
      "975:\tlearn: 0.1380918\ttotal: 34.9s\tremaining: 859ms\n",
      "976:\tlearn: 0.1379782\ttotal: 35s\tremaining: 823ms\n",
      "977:\tlearn: 0.1378767\ttotal: 35s\tremaining: 787ms\n",
      "978:\tlearn: 0.1378083\ttotal: 35s\tremaining: 752ms\n",
      "979:\tlearn: 0.1377659\ttotal: 35.1s\tremaining: 716ms\n",
      "980:\tlearn: 0.1376394\ttotal: 35.1s\tremaining: 680ms\n",
      "981:\tlearn: 0.1375760\ttotal: 35.1s\tremaining: 644ms\n",
      "982:\tlearn: 0.1375138\ttotal: 35.2s\tremaining: 608ms\n",
      "983:\tlearn: 0.1374301\ttotal: 35.2s\tremaining: 573ms\n",
      "984:\tlearn: 0.1373531\ttotal: 35.3s\tremaining: 537ms\n",
      "985:\tlearn: 0.1373087\ttotal: 35.3s\tremaining: 501ms\n",
      "986:\tlearn: 0.1372008\ttotal: 35.3s\tremaining: 465ms\n",
      "987:\tlearn: 0.1371781\ttotal: 35.4s\tremaining: 429ms\n",
      "988:\tlearn: 0.1370418\ttotal: 35.4s\tremaining: 394ms\n",
      "989:\tlearn: 0.1369281\ttotal: 35.4s\tremaining: 358ms\n",
      "990:\tlearn: 0.1368398\ttotal: 35.5s\tremaining: 322ms\n",
      "991:\tlearn: 0.1367623\ttotal: 35.5s\tremaining: 286ms\n",
      "992:\tlearn: 0.1366654\ttotal: 35.5s\tremaining: 251ms\n",
      "993:\tlearn: 0.1365696\ttotal: 35.6s\tremaining: 215ms\n",
      "994:\tlearn: 0.1364824\ttotal: 35.6s\tremaining: 179ms\n",
      "995:\tlearn: 0.1362929\ttotal: 35.7s\tremaining: 143ms\n",
      "996:\tlearn: 0.1362165\ttotal: 35.7s\tremaining: 107ms\n",
      "997:\tlearn: 0.1361890\ttotal: 35.7s\tremaining: 71.6ms\n",
      "998:\tlearn: 0.1361511\ttotal: 35.8s\tremaining: 35.8ms\n",
      "999:\tlearn: 0.1360786\ttotal: 35.8s\tremaining: 0us\n",
      "Learning rate set to 0.09175\n",
      "0:\tlearn: 1.8198424\ttotal: 37.2ms\tremaining: 37.1s\n",
      "1:\tlearn: 1.6131132\ttotal: 76.8ms\tremaining: 38.3s\n",
      "2:\tlearn: 1.4551016\ttotal: 122ms\tremaining: 40.5s\n",
      "3:\tlearn: 1.3497845\ttotal: 162ms\tremaining: 40.4s\n",
      "4:\tlearn: 1.2519902\ttotal: 195ms\tremaining: 38.9s\n",
      "5:\tlearn: 1.1847374\ttotal: 229ms\tremaining: 38s\n",
      "6:\tlearn: 1.1246482\ttotal: 263ms\tremaining: 37.2s\n",
      "7:\tlearn: 1.0622224\ttotal: 297ms\tremaining: 36.8s\n",
      "8:\tlearn: 1.0071020\ttotal: 332ms\tremaining: 36.5s\n",
      "9:\tlearn: 0.9696610\ttotal: 367ms\tremaining: 36.3s\n",
      "10:\tlearn: 0.9245827\ttotal: 401ms\tremaining: 36s\n",
      "11:\tlearn: 0.8826944\ttotal: 438ms\tremaining: 36s\n",
      "12:\tlearn: 0.8476049\ttotal: 476ms\tremaining: 36.1s\n",
      "13:\tlearn: 0.8163627\ttotal: 512ms\tremaining: 36.1s\n",
      "14:\tlearn: 0.7889757\ttotal: 553ms\tremaining: 36.3s\n",
      "15:\tlearn: 0.7668503\ttotal: 598ms\tremaining: 36.7s\n",
      "16:\tlearn: 0.7417204\ttotal: 634ms\tremaining: 36.7s\n",
      "17:\tlearn: 0.7188165\ttotal: 668ms\tremaining: 36.4s\n",
      "18:\tlearn: 0.6985426\ttotal: 703ms\tremaining: 36.3s\n",
      "19:\tlearn: 0.6842655\ttotal: 736ms\tremaining: 36.1s\n",
      "20:\tlearn: 0.6654872\ttotal: 770ms\tremaining: 35.9s\n",
      "21:\tlearn: 0.6502330\ttotal: 805ms\tremaining: 35.8s\n",
      "22:\tlearn: 0.6385863\ttotal: 838ms\tremaining: 35.6s\n",
      "23:\tlearn: 0.6246206\ttotal: 891ms\tremaining: 36.2s\n",
      "24:\tlearn: 0.6121509\ttotal: 933ms\tremaining: 36.4s\n",
      "25:\tlearn: 0.6004684\ttotal: 966ms\tremaining: 36.2s\n",
      "26:\tlearn: 0.5900605\ttotal: 1s\tremaining: 36.1s\n",
      "27:\tlearn: 0.5792342\ttotal: 1.03s\tremaining: 35.8s\n",
      "28:\tlearn: 0.5672564\ttotal: 1.06s\tremaining: 35.7s\n",
      "29:\tlearn: 0.5581181\ttotal: 1.09s\tremaining: 35.4s\n",
      "30:\tlearn: 0.5505217\ttotal: 1.13s\tremaining: 35.4s\n",
      "31:\tlearn: 0.5408229\ttotal: 1.17s\tremaining: 35.3s\n",
      "32:\tlearn: 0.5323857\ttotal: 1.2s\tremaining: 35.3s\n",
      "33:\tlearn: 0.5230489\ttotal: 1.24s\tremaining: 35.3s\n",
      "34:\tlearn: 0.5187481\ttotal: 1.28s\tremaining: 35.4s\n",
      "35:\tlearn: 0.5109944\ttotal: 1.32s\tremaining: 35.4s\n",
      "36:\tlearn: 0.5044893\ttotal: 1.35s\tremaining: 35.2s\n",
      "37:\tlearn: 0.4984072\ttotal: 1.38s\tremaining: 35.1s\n",
      "38:\tlearn: 0.4923034\ttotal: 1.42s\tremaining: 35s\n",
      "39:\tlearn: 0.4854702\ttotal: 1.45s\tremaining: 34.9s\n",
      "40:\tlearn: 0.4816129\ttotal: 1.48s\tremaining: 34.7s\n",
      "41:\tlearn: 0.4763418\ttotal: 1.52s\tremaining: 34.7s\n",
      "42:\tlearn: 0.4707381\ttotal: 1.56s\tremaining: 34.8s\n",
      "43:\tlearn: 0.4688654\ttotal: 1.6s\tremaining: 34.8s\n",
      "44:\tlearn: 0.4649857\ttotal: 1.64s\tremaining: 34.8s\n",
      "45:\tlearn: 0.4597009\ttotal: 1.67s\tremaining: 34.7s\n",
      "46:\tlearn: 0.4550228\ttotal: 1.71s\tremaining: 34.6s\n",
      "47:\tlearn: 0.4511013\ttotal: 1.74s\tremaining: 34.5s\n",
      "48:\tlearn: 0.4476356\ttotal: 1.77s\tremaining: 34.4s\n",
      "49:\tlearn: 0.4411154\ttotal: 1.81s\tremaining: 34.4s\n",
      "50:\tlearn: 0.4379347\ttotal: 1.84s\tremaining: 34.2s\n",
      "51:\tlearn: 0.4363664\ttotal: 1.88s\tremaining: 34.2s\n",
      "52:\tlearn: 0.4326708\ttotal: 1.92s\tremaining: 34.2s\n",
      "53:\tlearn: 0.4302314\ttotal: 1.95s\tremaining: 34.2s\n",
      "54:\tlearn: 0.4276799\ttotal: 1.99s\tremaining: 34.2s\n",
      "55:\tlearn: 0.4248558\ttotal: 2.03s\tremaining: 34.2s\n",
      "56:\tlearn: 0.4216043\ttotal: 2.06s\tremaining: 34.1s\n",
      "57:\tlearn: 0.4190391\ttotal: 2.09s\tremaining: 34s\n",
      "58:\tlearn: 0.4158579\ttotal: 2.13s\tremaining: 33.9s\n",
      "59:\tlearn: 0.4140447\ttotal: 2.16s\tremaining: 33.8s\n",
      "60:\tlearn: 0.4116254\ttotal: 2.19s\tremaining: 33.7s\n",
      "61:\tlearn: 0.4087782\ttotal: 2.23s\tremaining: 33.7s\n",
      "62:\tlearn: 0.4050886\ttotal: 2.27s\tremaining: 33.8s\n",
      "63:\tlearn: 0.4015004\ttotal: 2.31s\tremaining: 33.8s\n",
      "64:\tlearn: 0.3994280\ttotal: 2.35s\tremaining: 33.8s\n",
      "65:\tlearn: 0.3971058\ttotal: 2.39s\tremaining: 33.8s\n",
      "66:\tlearn: 0.3945083\ttotal: 2.42s\tremaining: 33.7s\n",
      "67:\tlearn: 0.3934034\ttotal: 2.45s\tremaining: 33.6s\n",
      "68:\tlearn: 0.3919591\ttotal: 2.48s\tremaining: 33.5s\n",
      "69:\tlearn: 0.3896992\ttotal: 2.52s\tremaining: 33.4s\n",
      "70:\tlearn: 0.3875861\ttotal: 2.55s\tremaining: 33.4s\n",
      "71:\tlearn: 0.3857968\ttotal: 2.58s\tremaining: 33.3s\n",
      "72:\tlearn: 0.3830135\ttotal: 2.62s\tremaining: 33.3s\n",
      "73:\tlearn: 0.3805979\ttotal: 2.66s\tremaining: 33.3s\n",
      "74:\tlearn: 0.3787208\ttotal: 2.7s\tremaining: 33.3s\n",
      "75:\tlearn: 0.3780874\ttotal: 2.74s\tremaining: 33.3s\n",
      "76:\tlearn: 0.3769034\ttotal: 2.77s\tremaining: 33.2s\n",
      "77:\tlearn: 0.3743429\ttotal: 2.8s\tremaining: 33.1s\n",
      "78:\tlearn: 0.3731482\ttotal: 2.84s\tremaining: 33.1s\n",
      "79:\tlearn: 0.3712110\ttotal: 2.87s\tremaining: 33s\n",
      "80:\tlearn: 0.3703069\ttotal: 2.9s\tremaining: 33s\n",
      "81:\tlearn: 0.3689389\ttotal: 2.94s\tremaining: 32.9s\n",
      "82:\tlearn: 0.3673852\ttotal: 2.99s\tremaining: 33s\n",
      "83:\tlearn: 0.3662664\ttotal: 3.03s\tremaining: 33s\n",
      "84:\tlearn: 0.3640159\ttotal: 3.06s\tremaining: 33s\n",
      "85:\tlearn: 0.3625636\ttotal: 3.1s\tremaining: 32.9s\n",
      "86:\tlearn: 0.3616300\ttotal: 3.13s\tremaining: 32.8s\n",
      "87:\tlearn: 0.3598064\ttotal: 3.17s\tremaining: 32.9s\n",
      "88:\tlearn: 0.3583174\ttotal: 3.21s\tremaining: 32.9s\n",
      "89:\tlearn: 0.3573774\ttotal: 3.24s\tremaining: 32.8s\n",
      "90:\tlearn: 0.3550617\ttotal: 3.28s\tremaining: 32.7s\n",
      "91:\tlearn: 0.3535309\ttotal: 3.31s\tremaining: 32.7s\n",
      "92:\tlearn: 0.3514614\ttotal: 3.34s\tremaining: 32.6s\n",
      "93:\tlearn: 0.3501446\ttotal: 3.38s\tremaining: 32.6s\n",
      "94:\tlearn: 0.3486559\ttotal: 3.42s\tremaining: 32.6s\n",
      "95:\tlearn: 0.3473425\ttotal: 3.47s\tremaining: 32.7s\n",
      "96:\tlearn: 0.3462698\ttotal: 3.51s\tremaining: 32.7s\n",
      "97:\tlearn: 0.3444640\ttotal: 3.55s\tremaining: 32.7s\n",
      "98:\tlearn: 0.3427450\ttotal: 3.59s\tremaining: 32.7s\n",
      "99:\tlearn: 0.3411160\ttotal: 3.63s\tremaining: 32.7s\n",
      "100:\tlearn: 0.3401031\ttotal: 3.67s\tremaining: 32.6s\n",
      "101:\tlearn: 0.3390224\ttotal: 3.7s\tremaining: 32.6s\n",
      "102:\tlearn: 0.3376294\ttotal: 3.74s\tremaining: 32.5s\n",
      "103:\tlearn: 0.3366156\ttotal: 3.77s\tremaining: 32.5s\n",
      "104:\tlearn: 0.3354538\ttotal: 3.81s\tremaining: 32.4s\n",
      "105:\tlearn: 0.3338096\ttotal: 3.84s\tremaining: 32.4s\n",
      "106:\tlearn: 0.3332020\ttotal: 3.88s\tremaining: 32.4s\n",
      "107:\tlearn: 0.3328037\ttotal: 3.92s\tremaining: 32.4s\n",
      "108:\tlearn: 0.3316835\ttotal: 3.96s\tremaining: 32.4s\n",
      "109:\tlearn: 0.3310680\ttotal: 4s\tremaining: 32.4s\n",
      "110:\tlearn: 0.3301316\ttotal: 4.03s\tremaining: 32.3s\n",
      "111:\tlearn: 0.3294333\ttotal: 4.07s\tremaining: 32.2s\n",
      "112:\tlearn: 0.3284790\ttotal: 4.11s\tremaining: 32.2s\n",
      "113:\tlearn: 0.3275979\ttotal: 4.14s\tremaining: 32.2s\n",
      "114:\tlearn: 0.3267456\ttotal: 4.17s\tremaining: 32.1s\n",
      "115:\tlearn: 0.3255391\ttotal: 4.21s\tremaining: 32s\n",
      "116:\tlearn: 0.3248882\ttotal: 4.24s\tremaining: 32s\n",
      "117:\tlearn: 0.3243009\ttotal: 4.27s\tremaining: 31.9s\n",
      "118:\tlearn: 0.3235698\ttotal: 4.3s\tremaining: 31.9s\n",
      "119:\tlearn: 0.3225128\ttotal: 4.35s\tremaining: 31.9s\n",
      "120:\tlearn: 0.3222525\ttotal: 4.38s\tremaining: 31.8s\n",
      "121:\tlearn: 0.3211955\ttotal: 4.43s\tremaining: 31.9s\n",
      "122:\tlearn: 0.3205251\ttotal: 4.46s\tremaining: 31.8s\n",
      "123:\tlearn: 0.3195387\ttotal: 4.49s\tremaining: 31.7s\n",
      "124:\tlearn: 0.3189899\ttotal: 4.52s\tremaining: 31.7s\n",
      "125:\tlearn: 0.3176124\ttotal: 4.55s\tremaining: 31.6s\n",
      "126:\tlearn: 0.3170662\ttotal: 4.59s\tremaining: 31.5s\n",
      "127:\tlearn: 0.3167359\ttotal: 4.62s\tremaining: 31.5s\n",
      "128:\tlearn: 0.3162100\ttotal: 4.65s\tremaining: 31.4s\n",
      "129:\tlearn: 0.3150443\ttotal: 4.7s\tremaining: 31.4s\n",
      "130:\tlearn: 0.3145810\ttotal: 4.73s\tremaining: 31.4s\n",
      "131:\tlearn: 0.3142965\ttotal: 4.77s\tremaining: 31.3s\n",
      "132:\tlearn: 0.3140353\ttotal: 4.8s\tremaining: 31.3s\n",
      "133:\tlearn: 0.3127434\ttotal: 4.83s\tremaining: 31.2s\n",
      "134:\tlearn: 0.3118957\ttotal: 4.87s\tremaining: 31.2s\n",
      "135:\tlearn: 0.3105289\ttotal: 4.9s\tremaining: 31.1s\n",
      "136:\tlearn: 0.3099287\ttotal: 4.93s\tremaining: 31.1s\n",
      "137:\tlearn: 0.3091448\ttotal: 4.96s\tremaining: 31s\n",
      "138:\tlearn: 0.3087169\ttotal: 5s\tremaining: 31s\n",
      "139:\tlearn: 0.3084093\ttotal: 5.04s\tremaining: 30.9s\n",
      "140:\tlearn: 0.3079823\ttotal: 5.08s\tremaining: 30.9s\n",
      "141:\tlearn: 0.3064906\ttotal: 5.12s\tremaining: 30.9s\n",
      "142:\tlearn: 0.3057769\ttotal: 5.16s\tremaining: 30.9s\n",
      "143:\tlearn: 0.3048856\ttotal: 5.2s\tremaining: 30.9s\n",
      "144:\tlearn: 0.3039665\ttotal: 5.24s\tremaining: 30.9s\n",
      "145:\tlearn: 0.3032722\ttotal: 5.28s\tremaining: 30.9s\n",
      "146:\tlearn: 0.3027427\ttotal: 5.31s\tremaining: 30.8s\n",
      "147:\tlearn: 0.3024516\ttotal: 5.34s\tremaining: 30.7s\n",
      "148:\tlearn: 0.3018120\ttotal: 5.37s\tremaining: 30.7s\n",
      "149:\tlearn: 0.3014544\ttotal: 5.4s\tremaining: 30.6s\n",
      "150:\tlearn: 0.3011009\ttotal: 5.43s\tremaining: 30.6s\n",
      "151:\tlearn: 0.3004700\ttotal: 5.47s\tremaining: 30.5s\n",
      "152:\tlearn: 0.2999529\ttotal: 5.53s\tremaining: 30.6s\n",
      "153:\tlearn: 0.2993434\ttotal: 5.56s\tremaining: 30.6s\n",
      "154:\tlearn: 0.2989661\ttotal: 5.59s\tremaining: 30.5s\n",
      "155:\tlearn: 0.2976946\ttotal: 5.63s\tremaining: 30.5s\n",
      "156:\tlearn: 0.2972239\ttotal: 5.66s\tremaining: 30.4s\n",
      "157:\tlearn: 0.2962778\ttotal: 5.7s\tremaining: 30.4s\n",
      "158:\tlearn: 0.2951953\ttotal: 5.74s\tremaining: 30.4s\n",
      "159:\tlearn: 0.2943775\ttotal: 5.77s\tremaining: 30.3s\n",
      "160:\tlearn: 0.2935452\ttotal: 5.8s\tremaining: 30.2s\n",
      "161:\tlearn: 0.2932341\ttotal: 5.83s\tremaining: 30.2s\n",
      "162:\tlearn: 0.2928720\ttotal: 5.87s\tremaining: 30.1s\n",
      "163:\tlearn: 0.2924780\ttotal: 5.9s\tremaining: 30.1s\n",
      "164:\tlearn: 0.2921641\ttotal: 5.94s\tremaining: 30.1s\n",
      "165:\tlearn: 0.2914371\ttotal: 5.98s\tremaining: 30s\n",
      "166:\tlearn: 0.2908898\ttotal: 6.02s\tremaining: 30s\n",
      "167:\tlearn: 0.2903653\ttotal: 6.05s\tremaining: 30s\n",
      "168:\tlearn: 0.2895543\ttotal: 6.1s\tremaining: 30s\n",
      "169:\tlearn: 0.2891765\ttotal: 6.13s\tremaining: 29.9s\n",
      "170:\tlearn: 0.2883161\ttotal: 6.17s\tremaining: 29.9s\n",
      "171:\tlearn: 0.2879721\ttotal: 6.2s\tremaining: 29.8s\n",
      "172:\tlearn: 0.2871626\ttotal: 6.23s\tremaining: 29.8s\n",
      "173:\tlearn: 0.2866187\ttotal: 6.26s\tremaining: 29.7s\n",
      "174:\tlearn: 0.2860662\ttotal: 6.29s\tremaining: 29.7s\n",
      "175:\tlearn: 0.2854631\ttotal: 6.33s\tremaining: 29.6s\n",
      "176:\tlearn: 0.2846507\ttotal: 6.37s\tremaining: 29.6s\n",
      "177:\tlearn: 0.2836830\ttotal: 6.42s\tremaining: 29.7s\n",
      "178:\tlearn: 0.2834155\ttotal: 6.46s\tremaining: 29.6s\n",
      "179:\tlearn: 0.2826984\ttotal: 6.5s\tremaining: 29.6s\n",
      "180:\tlearn: 0.2824750\ttotal: 6.54s\tremaining: 29.6s\n",
      "181:\tlearn: 0.2818419\ttotal: 6.57s\tremaining: 29.5s\n",
      "182:\tlearn: 0.2815821\ttotal: 6.62s\tremaining: 29.5s\n",
      "183:\tlearn: 0.2806673\ttotal: 6.66s\tremaining: 29.5s\n",
      "184:\tlearn: 0.2802813\ttotal: 6.7s\tremaining: 29.5s\n",
      "185:\tlearn: 0.2796726\ttotal: 6.74s\tremaining: 29.5s\n",
      "186:\tlearn: 0.2789033\ttotal: 6.78s\tremaining: 29.5s\n",
      "187:\tlearn: 0.2781689\ttotal: 6.82s\tremaining: 29.5s\n",
      "188:\tlearn: 0.2775352\ttotal: 6.86s\tremaining: 29.5s\n",
      "189:\tlearn: 0.2768951\ttotal: 6.91s\tremaining: 29.5s\n",
      "190:\tlearn: 0.2765180\ttotal: 6.94s\tremaining: 29.4s\n",
      "191:\tlearn: 0.2759222\ttotal: 6.98s\tremaining: 29.4s\n",
      "192:\tlearn: 0.2755795\ttotal: 7.01s\tremaining: 29.3s\n",
      "193:\tlearn: 0.2747754\ttotal: 7.04s\tremaining: 29.3s\n",
      "194:\tlearn: 0.2742000\ttotal: 7.08s\tremaining: 29.2s\n",
      "195:\tlearn: 0.2734741\ttotal: 7.11s\tremaining: 29.2s\n",
      "196:\tlearn: 0.2726320\ttotal: 7.14s\tremaining: 29.1s\n",
      "197:\tlearn: 0.2724338\ttotal: 7.17s\tremaining: 29.1s\n",
      "198:\tlearn: 0.2716345\ttotal: 7.21s\tremaining: 29s\n",
      "199:\tlearn: 0.2711954\ttotal: 7.24s\tremaining: 29s\n",
      "200:\tlearn: 0.2709461\ttotal: 7.29s\tremaining: 29s\n",
      "201:\tlearn: 0.2707287\ttotal: 7.32s\tremaining: 28.9s\n",
      "202:\tlearn: 0.2703215\ttotal: 7.36s\tremaining: 28.9s\n",
      "203:\tlearn: 0.2701318\ttotal: 7.39s\tremaining: 28.8s\n",
      "204:\tlearn: 0.2698416\ttotal: 7.42s\tremaining: 28.8s\n",
      "205:\tlearn: 0.2694736\ttotal: 7.45s\tremaining: 28.7s\n",
      "206:\tlearn: 0.2690213\ttotal: 7.49s\tremaining: 28.7s\n",
      "207:\tlearn: 0.2682183\ttotal: 7.52s\tremaining: 28.6s\n",
      "208:\tlearn: 0.2676721\ttotal: 7.57s\tremaining: 28.6s\n",
      "209:\tlearn: 0.2672890\ttotal: 7.61s\tremaining: 28.6s\n",
      "210:\tlearn: 0.2665604\ttotal: 7.65s\tremaining: 28.6s\n",
      "211:\tlearn: 0.2663580\ttotal: 7.68s\tremaining: 28.5s\n",
      "212:\tlearn: 0.2656909\ttotal: 7.71s\tremaining: 28.5s\n",
      "213:\tlearn: 0.2651437\ttotal: 7.74s\tremaining: 28.4s\n",
      "214:\tlearn: 0.2646732\ttotal: 7.77s\tremaining: 28.4s\n",
      "215:\tlearn: 0.2644624\ttotal: 7.8s\tremaining: 28.3s\n",
      "216:\tlearn: 0.2640746\ttotal: 7.84s\tremaining: 28.3s\n",
      "217:\tlearn: 0.2634899\ttotal: 7.88s\tremaining: 28.2s\n",
      "218:\tlearn: 0.2633325\ttotal: 7.91s\tremaining: 28.2s\n",
      "219:\tlearn: 0.2626702\ttotal: 7.94s\tremaining: 28.2s\n",
      "220:\tlearn: 0.2624284\ttotal: 7.98s\tremaining: 28.1s\n",
      "221:\tlearn: 0.2621808\ttotal: 8.02s\tremaining: 28.1s\n",
      "222:\tlearn: 0.2617405\ttotal: 8.05s\tremaining: 28.1s\n",
      "223:\tlearn: 0.2615474\ttotal: 8.09s\tremaining: 28s\n",
      "224:\tlearn: 0.2609982\ttotal: 8.12s\tremaining: 28s\n",
      "225:\tlearn: 0.2605562\ttotal: 8.15s\tremaining: 27.9s\n",
      "226:\tlearn: 0.2602038\ttotal: 8.18s\tremaining: 27.9s\n",
      "227:\tlearn: 0.2597442\ttotal: 8.22s\tremaining: 27.8s\n",
      "228:\tlearn: 0.2595264\ttotal: 8.25s\tremaining: 27.8s\n",
      "229:\tlearn: 0.2591314\ttotal: 8.3s\tremaining: 27.8s\n",
      "230:\tlearn: 0.2587738\ttotal: 8.34s\tremaining: 27.8s\n",
      "231:\tlearn: 0.2584355\ttotal: 8.37s\tremaining: 27.7s\n",
      "232:\tlearn: 0.2581368\ttotal: 8.4s\tremaining: 27.7s\n",
      "233:\tlearn: 0.2577461\ttotal: 8.43s\tremaining: 27.6s\n",
      "234:\tlearn: 0.2572728\ttotal: 8.46s\tremaining: 27.6s\n",
      "235:\tlearn: 0.2570010\ttotal: 8.5s\tremaining: 27.5s\n",
      "236:\tlearn: 0.2566199\ttotal: 8.53s\tremaining: 27.5s\n",
      "237:\tlearn: 0.2564571\ttotal: 8.56s\tremaining: 27.4s\n",
      "238:\tlearn: 0.2561567\ttotal: 8.6s\tremaining: 27.4s\n",
      "239:\tlearn: 0.2558333\ttotal: 8.63s\tremaining: 27.3s\n",
      "240:\tlearn: 0.2553689\ttotal: 8.66s\tremaining: 27.3s\n",
      "241:\tlearn: 0.2550295\ttotal: 8.7s\tremaining: 27.2s\n",
      "242:\tlearn: 0.2545709\ttotal: 8.74s\tremaining: 27.2s\n",
      "243:\tlearn: 0.2543869\ttotal: 8.78s\tremaining: 27.2s\n",
      "244:\tlearn: 0.2535914\ttotal: 8.81s\tremaining: 27.2s\n",
      "245:\tlearn: 0.2533750\ttotal: 8.85s\tremaining: 27.1s\n",
      "246:\tlearn: 0.2532330\ttotal: 8.88s\tremaining: 27.1s\n",
      "247:\tlearn: 0.2529291\ttotal: 8.91s\tremaining: 27s\n",
      "248:\tlearn: 0.2524916\ttotal: 8.94s\tremaining: 27s\n",
      "249:\tlearn: 0.2521615\ttotal: 8.97s\tremaining: 26.9s\n",
      "250:\tlearn: 0.2518410\ttotal: 9.02s\tremaining: 26.9s\n",
      "251:\tlearn: 0.2516826\ttotal: 9.06s\tremaining: 26.9s\n",
      "252:\tlearn: 0.2513159\ttotal: 9.1s\tremaining: 26.9s\n",
      "253:\tlearn: 0.2507450\ttotal: 9.14s\tremaining: 26.8s\n",
      "254:\tlearn: 0.2503183\ttotal: 9.18s\tremaining: 26.8s\n",
      "255:\tlearn: 0.2500108\ttotal: 9.22s\tremaining: 26.8s\n",
      "256:\tlearn: 0.2498096\ttotal: 9.25s\tremaining: 26.7s\n",
      "257:\tlearn: 0.2496541\ttotal: 9.28s\tremaining: 26.7s\n",
      "258:\tlearn: 0.2494265\ttotal: 9.32s\tremaining: 26.7s\n",
      "259:\tlearn: 0.2491202\ttotal: 9.35s\tremaining: 26.6s\n",
      "260:\tlearn: 0.2487336\ttotal: 9.38s\tremaining: 26.6s\n",
      "261:\tlearn: 0.2483668\ttotal: 9.41s\tremaining: 26.5s\n",
      "262:\tlearn: 0.2477146\ttotal: 9.46s\tremaining: 26.5s\n",
      "263:\tlearn: 0.2475910\ttotal: 9.49s\tremaining: 26.5s\n",
      "264:\tlearn: 0.2473856\ttotal: 9.54s\tremaining: 26.4s\n",
      "265:\tlearn: 0.2472278\ttotal: 9.57s\tremaining: 26.4s\n",
      "266:\tlearn: 0.2467293\ttotal: 9.6s\tremaining: 26.4s\n",
      "267:\tlearn: 0.2460010\ttotal: 9.63s\tremaining: 26.3s\n",
      "268:\tlearn: 0.2457829\ttotal: 9.67s\tremaining: 26.3s\n",
      "269:\tlearn: 0.2456309\ttotal: 9.7s\tremaining: 26.2s\n",
      "270:\tlearn: 0.2452472\ttotal: 9.73s\tremaining: 26.2s\n",
      "271:\tlearn: 0.2449516\ttotal: 9.77s\tremaining: 26.1s\n",
      "272:\tlearn: 0.2445601\ttotal: 9.81s\tremaining: 26.1s\n",
      "273:\tlearn: 0.2442056\ttotal: 9.84s\tremaining: 26.1s\n",
      "274:\tlearn: 0.2439222\ttotal: 9.88s\tremaining: 26s\n",
      "275:\tlearn: 0.2438386\ttotal: 9.91s\tremaining: 26s\n",
      "276:\tlearn: 0.2433822\ttotal: 9.95s\tremaining: 26s\n",
      "277:\tlearn: 0.2429108\ttotal: 9.98s\tremaining: 25.9s\n",
      "278:\tlearn: 0.2427105\ttotal: 10s\tremaining: 25.9s\n",
      "279:\tlearn: 0.2425651\ttotal: 10s\tremaining: 25.8s\n",
      "280:\tlearn: 0.2424431\ttotal: 10.1s\tremaining: 25.8s\n",
      "281:\tlearn: 0.2422068\ttotal: 10.1s\tremaining: 25.7s\n",
      "282:\tlearn: 0.2418814\ttotal: 10.2s\tremaining: 25.7s\n",
      "283:\tlearn: 0.2417081\ttotal: 10.2s\tremaining: 25.7s\n",
      "284:\tlearn: 0.2413910\ttotal: 10.2s\tremaining: 25.7s\n",
      "285:\tlearn: 0.2411069\ttotal: 10.3s\tremaining: 25.6s\n",
      "286:\tlearn: 0.2405978\ttotal: 10.3s\tremaining: 25.6s\n",
      "287:\tlearn: 0.2403446\ttotal: 10.3s\tremaining: 25.5s\n",
      "288:\tlearn: 0.2399381\ttotal: 10.4s\tremaining: 25.5s\n",
      "289:\tlearn: 0.2397049\ttotal: 10.4s\tremaining: 25.4s\n",
      "290:\tlearn: 0.2392170\ttotal: 10.4s\tremaining: 25.4s\n",
      "291:\tlearn: 0.2389411\ttotal: 10.5s\tremaining: 25.4s\n",
      "292:\tlearn: 0.2387183\ttotal: 10.5s\tremaining: 25.3s\n",
      "293:\tlearn: 0.2381985\ttotal: 10.5s\tremaining: 25.3s\n",
      "294:\tlearn: 0.2379453\ttotal: 10.6s\tremaining: 25.2s\n",
      "295:\tlearn: 0.2375982\ttotal: 10.6s\tremaining: 25.2s\n",
      "296:\tlearn: 0.2374895\ttotal: 10.6s\tremaining: 25.2s\n",
      "297:\tlearn: 0.2370935\ttotal: 10.7s\tremaining: 25.1s\n",
      "298:\tlearn: 0.2368250\ttotal: 10.7s\tremaining: 25.1s\n",
      "299:\tlearn: 0.2365487\ttotal: 10.7s\tremaining: 25.1s\n",
      "300:\tlearn: 0.2362648\ttotal: 10.8s\tremaining: 25s\n",
      "301:\tlearn: 0.2359085\ttotal: 10.8s\tremaining: 25s\n",
      "302:\tlearn: 0.2355438\ttotal: 10.8s\tremaining: 24.9s\n",
      "303:\tlearn: 0.2351437\ttotal: 10.9s\tremaining: 24.9s\n",
      "304:\tlearn: 0.2348293\ttotal: 10.9s\tremaining: 24.9s\n",
      "305:\tlearn: 0.2346830\ttotal: 11s\tremaining: 24.8s\n",
      "306:\tlearn: 0.2341570\ttotal: 11s\tremaining: 24.8s\n",
      "307:\tlearn: 0.2340486\ttotal: 11s\tremaining: 24.8s\n",
      "308:\tlearn: 0.2336817\ttotal: 11.1s\tremaining: 24.8s\n",
      "309:\tlearn: 0.2335382\ttotal: 11.1s\tremaining: 24.7s\n",
      "310:\tlearn: 0.2330748\ttotal: 11.1s\tremaining: 24.7s\n",
      "311:\tlearn: 0.2327045\ttotal: 11.2s\tremaining: 24.6s\n",
      "312:\tlearn: 0.2324931\ttotal: 11.2s\tremaining: 24.6s\n",
      "313:\tlearn: 0.2323760\ttotal: 11.2s\tremaining: 24.6s\n",
      "314:\tlearn: 0.2321136\ttotal: 11.3s\tremaining: 24.5s\n",
      "315:\tlearn: 0.2320589\ttotal: 11.3s\tremaining: 24.5s\n",
      "316:\tlearn: 0.2315514\ttotal: 11.3s\tremaining: 24.4s\n",
      "317:\tlearn: 0.2312848\ttotal: 11.4s\tremaining: 24.4s\n",
      "318:\tlearn: 0.2310979\ttotal: 11.4s\tremaining: 24.4s\n",
      "319:\tlearn: 0.2309433\ttotal: 11.5s\tremaining: 24.4s\n",
      "320:\tlearn: 0.2308334\ttotal: 11.5s\tremaining: 24.3s\n",
      "321:\tlearn: 0.2306329\ttotal: 11.5s\tremaining: 24.3s\n",
      "322:\tlearn: 0.2303297\ttotal: 11.6s\tremaining: 24.3s\n",
      "323:\tlearn: 0.2301881\ttotal: 11.6s\tremaining: 24.2s\n",
      "324:\tlearn: 0.2299464\ttotal: 11.7s\tremaining: 24.2s\n",
      "325:\tlearn: 0.2294109\ttotal: 11.7s\tremaining: 24.2s\n",
      "326:\tlearn: 0.2291995\ttotal: 11.7s\tremaining: 24.1s\n",
      "327:\tlearn: 0.2290174\ttotal: 11.8s\tremaining: 24.1s\n",
      "328:\tlearn: 0.2288905\ttotal: 11.8s\tremaining: 24s\n",
      "329:\tlearn: 0.2286230\ttotal: 11.8s\tremaining: 24s\n",
      "330:\tlearn: 0.2285701\ttotal: 11.9s\tremaining: 24s\n",
      "331:\tlearn: 0.2282265\ttotal: 11.9s\tremaining: 24s\n",
      "332:\tlearn: 0.2281296\ttotal: 11.9s\tremaining: 23.9s\n",
      "333:\tlearn: 0.2278159\ttotal: 12s\tremaining: 23.9s\n",
      "334:\tlearn: 0.2273190\ttotal: 12s\tremaining: 23.9s\n",
      "335:\tlearn: 0.2269361\ttotal: 12.1s\tremaining: 23.8s\n",
      "336:\tlearn: 0.2267123\ttotal: 12.1s\tremaining: 23.8s\n",
      "337:\tlearn: 0.2264831\ttotal: 12.1s\tremaining: 23.7s\n",
      "338:\tlearn: 0.2263898\ttotal: 12.1s\tremaining: 23.7s\n",
      "339:\tlearn: 0.2261082\ttotal: 12.2s\tremaining: 23.6s\n",
      "340:\tlearn: 0.2258343\ttotal: 12.2s\tremaining: 23.6s\n",
      "341:\tlearn: 0.2256996\ttotal: 12.3s\tremaining: 23.6s\n",
      "342:\tlearn: 0.2253895\ttotal: 12.3s\tremaining: 23.6s\n",
      "343:\tlearn: 0.2249946\ttotal: 12.3s\tremaining: 23.5s\n",
      "344:\tlearn: 0.2246937\ttotal: 12.4s\tremaining: 23.5s\n",
      "345:\tlearn: 0.2242404\ttotal: 12.4s\tremaining: 23.5s\n",
      "346:\tlearn: 0.2241737\ttotal: 12.4s\tremaining: 23.4s\n",
      "347:\tlearn: 0.2240812\ttotal: 12.5s\tremaining: 23.4s\n",
      "348:\tlearn: 0.2238629\ttotal: 12.5s\tremaining: 23.3s\n",
      "349:\tlearn: 0.2236396\ttotal: 12.5s\tremaining: 23.3s\n",
      "350:\tlearn: 0.2235261\ttotal: 12.6s\tremaining: 23.2s\n",
      "351:\tlearn: 0.2233276\ttotal: 12.6s\tremaining: 23.2s\n",
      "352:\tlearn: 0.2232376\ttotal: 12.6s\tremaining: 23.2s\n",
      "353:\tlearn: 0.2227585\ttotal: 12.7s\tremaining: 23.1s\n",
      "354:\tlearn: 0.2226472\ttotal: 12.7s\tremaining: 23.1s\n",
      "355:\tlearn: 0.2224155\ttotal: 12.8s\tremaining: 23.1s\n",
      "356:\tlearn: 0.2220692\ttotal: 12.8s\tremaining: 23s\n",
      "357:\tlearn: 0.2218312\ttotal: 12.8s\tremaining: 23s\n",
      "358:\tlearn: 0.2217230\ttotal: 12.9s\tremaining: 23s\n",
      "359:\tlearn: 0.2215494\ttotal: 12.9s\tremaining: 22.9s\n",
      "360:\tlearn: 0.2210919\ttotal: 12.9s\tremaining: 22.9s\n",
      "361:\tlearn: 0.2209567\ttotal: 12.9s\tremaining: 22.8s\n",
      "362:\tlearn: 0.2207405\ttotal: 13s\tremaining: 22.8s\n",
      "363:\tlearn: 0.2204562\ttotal: 13s\tremaining: 22.8s\n",
      "364:\tlearn: 0.2203500\ttotal: 13.1s\tremaining: 22.7s\n",
      "365:\tlearn: 0.2198823\ttotal: 13.1s\tremaining: 22.7s\n",
      "366:\tlearn: 0.2196451\ttotal: 13.1s\tremaining: 22.7s\n",
      "367:\tlearn: 0.2194184\ttotal: 13.2s\tremaining: 22.6s\n",
      "368:\tlearn: 0.2191446\ttotal: 13.2s\tremaining: 22.6s\n",
      "369:\tlearn: 0.2188745\ttotal: 13.2s\tremaining: 22.5s\n",
      "370:\tlearn: 0.2187895\ttotal: 13.3s\tremaining: 22.5s\n",
      "371:\tlearn: 0.2184282\ttotal: 13.3s\tremaining: 22.4s\n",
      "372:\tlearn: 0.2181384\ttotal: 13.3s\tremaining: 22.4s\n",
      "373:\tlearn: 0.2178360\ttotal: 13.4s\tremaining: 22.4s\n",
      "374:\tlearn: 0.2176234\ttotal: 13.4s\tremaining: 22.3s\n",
      "375:\tlearn: 0.2173803\ttotal: 13.4s\tremaining: 22.3s\n",
      "376:\tlearn: 0.2170908\ttotal: 13.5s\tremaining: 22.3s\n",
      "377:\tlearn: 0.2169112\ttotal: 13.5s\tremaining: 22.2s\n",
      "378:\tlearn: 0.2167232\ttotal: 13.5s\tremaining: 22.2s\n",
      "379:\tlearn: 0.2166106\ttotal: 13.6s\tremaining: 22.1s\n",
      "380:\tlearn: 0.2161915\ttotal: 13.6s\tremaining: 22.1s\n",
      "381:\tlearn: 0.2160402\ttotal: 13.6s\tremaining: 22.1s\n",
      "382:\tlearn: 0.2159299\ttotal: 13.7s\tremaining: 22s\n",
      "383:\tlearn: 0.2156136\ttotal: 13.7s\tremaining: 22s\n",
      "384:\tlearn: 0.2154505\ttotal: 13.7s\tremaining: 22s\n",
      "385:\tlearn: 0.2153238\ttotal: 13.8s\tremaining: 21.9s\n",
      "386:\tlearn: 0.2152140\ttotal: 13.8s\tremaining: 21.9s\n",
      "387:\tlearn: 0.2149434\ttotal: 13.9s\tremaining: 21.9s\n",
      "388:\tlearn: 0.2147672\ttotal: 13.9s\tremaining: 21.8s\n",
      "389:\tlearn: 0.2145286\ttotal: 13.9s\tremaining: 21.8s\n",
      "390:\tlearn: 0.2142533\ttotal: 14s\tremaining: 21.8s\n",
      "391:\tlearn: 0.2139525\ttotal: 14s\tremaining: 21.7s\n",
      "392:\tlearn: 0.2134771\ttotal: 14s\tremaining: 21.7s\n",
      "393:\tlearn: 0.2132860\ttotal: 14.1s\tremaining: 21.7s\n",
      "394:\tlearn: 0.2131215\ttotal: 14.1s\tremaining: 21.6s\n",
      "395:\tlearn: 0.2130176\ttotal: 14.1s\tremaining: 21.6s\n",
      "396:\tlearn: 0.2127335\ttotal: 14.2s\tremaining: 21.5s\n",
      "397:\tlearn: 0.2125284\ttotal: 14.2s\tremaining: 21.5s\n",
      "398:\tlearn: 0.2124214\ttotal: 14.2s\tremaining: 21.5s\n",
      "399:\tlearn: 0.2122624\ttotal: 14.3s\tremaining: 21.4s\n",
      "400:\tlearn: 0.2120801\ttotal: 14.3s\tremaining: 21.4s\n",
      "401:\tlearn: 0.2119389\ttotal: 14.4s\tremaining: 21.4s\n",
      "402:\tlearn: 0.2116664\ttotal: 14.4s\tremaining: 21.3s\n",
      "403:\tlearn: 0.2113196\ttotal: 14.4s\tremaining: 21.3s\n",
      "404:\tlearn: 0.2110988\ttotal: 14.5s\tremaining: 21.3s\n",
      "405:\tlearn: 0.2107515\ttotal: 14.5s\tremaining: 21.2s\n",
      "406:\tlearn: 0.2105939\ttotal: 14.5s\tremaining: 21.2s\n",
      "407:\tlearn: 0.2103980\ttotal: 14.6s\tremaining: 21.1s\n",
      "408:\tlearn: 0.2102748\ttotal: 14.6s\tremaining: 21.1s\n",
      "409:\tlearn: 0.2099790\ttotal: 14.6s\tremaining: 21.1s\n",
      "410:\tlearn: 0.2097330\ttotal: 14.7s\tremaining: 21s\n",
      "411:\tlearn: 0.2095463\ttotal: 14.7s\tremaining: 21s\n",
      "412:\tlearn: 0.2093890\ttotal: 14.8s\tremaining: 21s\n",
      "413:\tlearn: 0.2093085\ttotal: 14.8s\tremaining: 20.9s\n",
      "414:\tlearn: 0.2091206\ttotal: 14.8s\tremaining: 20.9s\n",
      "415:\tlearn: 0.2089709\ttotal: 14.9s\tremaining: 20.9s\n",
      "416:\tlearn: 0.2088040\ttotal: 14.9s\tremaining: 20.8s\n",
      "417:\tlearn: 0.2084930\ttotal: 14.9s\tremaining: 20.8s\n",
      "418:\tlearn: 0.2080643\ttotal: 15s\tremaining: 20.7s\n",
      "419:\tlearn: 0.2078283\ttotal: 15s\tremaining: 20.7s\n",
      "420:\tlearn: 0.2075130\ttotal: 15s\tremaining: 20.7s\n",
      "421:\tlearn: 0.2071744\ttotal: 15.1s\tremaining: 20.6s\n",
      "422:\tlearn: 0.2070628\ttotal: 15.1s\tremaining: 20.6s\n",
      "423:\tlearn: 0.2068127\ttotal: 15.2s\tremaining: 20.6s\n",
      "424:\tlearn: 0.2067123\ttotal: 15.2s\tremaining: 20.6s\n",
      "425:\tlearn: 0.2064989\ttotal: 15.2s\tremaining: 20.5s\n",
      "426:\tlearn: 0.2063550\ttotal: 15.3s\tremaining: 20.5s\n",
      "427:\tlearn: 0.2061126\ttotal: 15.3s\tremaining: 20.5s\n",
      "428:\tlearn: 0.2058165\ttotal: 15.3s\tremaining: 20.4s\n",
      "429:\tlearn: 0.2055889\ttotal: 15.4s\tremaining: 20.4s\n",
      "430:\tlearn: 0.2053706\ttotal: 15.4s\tremaining: 20.3s\n",
      "431:\tlearn: 0.2051892\ttotal: 15.4s\tremaining: 20.3s\n",
      "432:\tlearn: 0.2049474\ttotal: 15.5s\tremaining: 20.3s\n",
      "433:\tlearn: 0.2048368\ttotal: 15.5s\tremaining: 20.3s\n",
      "434:\tlearn: 0.2046112\ttotal: 15.6s\tremaining: 20.2s\n",
      "435:\tlearn: 0.2043144\ttotal: 15.6s\tremaining: 20.2s\n",
      "436:\tlearn: 0.2041633\ttotal: 15.6s\tremaining: 20.2s\n",
      "437:\tlearn: 0.2039238\ttotal: 15.7s\tremaining: 20.1s\n",
      "438:\tlearn: 0.2037927\ttotal: 15.7s\tremaining: 20.1s\n",
      "439:\tlearn: 0.2035614\ttotal: 15.8s\tremaining: 20.1s\n",
      "440:\tlearn: 0.2032799\ttotal: 15.8s\tremaining: 20s\n",
      "441:\tlearn: 0.2031162\ttotal: 15.8s\tremaining: 20s\n",
      "442:\tlearn: 0.2029615\ttotal: 15.9s\tremaining: 20s\n",
      "443:\tlearn: 0.2028208\ttotal: 15.9s\tremaining: 19.9s\n",
      "444:\tlearn: 0.2027648\ttotal: 15.9s\tremaining: 19.9s\n",
      "445:\tlearn: 0.2025731\ttotal: 16s\tremaining: 19.8s\n",
      "446:\tlearn: 0.2022475\ttotal: 16s\tremaining: 19.8s\n",
      "447:\tlearn: 0.2021240\ttotal: 16.1s\tremaining: 19.8s\n",
      "448:\tlearn: 0.2020436\ttotal: 16.1s\tremaining: 19.8s\n",
      "449:\tlearn: 0.2018796\ttotal: 16.1s\tremaining: 19.7s\n",
      "450:\tlearn: 0.2016016\ttotal: 16.2s\tremaining: 19.7s\n",
      "451:\tlearn: 0.2014250\ttotal: 16.2s\tremaining: 19.7s\n",
      "452:\tlearn: 0.2011180\ttotal: 16.2s\tremaining: 19.6s\n",
      "453:\tlearn: 0.2009083\ttotal: 16.3s\tremaining: 19.6s\n",
      "454:\tlearn: 0.2007813\ttotal: 16.3s\tremaining: 19.5s\n",
      "455:\tlearn: 0.2005721\ttotal: 16.3s\tremaining: 19.5s\n",
      "456:\tlearn: 0.2002990\ttotal: 16.4s\tremaining: 19.4s\n",
      "457:\tlearn: 0.2000834\ttotal: 16.4s\tremaining: 19.4s\n",
      "458:\tlearn: 0.1999395\ttotal: 16.5s\tremaining: 19.4s\n",
      "459:\tlearn: 0.1997643\ttotal: 16.5s\tremaining: 19.4s\n",
      "460:\tlearn: 0.1994852\ttotal: 16.5s\tremaining: 19.3s\n",
      "461:\tlearn: 0.1990207\ttotal: 16.6s\tremaining: 19.3s\n",
      "462:\tlearn: 0.1986898\ttotal: 16.6s\tremaining: 19.3s\n",
      "463:\tlearn: 0.1985586\ttotal: 16.6s\tremaining: 19.2s\n",
      "464:\tlearn: 0.1984742\ttotal: 16.7s\tremaining: 19.2s\n",
      "465:\tlearn: 0.1981232\ttotal: 16.7s\tremaining: 19.2s\n",
      "466:\tlearn: 0.1978913\ttotal: 16.8s\tremaining: 19.1s\n",
      "467:\tlearn: 0.1977733\ttotal: 16.8s\tremaining: 19.1s\n",
      "468:\tlearn: 0.1976410\ttotal: 16.8s\tremaining: 19s\n",
      "469:\tlearn: 0.1975069\ttotal: 16.9s\tremaining: 19s\n",
      "470:\tlearn: 0.1972939\ttotal: 16.9s\tremaining: 19s\n",
      "471:\tlearn: 0.1971014\ttotal: 16.9s\tremaining: 19s\n",
      "472:\tlearn: 0.1970012\ttotal: 17s\tremaining: 18.9s\n",
      "473:\tlearn: 0.1969279\ttotal: 17s\tremaining: 18.9s\n",
      "474:\tlearn: 0.1966195\ttotal: 17s\tremaining: 18.8s\n",
      "475:\tlearn: 0.1963823\ttotal: 17.1s\tremaining: 18.8s\n",
      "476:\tlearn: 0.1962360\ttotal: 17.1s\tremaining: 18.8s\n",
      "477:\tlearn: 0.1960501\ttotal: 17.2s\tremaining: 18.7s\n",
      "478:\tlearn: 0.1959113\ttotal: 17.2s\tremaining: 18.7s\n",
      "479:\tlearn: 0.1957506\ttotal: 17.2s\tremaining: 18.7s\n",
      "480:\tlearn: 0.1956853\ttotal: 17.3s\tremaining: 18.6s\n",
      "481:\tlearn: 0.1955988\ttotal: 17.3s\tremaining: 18.6s\n",
      "482:\tlearn: 0.1954640\ttotal: 17.3s\tremaining: 18.6s\n",
      "483:\tlearn: 0.1952127\ttotal: 17.4s\tremaining: 18.5s\n",
      "484:\tlearn: 0.1950937\ttotal: 17.4s\tremaining: 18.5s\n",
      "485:\tlearn: 0.1949044\ttotal: 17.5s\tremaining: 18.5s\n",
      "486:\tlearn: 0.1945573\ttotal: 17.5s\tremaining: 18.4s\n",
      "487:\tlearn: 0.1944409\ttotal: 17.5s\tremaining: 18.4s\n",
      "488:\tlearn: 0.1943769\ttotal: 17.6s\tremaining: 18.3s\n",
      "489:\tlearn: 0.1942091\ttotal: 17.6s\tremaining: 18.3s\n",
      "490:\tlearn: 0.1939017\ttotal: 17.6s\tremaining: 18.3s\n",
      "491:\tlearn: 0.1937431\ttotal: 17.7s\tremaining: 18.2s\n",
      "492:\tlearn: 0.1933914\ttotal: 17.7s\tremaining: 18.2s\n",
      "493:\tlearn: 0.1930792\ttotal: 17.7s\tremaining: 18.2s\n",
      "494:\tlearn: 0.1927704\ttotal: 17.8s\tremaining: 18.1s\n",
      "495:\tlearn: 0.1925702\ttotal: 17.8s\tremaining: 18.1s\n",
      "496:\tlearn: 0.1923930\ttotal: 17.9s\tremaining: 18.1s\n",
      "497:\tlearn: 0.1922247\ttotal: 17.9s\tremaining: 18s\n",
      "498:\tlearn: 0.1919794\ttotal: 17.9s\tremaining: 18s\n",
      "499:\tlearn: 0.1917969\ttotal: 17.9s\tremaining: 17.9s\n",
      "500:\tlearn: 0.1917260\ttotal: 18s\tremaining: 17.9s\n",
      "501:\tlearn: 0.1915356\ttotal: 18s\tremaining: 17.9s\n",
      "502:\tlearn: 0.1912427\ttotal: 18s\tremaining: 17.8s\n",
      "503:\tlearn: 0.1910897\ttotal: 18.1s\tremaining: 17.8s\n",
      "504:\tlearn: 0.1909473\ttotal: 18.1s\tremaining: 17.8s\n",
      "505:\tlearn: 0.1907791\ttotal: 18.2s\tremaining: 17.7s\n",
      "506:\tlearn: 0.1907391\ttotal: 18.2s\tremaining: 17.7s\n",
      "507:\tlearn: 0.1906142\ttotal: 18.2s\tremaining: 17.7s\n",
      "508:\tlearn: 0.1904839\ttotal: 18.3s\tremaining: 17.6s\n",
      "509:\tlearn: 0.1902983\ttotal: 18.3s\tremaining: 17.6s\n",
      "510:\tlearn: 0.1901216\ttotal: 18.3s\tremaining: 17.6s\n",
      "511:\tlearn: 0.1899679\ttotal: 18.4s\tremaining: 17.5s\n",
      "512:\tlearn: 0.1897791\ttotal: 18.4s\tremaining: 17.5s\n",
      "513:\tlearn: 0.1896417\ttotal: 18.4s\tremaining: 17.4s\n",
      "514:\tlearn: 0.1895074\ttotal: 18.5s\tremaining: 17.4s\n",
      "515:\tlearn: 0.1893480\ttotal: 18.5s\tremaining: 17.4s\n",
      "516:\tlearn: 0.1891909\ttotal: 18.6s\tremaining: 17.3s\n",
      "517:\tlearn: 0.1890492\ttotal: 18.6s\tremaining: 17.3s\n",
      "518:\tlearn: 0.1888791\ttotal: 18.6s\tremaining: 17.3s\n",
      "519:\tlearn: 0.1888065\ttotal: 18.7s\tremaining: 17.2s\n",
      "520:\tlearn: 0.1886586\ttotal: 18.7s\tremaining: 17.2s\n",
      "521:\tlearn: 0.1885721\ttotal: 18.7s\tremaining: 17.2s\n",
      "522:\tlearn: 0.1883439\ttotal: 18.8s\tremaining: 17.1s\n",
      "523:\tlearn: 0.1881163\ttotal: 18.8s\tremaining: 17.1s\n",
      "524:\tlearn: 0.1878291\ttotal: 18.8s\tremaining: 17.1s\n",
      "525:\tlearn: 0.1876961\ttotal: 18.9s\tremaining: 17s\n",
      "526:\tlearn: 0.1874787\ttotal: 18.9s\tremaining: 17s\n",
      "527:\tlearn: 0.1873027\ttotal: 18.9s\tremaining: 16.9s\n",
      "528:\tlearn: 0.1872067\ttotal: 19s\tremaining: 16.9s\n",
      "529:\tlearn: 0.1869960\ttotal: 19s\tremaining: 16.9s\n",
      "530:\tlearn: 0.1867822\ttotal: 19.1s\tremaining: 16.8s\n",
      "531:\tlearn: 0.1866490\ttotal: 19.1s\tremaining: 16.8s\n",
      "532:\tlearn: 0.1865742\ttotal: 19.1s\tremaining: 16.8s\n",
      "533:\tlearn: 0.1864115\ttotal: 19.2s\tremaining: 16.7s\n",
      "534:\tlearn: 0.1862799\ttotal: 19.2s\tremaining: 16.7s\n",
      "535:\tlearn: 0.1861566\ttotal: 19.2s\tremaining: 16.7s\n",
      "536:\tlearn: 0.1860426\ttotal: 19.3s\tremaining: 16.6s\n",
      "537:\tlearn: 0.1859413\ttotal: 19.3s\tremaining: 16.6s\n",
      "538:\tlearn: 0.1858362\ttotal: 19.4s\tremaining: 16.6s\n",
      "539:\tlearn: 0.1857571\ttotal: 19.4s\tremaining: 16.5s\n",
      "540:\tlearn: 0.1855757\ttotal: 19.4s\tremaining: 16.5s\n",
      "541:\tlearn: 0.1853965\ttotal: 19.5s\tremaining: 16.4s\n",
      "542:\tlearn: 0.1851814\ttotal: 19.5s\tremaining: 16.4s\n",
      "543:\tlearn: 0.1850880\ttotal: 19.5s\tremaining: 16.4s\n",
      "544:\tlearn: 0.1850021\ttotal: 19.6s\tremaining: 16.3s\n",
      "545:\tlearn: 0.1848912\ttotal: 19.6s\tremaining: 16.3s\n",
      "546:\tlearn: 0.1847686\ttotal: 19.6s\tremaining: 16.3s\n",
      "547:\tlearn: 0.1846635\ttotal: 19.7s\tremaining: 16.2s\n",
      "548:\tlearn: 0.1845474\ttotal: 19.7s\tremaining: 16.2s\n",
      "549:\tlearn: 0.1843799\ttotal: 19.8s\tremaining: 16.2s\n",
      "550:\tlearn: 0.1841527\ttotal: 19.8s\tremaining: 16.1s\n",
      "551:\tlearn: 0.1840215\ttotal: 19.8s\tremaining: 16.1s\n",
      "552:\tlearn: 0.1836554\ttotal: 19.8s\tremaining: 16s\n",
      "553:\tlearn: 0.1834939\ttotal: 19.9s\tremaining: 16s\n",
      "554:\tlearn: 0.1834218\ttotal: 19.9s\tremaining: 16s\n",
      "555:\tlearn: 0.1833433\ttotal: 20s\tremaining: 15.9s\n",
      "556:\tlearn: 0.1831594\ttotal: 20s\tremaining: 15.9s\n",
      "557:\tlearn: 0.1830864\ttotal: 20s\tremaining: 15.9s\n",
      "558:\tlearn: 0.1828103\ttotal: 20.1s\tremaining: 15.8s\n",
      "559:\tlearn: 0.1826893\ttotal: 20.1s\tremaining: 15.8s\n",
      "560:\tlearn: 0.1825670\ttotal: 20.1s\tremaining: 15.8s\n",
      "561:\tlearn: 0.1823972\ttotal: 20.2s\tremaining: 15.7s\n",
      "562:\tlearn: 0.1821198\ttotal: 20.2s\tremaining: 15.7s\n",
      "563:\tlearn: 0.1820381\ttotal: 20.2s\tremaining: 15.6s\n",
      "564:\tlearn: 0.1818893\ttotal: 20.3s\tremaining: 15.6s\n",
      "565:\tlearn: 0.1817723\ttotal: 20.3s\tremaining: 15.6s\n",
      "566:\tlearn: 0.1814694\ttotal: 20.4s\tremaining: 15.6s\n",
      "567:\tlearn: 0.1813988\ttotal: 20.4s\tremaining: 15.5s\n",
      "568:\tlearn: 0.1811125\ttotal: 20.4s\tremaining: 15.5s\n",
      "569:\tlearn: 0.1810348\ttotal: 20.5s\tremaining: 15.4s\n",
      "570:\tlearn: 0.1808815\ttotal: 20.5s\tremaining: 15.4s\n",
      "571:\tlearn: 0.1806567\ttotal: 20.5s\tremaining: 15.4s\n",
      "572:\tlearn: 0.1806027\ttotal: 20.6s\tremaining: 15.3s\n",
      "573:\tlearn: 0.1804542\ttotal: 20.6s\tremaining: 15.3s\n",
      "574:\tlearn: 0.1803285\ttotal: 20.6s\tremaining: 15.3s\n",
      "575:\tlearn: 0.1803047\ttotal: 20.7s\tremaining: 15.2s\n",
      "576:\tlearn: 0.1800979\ttotal: 20.7s\tremaining: 15.2s\n",
      "577:\tlearn: 0.1799137\ttotal: 20.7s\tremaining: 15.1s\n",
      "578:\tlearn: 0.1797681\ttotal: 20.8s\tremaining: 15.1s\n",
      "579:\tlearn: 0.1795754\ttotal: 20.8s\tremaining: 15.1s\n",
      "580:\tlearn: 0.1794010\ttotal: 20.9s\tremaining: 15s\n",
      "581:\tlearn: 0.1792636\ttotal: 20.9s\tremaining: 15s\n",
      "582:\tlearn: 0.1791384\ttotal: 20.9s\tremaining: 15s\n",
      "583:\tlearn: 0.1790499\ttotal: 21s\tremaining: 14.9s\n",
      "584:\tlearn: 0.1789328\ttotal: 21s\tremaining: 14.9s\n",
      "585:\tlearn: 0.1787071\ttotal: 21s\tremaining: 14.8s\n",
      "586:\tlearn: 0.1785994\ttotal: 21.1s\tremaining: 14.8s\n",
      "587:\tlearn: 0.1785625\ttotal: 21.1s\tremaining: 14.8s\n",
      "588:\tlearn: 0.1784491\ttotal: 21.1s\tremaining: 14.7s\n",
      "589:\tlearn: 0.1781533\ttotal: 21.2s\tremaining: 14.7s\n",
      "590:\tlearn: 0.1780513\ttotal: 21.2s\tremaining: 14.7s\n",
      "591:\tlearn: 0.1779675\ttotal: 21.2s\tremaining: 14.6s\n",
      "592:\tlearn: 0.1777805\ttotal: 21.3s\tremaining: 14.6s\n",
      "593:\tlearn: 0.1776950\ttotal: 21.3s\tremaining: 14.6s\n",
      "594:\tlearn: 0.1775942\ttotal: 21.4s\tremaining: 14.5s\n",
      "595:\tlearn: 0.1773344\ttotal: 21.4s\tremaining: 14.5s\n",
      "596:\tlearn: 0.1771443\ttotal: 21.4s\tremaining: 14.5s\n",
      "597:\tlearn: 0.1770735\ttotal: 21.5s\tremaining: 14.4s\n",
      "598:\tlearn: 0.1768606\ttotal: 21.5s\tremaining: 14.4s\n",
      "599:\tlearn: 0.1765643\ttotal: 21.5s\tremaining: 14.4s\n",
      "600:\tlearn: 0.1764806\ttotal: 21.6s\tremaining: 14.3s\n",
      "601:\tlearn: 0.1762045\ttotal: 21.6s\tremaining: 14.3s\n",
      "602:\tlearn: 0.1761657\ttotal: 21.7s\tremaining: 14.3s\n",
      "603:\tlearn: 0.1760748\ttotal: 21.7s\tremaining: 14.2s\n",
      "604:\tlearn: 0.1760387\ttotal: 21.7s\tremaining: 14.2s\n",
      "605:\tlearn: 0.1757449\ttotal: 21.8s\tremaining: 14.2s\n",
      "606:\tlearn: 0.1756735\ttotal: 21.8s\tremaining: 14.1s\n",
      "607:\tlearn: 0.1755017\ttotal: 21.8s\tremaining: 14.1s\n",
      "608:\tlearn: 0.1754076\ttotal: 21.9s\tremaining: 14s\n",
      "609:\tlearn: 0.1751918\ttotal: 21.9s\tremaining: 14s\n",
      "610:\tlearn: 0.1750491\ttotal: 21.9s\tremaining: 14s\n",
      "611:\tlearn: 0.1749361\ttotal: 22s\tremaining: 13.9s\n",
      "612:\tlearn: 0.1747278\ttotal: 22s\tremaining: 13.9s\n",
      "613:\tlearn: 0.1746006\ttotal: 22s\tremaining: 13.8s\n",
      "614:\tlearn: 0.1744773\ttotal: 22.1s\tremaining: 13.8s\n",
      "615:\tlearn: 0.1744022\ttotal: 22.1s\tremaining: 13.8s\n",
      "616:\tlearn: 0.1741904\ttotal: 22.1s\tremaining: 13.7s\n",
      "617:\tlearn: 0.1740655\ttotal: 22.2s\tremaining: 13.7s\n",
      "618:\tlearn: 0.1739144\ttotal: 22.2s\tremaining: 13.7s\n",
      "619:\tlearn: 0.1737733\ttotal: 22.2s\tremaining: 13.6s\n",
      "620:\tlearn: 0.1736083\ttotal: 22.3s\tremaining: 13.6s\n",
      "621:\tlearn: 0.1734893\ttotal: 22.3s\tremaining: 13.6s\n",
      "622:\tlearn: 0.1734501\ttotal: 22.4s\tremaining: 13.5s\n",
      "623:\tlearn: 0.1733921\ttotal: 22.4s\tremaining: 13.5s\n",
      "624:\tlearn: 0.1731774\ttotal: 22.4s\tremaining: 13.5s\n",
      "625:\tlearn: 0.1730090\ttotal: 22.5s\tremaining: 13.4s\n",
      "626:\tlearn: 0.1728893\ttotal: 22.5s\tremaining: 13.4s\n",
      "627:\tlearn: 0.1727605\ttotal: 22.5s\tremaining: 13.4s\n",
      "628:\tlearn: 0.1725678\ttotal: 22.6s\tremaining: 13.3s\n",
      "629:\tlearn: 0.1723805\ttotal: 22.6s\tremaining: 13.3s\n",
      "630:\tlearn: 0.1722432\ttotal: 22.7s\tremaining: 13.3s\n",
      "631:\tlearn: 0.1720951\ttotal: 22.7s\tremaining: 13.2s\n",
      "632:\tlearn: 0.1717958\ttotal: 22.8s\tremaining: 13.2s\n",
      "633:\tlearn: 0.1715658\ttotal: 22.8s\tremaining: 13.2s\n",
      "634:\tlearn: 0.1714380\ttotal: 22.8s\tremaining: 13.1s\n",
      "635:\tlearn: 0.1713755\ttotal: 22.9s\tremaining: 13.1s\n",
      "636:\tlearn: 0.1711390\ttotal: 22.9s\tremaining: 13.1s\n",
      "637:\tlearn: 0.1709733\ttotal: 22.9s\tremaining: 13s\n",
      "638:\tlearn: 0.1707829\ttotal: 23s\tremaining: 13s\n",
      "639:\tlearn: 0.1707347\ttotal: 23s\tremaining: 12.9s\n",
      "640:\tlearn: 0.1706508\ttotal: 23s\tremaining: 12.9s\n",
      "641:\tlearn: 0.1705549\ttotal: 23.1s\tremaining: 12.9s\n",
      "642:\tlearn: 0.1704142\ttotal: 23.1s\tremaining: 12.8s\n",
      "643:\tlearn: 0.1702350\ttotal: 23.2s\tremaining: 12.8s\n",
      "644:\tlearn: 0.1700197\ttotal: 23.2s\tremaining: 12.8s\n",
      "645:\tlearn: 0.1698974\ttotal: 23.2s\tremaining: 12.7s\n",
      "646:\tlearn: 0.1697993\ttotal: 23.3s\tremaining: 12.7s\n",
      "647:\tlearn: 0.1696515\ttotal: 23.3s\tremaining: 12.7s\n",
      "648:\tlearn: 0.1694651\ttotal: 23.3s\tremaining: 12.6s\n",
      "649:\tlearn: 0.1694201\ttotal: 23.4s\tremaining: 12.6s\n",
      "650:\tlearn: 0.1692707\ttotal: 23.4s\tremaining: 12.6s\n",
      "651:\tlearn: 0.1692096\ttotal: 23.4s\tremaining: 12.5s\n",
      "652:\tlearn: 0.1691510\ttotal: 23.5s\tremaining: 12.5s\n",
      "653:\tlearn: 0.1690977\ttotal: 23.5s\tremaining: 12.4s\n",
      "654:\tlearn: 0.1690138\ttotal: 23.5s\tremaining: 12.4s\n",
      "655:\tlearn: 0.1688998\ttotal: 23.6s\tremaining: 12.4s\n",
      "656:\tlearn: 0.1688238\ttotal: 23.6s\tremaining: 12.3s\n",
      "657:\tlearn: 0.1685947\ttotal: 23.7s\tremaining: 12.3s\n",
      "658:\tlearn: 0.1685014\ttotal: 23.7s\tremaining: 12.3s\n",
      "659:\tlearn: 0.1684499\ttotal: 23.7s\tremaining: 12.2s\n",
      "660:\tlearn: 0.1682405\ttotal: 23.8s\tremaining: 12.2s\n",
      "661:\tlearn: 0.1680210\ttotal: 23.8s\tremaining: 12.2s\n",
      "662:\tlearn: 0.1679461\ttotal: 23.8s\tremaining: 12.1s\n",
      "663:\tlearn: 0.1678615\ttotal: 23.9s\tremaining: 12.1s\n",
      "664:\tlearn: 0.1677272\ttotal: 23.9s\tremaining: 12s\n",
      "665:\tlearn: 0.1675272\ttotal: 23.9s\tremaining: 12s\n",
      "666:\tlearn: 0.1673971\ttotal: 24s\tremaining: 12s\n",
      "667:\tlearn: 0.1673432\ttotal: 24s\tremaining: 11.9s\n",
      "668:\tlearn: 0.1671403\ttotal: 24s\tremaining: 11.9s\n",
      "669:\tlearn: 0.1670350\ttotal: 24.1s\tremaining: 11.9s\n",
      "670:\tlearn: 0.1669597\ttotal: 24.1s\tremaining: 11.8s\n",
      "671:\tlearn: 0.1668381\ttotal: 24.2s\tremaining: 11.8s\n",
      "672:\tlearn: 0.1667961\ttotal: 24.2s\tremaining: 11.8s\n",
      "673:\tlearn: 0.1666338\ttotal: 24.2s\tremaining: 11.7s\n",
      "674:\tlearn: 0.1664830\ttotal: 24.3s\tremaining: 11.7s\n",
      "675:\tlearn: 0.1663724\ttotal: 24.3s\tremaining: 11.7s\n",
      "676:\tlearn: 0.1661531\ttotal: 24.3s\tremaining: 11.6s\n",
      "677:\tlearn: 0.1660169\ttotal: 24.4s\tremaining: 11.6s\n",
      "678:\tlearn: 0.1658799\ttotal: 24.4s\tremaining: 11.5s\n",
      "679:\tlearn: 0.1657391\ttotal: 24.4s\tremaining: 11.5s\n",
      "680:\tlearn: 0.1656670\ttotal: 24.5s\tremaining: 11.5s\n",
      "681:\tlearn: 0.1656007\ttotal: 24.5s\tremaining: 11.4s\n",
      "682:\tlearn: 0.1654623\ttotal: 24.6s\tremaining: 11.4s\n",
      "683:\tlearn: 0.1653868\ttotal: 24.6s\tremaining: 11.4s\n",
      "684:\tlearn: 0.1651622\ttotal: 24.6s\tremaining: 11.3s\n",
      "685:\tlearn: 0.1651004\ttotal: 24.7s\tremaining: 11.3s\n",
      "686:\tlearn: 0.1649840\ttotal: 24.7s\tremaining: 11.3s\n",
      "687:\tlearn: 0.1648266\ttotal: 24.8s\tremaining: 11.2s\n",
      "688:\tlearn: 0.1647462\ttotal: 24.8s\tremaining: 11.2s\n",
      "689:\tlearn: 0.1646264\ttotal: 24.8s\tremaining: 11.2s\n",
      "690:\tlearn: 0.1644663\ttotal: 24.9s\tremaining: 11.1s\n",
      "691:\tlearn: 0.1643415\ttotal: 24.9s\tremaining: 11.1s\n",
      "692:\tlearn: 0.1642700\ttotal: 24.9s\tremaining: 11s\n",
      "693:\tlearn: 0.1641687\ttotal: 24.9s\tremaining: 11s\n",
      "694:\tlearn: 0.1640973\ttotal: 25s\tremaining: 11s\n",
      "695:\tlearn: 0.1638728\ttotal: 25s\tremaining: 10.9s\n",
      "696:\tlearn: 0.1637791\ttotal: 25.1s\tremaining: 10.9s\n",
      "697:\tlearn: 0.1635620\ttotal: 25.1s\tremaining: 10.9s\n",
      "698:\tlearn: 0.1633664\ttotal: 25.1s\tremaining: 10.8s\n",
      "699:\tlearn: 0.1633044\ttotal: 25.2s\tremaining: 10.8s\n",
      "700:\tlearn: 0.1631651\ttotal: 25.2s\tremaining: 10.8s\n",
      "701:\tlearn: 0.1630690\ttotal: 25.3s\tremaining: 10.7s\n",
      "702:\tlearn: 0.1628820\ttotal: 25.3s\tremaining: 10.7s\n",
      "703:\tlearn: 0.1627939\ttotal: 25.3s\tremaining: 10.7s\n",
      "704:\tlearn: 0.1626886\ttotal: 25.4s\tremaining: 10.6s\n",
      "705:\tlearn: 0.1625631\ttotal: 25.4s\tremaining: 10.6s\n",
      "706:\tlearn: 0.1624865\ttotal: 25.4s\tremaining: 10.5s\n",
      "707:\tlearn: 0.1624015\ttotal: 25.5s\tremaining: 10.5s\n",
      "708:\tlearn: 0.1622753\ttotal: 25.5s\tremaining: 10.5s\n",
      "709:\tlearn: 0.1620569\ttotal: 25.6s\tremaining: 10.4s\n",
      "710:\tlearn: 0.1619698\ttotal: 25.6s\tremaining: 10.4s\n",
      "711:\tlearn: 0.1618188\ttotal: 25.6s\tremaining: 10.4s\n",
      "712:\tlearn: 0.1617478\ttotal: 25.7s\tremaining: 10.3s\n",
      "713:\tlearn: 0.1616914\ttotal: 25.7s\tremaining: 10.3s\n",
      "714:\tlearn: 0.1615825\ttotal: 25.8s\tremaining: 10.3s\n",
      "715:\tlearn: 0.1614621\ttotal: 25.8s\tremaining: 10.2s\n",
      "716:\tlearn: 0.1613746\ttotal: 25.8s\tremaining: 10.2s\n",
      "717:\tlearn: 0.1613021\ttotal: 25.8s\tremaining: 10.2s\n",
      "718:\tlearn: 0.1611182\ttotal: 25.9s\tremaining: 10.1s\n",
      "719:\tlearn: 0.1610207\ttotal: 25.9s\tremaining: 10.1s\n",
      "720:\tlearn: 0.1609007\ttotal: 26s\tremaining: 10.1s\n",
      "721:\tlearn: 0.1608408\ttotal: 26s\tremaining: 10s\n",
      "722:\tlearn: 0.1607429\ttotal: 26s\tremaining: 9.98s\n",
      "723:\tlearn: 0.1605977\ttotal: 26.1s\tremaining: 9.94s\n",
      "724:\tlearn: 0.1605093\ttotal: 26.1s\tremaining: 9.91s\n",
      "725:\tlearn: 0.1603625\ttotal: 26.2s\tremaining: 9.87s\n",
      "726:\tlearn: 0.1602894\ttotal: 26.2s\tremaining: 9.84s\n",
      "727:\tlearn: 0.1600719\ttotal: 26.2s\tremaining: 9.8s\n",
      "728:\tlearn: 0.1599568\ttotal: 26.3s\tremaining: 9.76s\n",
      "729:\tlearn: 0.1597958\ttotal: 26.3s\tremaining: 9.72s\n",
      "730:\tlearn: 0.1597146\ttotal: 26.3s\tremaining: 9.69s\n",
      "731:\tlearn: 0.1596500\ttotal: 26.4s\tremaining: 9.65s\n",
      "732:\tlearn: 0.1594801\ttotal: 26.4s\tremaining: 9.62s\n",
      "733:\tlearn: 0.1593699\ttotal: 26.4s\tremaining: 9.58s\n",
      "734:\tlearn: 0.1592858\ttotal: 26.5s\tremaining: 9.55s\n",
      "735:\tlearn: 0.1592313\ttotal: 26.5s\tremaining: 9.52s\n",
      "736:\tlearn: 0.1590523\ttotal: 26.6s\tremaining: 9.48s\n",
      "737:\tlearn: 0.1589664\ttotal: 26.6s\tremaining: 9.44s\n",
      "738:\tlearn: 0.1587994\ttotal: 26.6s\tremaining: 9.4s\n",
      "739:\tlearn: 0.1587282\ttotal: 26.7s\tremaining: 9.37s\n",
      "740:\tlearn: 0.1586341\ttotal: 26.7s\tremaining: 9.33s\n",
      "741:\tlearn: 0.1584594\ttotal: 26.7s\tremaining: 9.29s\n",
      "742:\tlearn: 0.1583387\ttotal: 26.8s\tremaining: 9.26s\n",
      "743:\tlearn: 0.1582724\ttotal: 26.8s\tremaining: 9.22s\n",
      "744:\tlearn: 0.1581630\ttotal: 26.8s\tremaining: 9.18s\n",
      "745:\tlearn: 0.1580985\ttotal: 26.9s\tremaining: 9.15s\n",
      "746:\tlearn: 0.1580412\ttotal: 26.9s\tremaining: 9.12s\n",
      "747:\tlearn: 0.1578753\ttotal: 26.9s\tremaining: 9.08s\n",
      "748:\tlearn: 0.1577838\ttotal: 27s\tremaining: 9.04s\n",
      "749:\tlearn: 0.1577020\ttotal: 27s\tremaining: 9.01s\n",
      "750:\tlearn: 0.1575440\ttotal: 27.1s\tremaining: 8.97s\n",
      "751:\tlearn: 0.1574523\ttotal: 27.1s\tremaining: 8.93s\n",
      "752:\tlearn: 0.1573710\ttotal: 27.1s\tremaining: 8.9s\n",
      "753:\tlearn: 0.1572384\ttotal: 27.2s\tremaining: 8.86s\n",
      "754:\tlearn: 0.1570869\ttotal: 27.2s\tremaining: 8.83s\n",
      "755:\tlearn: 0.1570408\ttotal: 27.3s\tremaining: 8.8s\n",
      "756:\tlearn: 0.1568904\ttotal: 27.3s\tremaining: 8.76s\n",
      "757:\tlearn: 0.1567422\ttotal: 27.3s\tremaining: 8.73s\n",
      "758:\tlearn: 0.1566745\ttotal: 27.4s\tremaining: 8.69s\n",
      "759:\tlearn: 0.1565646\ttotal: 27.4s\tremaining: 8.65s\n",
      "760:\tlearn: 0.1564804\ttotal: 27.4s\tremaining: 8.62s\n",
      "761:\tlearn: 0.1564319\ttotal: 27.5s\tremaining: 8.58s\n",
      "762:\tlearn: 0.1563355\ttotal: 27.5s\tremaining: 8.54s\n",
      "763:\tlearn: 0.1561269\ttotal: 27.5s\tremaining: 8.51s\n",
      "764:\tlearn: 0.1560722\ttotal: 27.6s\tremaining: 8.47s\n",
      "765:\tlearn: 0.1559635\ttotal: 27.6s\tremaining: 8.44s\n",
      "766:\tlearn: 0.1558164\ttotal: 27.7s\tremaining: 8.4s\n",
      "767:\tlearn: 0.1556470\ttotal: 27.7s\tremaining: 8.37s\n",
      "768:\tlearn: 0.1555991\ttotal: 27.7s\tremaining: 8.33s\n",
      "769:\tlearn: 0.1555081\ttotal: 27.8s\tremaining: 8.3s\n",
      "770:\tlearn: 0.1554300\ttotal: 27.8s\tremaining: 8.26s\n",
      "771:\tlearn: 0.1553033\ttotal: 27.9s\tremaining: 8.22s\n",
      "772:\tlearn: 0.1551298\ttotal: 27.9s\tremaining: 8.19s\n",
      "773:\tlearn: 0.1550449\ttotal: 27.9s\tremaining: 8.15s\n",
      "774:\tlearn: 0.1549529\ttotal: 27.9s\tremaining: 8.11s\n",
      "775:\tlearn: 0.1548801\ttotal: 28s\tremaining: 8.08s\n",
      "776:\tlearn: 0.1548215\ttotal: 28s\tremaining: 8.04s\n",
      "777:\tlearn: 0.1547699\ttotal: 28s\tremaining: 8s\n",
      "778:\tlearn: 0.1547000\ttotal: 28.1s\tremaining: 7.97s\n",
      "779:\tlearn: 0.1545730\ttotal: 28.1s\tremaining: 7.94s\n",
      "780:\tlearn: 0.1545472\ttotal: 28.2s\tremaining: 7.9s\n",
      "781:\tlearn: 0.1543625\ttotal: 28.2s\tremaining: 7.87s\n",
      "782:\tlearn: 0.1541662\ttotal: 28.3s\tremaining: 7.83s\n",
      "783:\tlearn: 0.1540470\ttotal: 28.3s\tremaining: 7.8s\n",
      "784:\tlearn: 0.1539259\ttotal: 28.3s\tremaining: 7.76s\n",
      "785:\tlearn: 0.1538366\ttotal: 28.4s\tremaining: 7.72s\n",
      "786:\tlearn: 0.1537333\ttotal: 28.4s\tremaining: 7.68s\n",
      "787:\tlearn: 0.1536528\ttotal: 28.4s\tremaining: 7.65s\n",
      "788:\tlearn: 0.1535531\ttotal: 28.5s\tremaining: 7.61s\n",
      "789:\tlearn: 0.1534426\ttotal: 28.5s\tremaining: 7.58s\n",
      "790:\tlearn: 0.1534090\ttotal: 28.5s\tremaining: 7.54s\n",
      "791:\tlearn: 0.1533204\ttotal: 28.6s\tremaining: 7.5s\n",
      "792:\tlearn: 0.1532179\ttotal: 28.6s\tremaining: 7.47s\n",
      "793:\tlearn: 0.1531531\ttotal: 28.7s\tremaining: 7.44s\n",
      "794:\tlearn: 0.1530197\ttotal: 28.7s\tremaining: 7.4s\n",
      "795:\tlearn: 0.1530033\ttotal: 28.7s\tremaining: 7.37s\n",
      "796:\tlearn: 0.1528685\ttotal: 28.8s\tremaining: 7.33s\n",
      "797:\tlearn: 0.1527298\ttotal: 28.8s\tremaining: 7.29s\n",
      "798:\tlearn: 0.1525287\ttotal: 28.9s\tremaining: 7.26s\n",
      "799:\tlearn: 0.1524031\ttotal: 28.9s\tremaining: 7.22s\n",
      "800:\tlearn: 0.1523312\ttotal: 28.9s\tremaining: 7.18s\n",
      "801:\tlearn: 0.1522492\ttotal: 28.9s\tremaining: 7.15s\n",
      "802:\tlearn: 0.1521429\ttotal: 29s\tremaining: 7.11s\n",
      "803:\tlearn: 0.1520100\ttotal: 29s\tremaining: 7.08s\n",
      "804:\tlearn: 0.1519060\ttotal: 29.1s\tremaining: 7.04s\n",
      "805:\tlearn: 0.1518528\ttotal: 29.1s\tremaining: 7s\n",
      "806:\tlearn: 0.1517527\ttotal: 29.1s\tremaining: 6.97s\n",
      "807:\tlearn: 0.1516434\ttotal: 29.2s\tremaining: 6.93s\n",
      "808:\tlearn: 0.1515342\ttotal: 29.2s\tremaining: 6.9s\n",
      "809:\tlearn: 0.1514773\ttotal: 29.3s\tremaining: 6.86s\n",
      "810:\tlearn: 0.1514053\ttotal: 29.3s\tremaining: 6.83s\n",
      "811:\tlearn: 0.1513214\ttotal: 29.3s\tremaining: 6.79s\n",
      "812:\tlearn: 0.1512176\ttotal: 29.4s\tremaining: 6.75s\n",
      "813:\tlearn: 0.1511097\ttotal: 29.4s\tremaining: 6.71s\n",
      "814:\tlearn: 0.1510017\ttotal: 29.4s\tremaining: 6.68s\n",
      "815:\tlearn: 0.1509364\ttotal: 29.5s\tremaining: 6.64s\n",
      "816:\tlearn: 0.1508955\ttotal: 29.5s\tremaining: 6.61s\n",
      "817:\tlearn: 0.1508735\ttotal: 29.6s\tremaining: 6.58s\n",
      "818:\tlearn: 0.1506716\ttotal: 29.6s\tremaining: 6.54s\n",
      "819:\tlearn: 0.1505094\ttotal: 29.6s\tremaining: 6.5s\n",
      "820:\tlearn: 0.1503959\ttotal: 29.7s\tremaining: 6.47s\n",
      "821:\tlearn: 0.1503119\ttotal: 29.7s\tremaining: 6.43s\n",
      "822:\tlearn: 0.1502719\ttotal: 29.7s\tremaining: 6.39s\n",
      "823:\tlearn: 0.1502208\ttotal: 29.8s\tremaining: 6.36s\n",
      "824:\tlearn: 0.1501339\ttotal: 29.8s\tremaining: 6.32s\n",
      "825:\tlearn: 0.1500715\ttotal: 29.8s\tremaining: 6.28s\n",
      "826:\tlearn: 0.1498657\ttotal: 29.9s\tremaining: 6.25s\n",
      "827:\tlearn: 0.1497550\ttotal: 29.9s\tremaining: 6.21s\n",
      "828:\tlearn: 0.1497013\ttotal: 29.9s\tremaining: 6.18s\n",
      "829:\tlearn: 0.1495278\ttotal: 30s\tremaining: 6.14s\n",
      "830:\tlearn: 0.1494448\ttotal: 30s\tremaining: 6.11s\n",
      "831:\tlearn: 0.1493234\ttotal: 30.1s\tremaining: 6.07s\n",
      "832:\tlearn: 0.1492604\ttotal: 30.1s\tremaining: 6.03s\n",
      "833:\tlearn: 0.1491632\ttotal: 30.1s\tremaining: 6s\n",
      "834:\tlearn: 0.1491259\ttotal: 30.2s\tremaining: 5.96s\n",
      "835:\tlearn: 0.1490137\ttotal: 30.2s\tremaining: 5.92s\n",
      "836:\tlearn: 0.1489083\ttotal: 30.2s\tremaining: 5.88s\n",
      "837:\tlearn: 0.1488572\ttotal: 30.3s\tremaining: 5.85s\n",
      "838:\tlearn: 0.1487139\ttotal: 30.3s\tremaining: 5.81s\n",
      "839:\tlearn: 0.1486275\ttotal: 30.3s\tremaining: 5.78s\n",
      "840:\tlearn: 0.1485632\ttotal: 30.4s\tremaining: 5.74s\n",
      "841:\tlearn: 0.1484995\ttotal: 30.4s\tremaining: 5.71s\n",
      "842:\tlearn: 0.1483784\ttotal: 30.4s\tremaining: 5.67s\n",
      "843:\tlearn: 0.1481950\ttotal: 30.5s\tremaining: 5.63s\n",
      "844:\tlearn: 0.1481444\ttotal: 30.5s\tremaining: 5.6s\n",
      "845:\tlearn: 0.1480858\ttotal: 30.6s\tremaining: 5.56s\n",
      "846:\tlearn: 0.1479715\ttotal: 30.6s\tremaining: 5.53s\n",
      "847:\tlearn: 0.1478490\ttotal: 30.6s\tremaining: 5.49s\n",
      "848:\tlearn: 0.1477851\ttotal: 30.7s\tremaining: 5.45s\n",
      "849:\tlearn: 0.1477146\ttotal: 30.7s\tremaining: 5.42s\n",
      "850:\tlearn: 0.1476313\ttotal: 30.7s\tremaining: 5.38s\n",
      "851:\tlearn: 0.1474677\ttotal: 30.8s\tremaining: 5.34s\n",
      "852:\tlearn: 0.1473953\ttotal: 30.8s\tremaining: 5.31s\n",
      "853:\tlearn: 0.1473219\ttotal: 30.8s\tremaining: 5.27s\n",
      "854:\tlearn: 0.1472518\ttotal: 30.9s\tremaining: 5.24s\n",
      "855:\tlearn: 0.1470014\ttotal: 30.9s\tremaining: 5.2s\n",
      "856:\tlearn: 0.1468182\ttotal: 31s\tremaining: 5.17s\n",
      "857:\tlearn: 0.1467327\ttotal: 31s\tremaining: 5.13s\n",
      "858:\tlearn: 0.1467001\ttotal: 31s\tremaining: 5.09s\n",
      "859:\tlearn: 0.1466166\ttotal: 31.1s\tremaining: 5.06s\n",
      "860:\tlearn: 0.1464949\ttotal: 31.1s\tremaining: 5.02s\n",
      "861:\tlearn: 0.1463915\ttotal: 31.1s\tremaining: 4.98s\n",
      "862:\tlearn: 0.1463357\ttotal: 31.2s\tremaining: 4.95s\n",
      "863:\tlearn: 0.1462397\ttotal: 31.2s\tremaining: 4.91s\n",
      "864:\tlearn: 0.1461704\ttotal: 31.2s\tremaining: 4.87s\n",
      "865:\tlearn: 0.1460367\ttotal: 31.3s\tremaining: 4.84s\n",
      "866:\tlearn: 0.1458755\ttotal: 31.3s\tremaining: 4.8s\n",
      "867:\tlearn: 0.1458500\ttotal: 31.4s\tremaining: 4.77s\n",
      "868:\tlearn: 0.1457437\ttotal: 31.4s\tremaining: 4.73s\n",
      "869:\tlearn: 0.1457007\ttotal: 31.4s\tremaining: 4.7s\n",
      "870:\tlearn: 0.1456251\ttotal: 31.5s\tremaining: 4.66s\n",
      "871:\tlearn: 0.1455638\ttotal: 31.5s\tremaining: 4.63s\n",
      "872:\tlearn: 0.1455018\ttotal: 31.5s\tremaining: 4.59s\n",
      "873:\tlearn: 0.1453261\ttotal: 31.6s\tremaining: 4.55s\n",
      "874:\tlearn: 0.1452390\ttotal: 31.6s\tremaining: 4.52s\n",
      "875:\tlearn: 0.1451868\ttotal: 31.6s\tremaining: 4.48s\n",
      "876:\tlearn: 0.1450964\ttotal: 31.7s\tremaining: 4.44s\n",
      "877:\tlearn: 0.1449670\ttotal: 31.7s\tremaining: 4.41s\n",
      "878:\tlearn: 0.1448500\ttotal: 31.8s\tremaining: 4.37s\n",
      "879:\tlearn: 0.1447114\ttotal: 31.8s\tremaining: 4.34s\n",
      "880:\tlearn: 0.1446259\ttotal: 31.8s\tremaining: 4.3s\n",
      "881:\tlearn: 0.1445630\ttotal: 31.9s\tremaining: 4.26s\n",
      "882:\tlearn: 0.1443908\ttotal: 31.9s\tremaining: 4.23s\n",
      "883:\tlearn: 0.1443206\ttotal: 32s\tremaining: 4.19s\n",
      "884:\tlearn: 0.1442609\ttotal: 32s\tremaining: 4.16s\n",
      "885:\tlearn: 0.1441625\ttotal: 32s\tremaining: 4.12s\n",
      "886:\tlearn: 0.1441153\ttotal: 32.1s\tremaining: 4.08s\n",
      "887:\tlearn: 0.1440193\ttotal: 32.1s\tremaining: 4.05s\n",
      "888:\tlearn: 0.1438339\ttotal: 32.1s\tremaining: 4.01s\n",
      "889:\tlearn: 0.1437561\ttotal: 32.2s\tremaining: 3.97s\n",
      "890:\tlearn: 0.1436214\ttotal: 32.2s\tremaining: 3.94s\n",
      "891:\tlearn: 0.1434983\ttotal: 32.2s\tremaining: 3.9s\n",
      "892:\tlearn: 0.1434170\ttotal: 32.3s\tremaining: 3.87s\n",
      "893:\tlearn: 0.1433545\ttotal: 32.3s\tremaining: 3.83s\n",
      "894:\tlearn: 0.1432522\ttotal: 32.4s\tremaining: 3.8s\n",
      "895:\tlearn: 0.1431945\ttotal: 32.4s\tremaining: 3.76s\n",
      "896:\tlearn: 0.1431070\ttotal: 32.4s\tremaining: 3.73s\n",
      "897:\tlearn: 0.1429886\ttotal: 32.5s\tremaining: 3.69s\n",
      "898:\tlearn: 0.1429127\ttotal: 32.5s\tremaining: 3.65s\n",
      "899:\tlearn: 0.1428712\ttotal: 32.5s\tremaining: 3.62s\n",
      "900:\tlearn: 0.1428110\ttotal: 32.6s\tremaining: 3.58s\n",
      "901:\tlearn: 0.1426976\ttotal: 32.6s\tremaining: 3.54s\n",
      "902:\tlearn: 0.1425516\ttotal: 32.7s\tremaining: 3.51s\n",
      "903:\tlearn: 0.1424836\ttotal: 32.7s\tremaining: 3.47s\n",
      "904:\tlearn: 0.1423780\ttotal: 32.7s\tremaining: 3.44s\n",
      "905:\tlearn: 0.1423188\ttotal: 32.8s\tremaining: 3.4s\n",
      "906:\tlearn: 0.1422524\ttotal: 32.8s\tremaining: 3.36s\n",
      "907:\tlearn: 0.1421854\ttotal: 32.8s\tremaining: 3.33s\n",
      "908:\tlearn: 0.1420992\ttotal: 32.9s\tremaining: 3.29s\n",
      "909:\tlearn: 0.1420224\ttotal: 32.9s\tremaining: 3.25s\n",
      "910:\tlearn: 0.1419756\ttotal: 32.9s\tremaining: 3.22s\n",
      "911:\tlearn: 0.1419013\ttotal: 33s\tremaining: 3.18s\n",
      "912:\tlearn: 0.1418665\ttotal: 33s\tremaining: 3.15s\n",
      "913:\tlearn: 0.1417191\ttotal: 33s\tremaining: 3.11s\n",
      "914:\tlearn: 0.1416938\ttotal: 33.1s\tremaining: 3.07s\n",
      "915:\tlearn: 0.1416334\ttotal: 33.1s\tremaining: 3.04s\n",
      "916:\tlearn: 0.1415012\ttotal: 33.2s\tremaining: 3s\n",
      "917:\tlearn: 0.1413978\ttotal: 33.2s\tremaining: 2.96s\n",
      "918:\tlearn: 0.1413223\ttotal: 33.2s\tremaining: 2.93s\n",
      "919:\tlearn: 0.1412533\ttotal: 33.3s\tremaining: 2.89s\n",
      "920:\tlearn: 0.1411928\ttotal: 33.3s\tremaining: 2.86s\n",
      "921:\tlearn: 0.1411088\ttotal: 33.3s\tremaining: 2.82s\n",
      "922:\tlearn: 0.1410095\ttotal: 33.4s\tremaining: 2.78s\n",
      "923:\tlearn: 0.1409067\ttotal: 33.4s\tremaining: 2.75s\n",
      "924:\tlearn: 0.1408212\ttotal: 33.4s\tremaining: 2.71s\n",
      "925:\tlearn: 0.1407327\ttotal: 33.5s\tremaining: 2.67s\n",
      "926:\tlearn: 0.1406435\ttotal: 33.5s\tremaining: 2.64s\n",
      "927:\tlearn: 0.1405645\ttotal: 33.5s\tremaining: 2.6s\n",
      "928:\tlearn: 0.1404735\ttotal: 33.6s\tremaining: 2.57s\n",
      "929:\tlearn: 0.1404327\ttotal: 33.6s\tremaining: 2.53s\n",
      "930:\tlearn: 0.1403109\ttotal: 33.7s\tremaining: 2.5s\n",
      "931:\tlearn: 0.1402108\ttotal: 33.7s\tremaining: 2.46s\n",
      "932:\tlearn: 0.1400651\ttotal: 33.8s\tremaining: 2.42s\n",
      "933:\tlearn: 0.1400047\ttotal: 33.8s\tremaining: 2.39s\n",
      "934:\tlearn: 0.1399457\ttotal: 33.8s\tremaining: 2.35s\n",
      "935:\tlearn: 0.1399237\ttotal: 33.9s\tremaining: 2.31s\n",
      "936:\tlearn: 0.1398397\ttotal: 33.9s\tremaining: 2.28s\n",
      "937:\tlearn: 0.1397952\ttotal: 33.9s\tremaining: 2.24s\n",
      "938:\tlearn: 0.1397019\ttotal: 34s\tremaining: 2.21s\n",
      "939:\tlearn: 0.1396288\ttotal: 34s\tremaining: 2.17s\n",
      "940:\tlearn: 0.1395569\ttotal: 34s\tremaining: 2.13s\n",
      "941:\tlearn: 0.1395205\ttotal: 34.1s\tremaining: 2.1s\n",
      "942:\tlearn: 0.1394593\ttotal: 34.1s\tremaining: 2.06s\n",
      "943:\tlearn: 0.1393555\ttotal: 34.2s\tremaining: 2.03s\n",
      "944:\tlearn: 0.1392238\ttotal: 34.2s\tremaining: 1.99s\n",
      "945:\tlearn: 0.1391843\ttotal: 34.2s\tremaining: 1.95s\n",
      "946:\tlearn: 0.1391189\ttotal: 34.3s\tremaining: 1.92s\n",
      "947:\tlearn: 0.1390313\ttotal: 34.3s\tremaining: 1.88s\n",
      "948:\tlearn: 0.1389280\ttotal: 34.3s\tremaining: 1.84s\n",
      "949:\tlearn: 0.1387751\ttotal: 34.4s\tremaining: 1.81s\n",
      "950:\tlearn: 0.1387098\ttotal: 34.4s\tremaining: 1.77s\n",
      "951:\tlearn: 0.1386082\ttotal: 34.4s\tremaining: 1.74s\n",
      "952:\tlearn: 0.1385250\ttotal: 34.5s\tremaining: 1.7s\n",
      "953:\tlearn: 0.1384198\ttotal: 34.5s\tremaining: 1.66s\n",
      "954:\tlearn: 0.1383363\ttotal: 34.6s\tremaining: 1.63s\n",
      "955:\tlearn: 0.1382374\ttotal: 34.6s\tremaining: 1.59s\n",
      "956:\tlearn: 0.1381447\ttotal: 34.6s\tremaining: 1.56s\n",
      "957:\tlearn: 0.1380832\ttotal: 34.7s\tremaining: 1.52s\n",
      "958:\tlearn: 0.1379957\ttotal: 34.7s\tremaining: 1.48s\n",
      "959:\tlearn: 0.1379107\ttotal: 34.8s\tremaining: 1.45s\n",
      "960:\tlearn: 0.1377613\ttotal: 34.8s\tremaining: 1.41s\n",
      "961:\tlearn: 0.1376667\ttotal: 34.8s\tremaining: 1.38s\n",
      "962:\tlearn: 0.1375878\ttotal: 34.9s\tremaining: 1.34s\n",
      "963:\tlearn: 0.1374805\ttotal: 34.9s\tremaining: 1.3s\n",
      "964:\tlearn: 0.1373249\ttotal: 34.9s\tremaining: 1.27s\n",
      "965:\tlearn: 0.1372362\ttotal: 35s\tremaining: 1.23s\n",
      "966:\tlearn: 0.1371578\ttotal: 35s\tremaining: 1.2s\n",
      "967:\tlearn: 0.1371065\ttotal: 35.1s\tremaining: 1.16s\n",
      "968:\tlearn: 0.1369908\ttotal: 35.1s\tremaining: 1.12s\n",
      "969:\tlearn: 0.1368745\ttotal: 35.1s\tremaining: 1.09s\n",
      "970:\tlearn: 0.1367884\ttotal: 35.2s\tremaining: 1.05s\n",
      "971:\tlearn: 0.1367160\ttotal: 35.2s\tremaining: 1.01s\n",
      "972:\tlearn: 0.1366324\ttotal: 35.2s\tremaining: 978ms\n",
      "973:\tlearn: 0.1365756\ttotal: 35.3s\tremaining: 942ms\n",
      "974:\tlearn: 0.1365396\ttotal: 35.3s\tremaining: 905ms\n",
      "975:\tlearn: 0.1364079\ttotal: 35.3s\tremaining: 869ms\n",
      "976:\tlearn: 0.1363563\ttotal: 35.4s\tremaining: 833ms\n",
      "977:\tlearn: 0.1362589\ttotal: 35.4s\tremaining: 797ms\n",
      "978:\tlearn: 0.1361691\ttotal: 35.5s\tremaining: 760ms\n",
      "979:\tlearn: 0.1361229\ttotal: 35.5s\tremaining: 724ms\n",
      "980:\tlearn: 0.1360850\ttotal: 35.5s\tremaining: 688ms\n",
      "981:\tlearn: 0.1359829\ttotal: 35.6s\tremaining: 652ms\n",
      "982:\tlearn: 0.1359095\ttotal: 35.6s\tremaining: 616ms\n",
      "983:\tlearn: 0.1358241\ttotal: 35.6s\tremaining: 580ms\n",
      "984:\tlearn: 0.1357742\ttotal: 35.7s\tremaining: 543ms\n",
      "985:\tlearn: 0.1356652\ttotal: 35.7s\tremaining: 507ms\n",
      "986:\tlearn: 0.1355958\ttotal: 35.8s\tremaining: 471ms\n",
      "987:\tlearn: 0.1355691\ttotal: 35.8s\tremaining: 435ms\n",
      "988:\tlearn: 0.1354056\ttotal: 35.8s\tremaining: 398ms\n",
      "989:\tlearn: 0.1353427\ttotal: 35.9s\tremaining: 362ms\n",
      "990:\tlearn: 0.1352796\ttotal: 35.9s\tremaining: 326ms\n",
      "991:\tlearn: 0.1351667\ttotal: 35.9s\tremaining: 290ms\n",
      "992:\tlearn: 0.1351152\ttotal: 36s\tremaining: 254ms\n",
      "993:\tlearn: 0.1350645\ttotal: 36s\tremaining: 217ms\n",
      "994:\tlearn: 0.1349521\ttotal: 36s\tremaining: 181ms\n",
      "995:\tlearn: 0.1349026\ttotal: 36.1s\tremaining: 145ms\n",
      "996:\tlearn: 0.1348037\ttotal: 36.1s\tremaining: 109ms\n",
      "997:\tlearn: 0.1347249\ttotal: 36.2s\tremaining: 72.5ms\n",
      "998:\tlearn: 0.1346588\ttotal: 36.2s\tremaining: 36.2ms\n",
      "999:\tlearn: 0.1346076\ttotal: 36.2s\tremaining: 0us\n",
      "CatBoost with k-fold Cross-Validation Completed :)  \n",
      "******************************\n",
      "Epoch 1/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4666 - loss: 1.5887 - val_accuracy: 0.6226 - val_loss: 1.1228\n",
      "Epoch 2/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6084 - loss: 1.0845 - val_accuracy: 0.6256 - val_loss: 1.0260\n",
      "Epoch 3/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6391 - loss: 0.9850 - val_accuracy: 0.6572 - val_loss: 0.9558\n",
      "Epoch 4/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6646 - loss: 0.9267 - val_accuracy: 0.7030 - val_loss: 0.9009\n",
      "Epoch 5/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7033 - loss: 0.8593 - val_accuracy: 0.7055 - val_loss: 0.8205\n",
      "Epoch 6/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.7967 - val_accuracy: 0.7472 - val_loss: 0.7682\n",
      "Epoch 7/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7567 - loss: 0.7425 - val_accuracy: 0.7659 - val_loss: 0.7181\n",
      "Epoch 8/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7708 - loss: 0.6989 - val_accuracy: 0.7733 - val_loss: 0.6829\n",
      "Epoch 9/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7841 - loss: 0.6618 - val_accuracy: 0.7851 - val_loss: 0.6627\n",
      "Epoch 10/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7925 - loss: 0.6432 - val_accuracy: 0.7939 - val_loss: 0.6403\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4328 - loss: 1.6115 - val_accuracy: 0.6171 - val_loss: 1.1136\n",
      "Epoch 2/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6179 - loss: 1.0582 - val_accuracy: 0.6278 - val_loss: 1.0147\n",
      "Epoch 3/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6450 - loss: 0.9883 - val_accuracy: 0.6629 - val_loss: 0.9325\n",
      "Epoch 4/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6877 - loss: 0.8926 - val_accuracy: 0.7326 - val_loss: 0.8410\n",
      "Epoch 5/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7379 - loss: 0.7938 - val_accuracy: 0.7590 - val_loss: 0.7619\n",
      "Epoch 6/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7709 - loss: 0.7224 - val_accuracy: 0.7842 - val_loss: 0.7108\n",
      "Epoch 7/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7711 - loss: 0.7036 - val_accuracy: 0.7922 - val_loss: 0.6795\n",
      "Epoch 8/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7756 - loss: 0.6740 - val_accuracy: 0.7713 - val_loss: 0.6610\n",
      "Epoch 9/10\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7908 - loss: 0.6308 - val_accuracy: 0.7928 - val_loss: 0.6392\n",
      "Epoch 10/10\n",
      "\u001b[1m406/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7876 - loss: 0.6257"
     ]
    }
   ],
   "source": [
    "n_splits_for_cv = 5 #Dont Change \n",
    "## **Importing Modules and Libraries**\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "start_time_1 = datetime.datetime.now()\n",
    "\n",
    "\n",
    "# Get the current time in the desired format\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(start_time_1)\n",
    "print(timestamp)\n",
    "# Generate the filename with the timestamp\n",
    "log_filename = f\"errors_{timestamp}.txt\"\n",
    "print(log_filename)\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename=log_filename, level=logging.ERROR, filemode='a')\n",
    "\n",
    "import os\n",
    "# Suppress TensorFlow GPU-related warnings\n",
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from os import path\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten , Activation, SimpleRNN, LSTM, GRU, Dropout, TimeDistributed, Reshape, Input, Lambda, Add\n",
    "from keras import Sequential\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "import sklearn.discriminant_analysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "import skfuzzy as fuzz\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from keras.utils import to_categorical\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report, multilabel_confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier, StackingClassifier, AdaBoostClassifier, HistGradientBoostingClassifier, IsolationForest, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, PassiveAggressiveClassifier, RidgeClassifier, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.neural_network import MLPClassifier, BernoulliRBM\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import skfuzzy as fuzz\n",
    "from pgmpy.estimators import TreeSearch\n",
    "\n",
    "from hmmlearn import hmm\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Activation, SimpleRNN, LSTM, GRU, Dropout, TimeDistributed, Reshape, Input, Lambda, Add\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pgmpy.models import BayesianModel\n",
    "from pomegranate import *\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.models import JunctionTree\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from catboost import CatBoostClassifier\n",
    "import tensorflow as tf\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import ExpectationMaximization\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.datasets import make_classification\n",
    "from pgmpy.models import MarkovModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\"\"\"## **Importing Datasets**\"\"\"\n",
    "\n",
    "# dont change this\n",
    "method = \"UNSW_NB_15_TSA_SMOTE_ENN\"\n",
    "method = method + \"_k_fold_5_Metrics\"\n",
    "\n",
    "train_data = pd.read_csv('UNSW_NB_15_TSA_SMOTE_ENN.csv')\n",
    "test_data = pd.read_csv('UNSW_NB_15_TSA_test.csv')\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "# **MULTI-CLASS CLASSIFICATION**\n",
    "## **Data Splitting**\n",
    "X_train = train_data.drop(columns=['label'],axis=1)\n",
    "X_test = test_data.drop(columns=['label'],axis=1)\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']\n",
    "X_train = pd.concat([X_train, X_test], axis=0)\n",
    "y_train = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "fname = method + \"_output.csv\"\n",
    "outfile = open(fname, 'w')\n",
    "outfile.write(\"algo vs matrices,time to train(sec),time to predict(sec),accuracy_score,precision_score,recall_score,f1_score,fbeta_score,matthews_corrcoef,jaccard_score,cohen_kappa_score,hamming_loss,zero_one_loss,mean_absolute_error,mean_squared_error,mean_squared_error,balanced_accuracy_score,explained_variance_score\\n\")\n",
    "def format_decimal(number):\n",
    "    return f\"{number:.{3}f}\"\n",
    "def result(y_pred,y_test,algo,time_to_predict,time_to_train):\n",
    "    outfile.write(algo+\",\")\n",
    "    outfile.write(str(format_decimal(time_to_train))+\",\")\n",
    "    outfile.write(str(format_decimal(time_to_predict))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.accuracy_score(y_test,y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.precision_score(y_test, y_pred, average='weighted')))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.recall_score(y_test, y_pred, average='weighted')))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.f1_score(y_test, y_pred, average='weighted')))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.fbeta_score(y_test, y_pred,average='weighted', beta=0.5)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.matthews_corrcoef(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.jaccard_score(y_test, y_pred, average='weighted')))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.cohen_kappa_score(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.hamming_loss(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.zero_one_loss(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.mean_absolute_error(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.mean_squared_error(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.balanced_accuracy_score(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.explained_variance_score(y_test, y_pred)*100))+\"\\n\")\n",
    "\n",
    "#X_train,temp1,y_train,temp2 = train_test_split(X_train,y_train,train_size=0.1,random_state=7)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "# Initialize Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits= n_splits_for_cv, random_state=47, shuffle=True)\n",
    "\n",
    " \n",
    " \n",
    " \n",
    "def separator(algo=\"temp\"):\n",
    "    with open(\"errors.txt\", \"a\") as file:\n",
    "        #file.write(datetime.now().strftime(\"%d %b %Y %H:%M\"))\n",
    "        file.write(\"\\n\\n*********\\n\\n\")\n",
    "    outfile.write(algo.strip()+ \" \" + \"erroralgo,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **1.Decision Tree**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test = []\n",
    "    all_y_pred = []\n",
    "    start_cv = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train = 0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Decision Tree Classifier for this fold\n",
    "        dt_multi = DecisionTreeClassifier(random_state=24)\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fit the model\n",
    "        start_train = time.time()\n",
    "        dt_multi.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train - start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = dt_multi.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict +=  end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test.extend(y_test_fold)\n",
    "        all_y_pred.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = multilabel_confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix\")\n",
    "        i = str(fold_number)\n",
    "        pname = method + \"_fold_\"+ i + \"_Decision_Tree_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv = time.time()\n",
    "    result(all_y_pred, all_y_test, \"DT\", time_to_train, time_to_predict)\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Decison Tree Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Decison Tree\")\n",
    "\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **2.Linear Regression**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_lr = []\n",
    "    all_y_pred_lr = []\n",
    "    start_cv_lr = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train = 0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Linear Regression model for this fold\n",
    "        lr_multi = LinearRegression()\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fit the model\n",
    "        start_train = time.time()\n",
    "        lr_multi.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train+=end_train - start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = lr_multi.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict +=  end_predict - start_predict\n",
    "        for i in range(len(y_pred_fold)):\n",
    "            y_pred_fold[i] = int(np.round_(y_pred_fold[i]))\n",
    "        # Append metrics to lists\n",
    "        all_y_test_lr.extend(y_test_fold)\n",
    "        all_y_pred_lr.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Linear Regression\")\n",
    "        pname = method + \"_fold_\"+ str(fold_number) + \"_Linear_Regression_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_lr = time.time()\n",
    "    result(all_y_pred_lr, all_y_test_lr, \"Linear Regression\", time_to_train, time_to_predict)\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Linear Regression Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Linear Regression\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **3.Logistic Regression**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_logreg = []\n",
    "    all_y_pred_logreg = []\n",
    "    start_cv_logreg = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train  = 0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Logistic Regression model for this fold\n",
    "        logreg_multi =LogisticRegression(random_state=123, max_iter=5000,solver='newton-cg',multi_class='multinomial')\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fit the model\n",
    "        start_train = time.time()\n",
    "        logreg_multi.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train - start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = logreg_multi.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict +=  end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_logreg.extend(y_test_fold)\n",
    "        all_y_pred_logreg.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Logistic Regression\")\n",
    "        pname = method + \"_fold_\"+ str(fold_number) + \"_Logistic_Regression_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_logreg = time.time()\n",
    "    result(all_y_pred_logreg, all_y_test_logreg, \"Logistic Regression\", time_to_train, time_to_predict)\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"LogisticRegression Completed :) \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"LogisticRegression\")\n",
    "\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **4.K Nearest Neighbor Classifier**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_knn = []\n",
    "    all_y_pred_knn = []\n",
    "    start_cv_knn = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train = 0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize KNN model for this fold\n",
    "        knn = KNeighborsClassifier(8)\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fit the model\n",
    "        start_train = time.time()\n",
    "        knn.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train - start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = knn.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_knn.extend(y_test_fold)\n",
    "        all_y_pred_knn.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - KNN\")\n",
    "        pname = method + \"_fold_\"+ str(fold_number) + \"_KNN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_knn = time.time()\n",
    "    result(all_y_pred_knn, all_y_test_knn, \"KNN\", time_to_train, time_to_predict)\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"KNN Completed :) \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"KNN\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **5.Random Forest Classifier**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_rf = []\n",
    "    all_y_pred_rf = []\n",
    "    start_cv_rf = time.time()\n",
    "    time_to_predict=0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Random Forest model for this fold\n",
    "        rf = RandomForestClassifier(random_state=24)\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fit the model\n",
    "        start_train = time.time()\n",
    "        rf.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = rf.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict += end_predict -start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_rf.extend(y_test_fold)\n",
    "        all_y_pred_rf.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Random Forest\")\n",
    "        pname = method + \"_fold_\"+ str(fold_number) + \"_Random_Forest_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_rf = time.time()\n",
    "    result(all_y_pred_rf, all_y_test_rf, \"Random Forest\", time_to_train, time_to_predict)\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Random forest Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Random forest\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **6.Multi Layer Perceptron**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_mlp = []\n",
    "    all_y_pred_mlp = []\n",
    "    start_cv_mlp = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize MLP model for this fold\n",
    "        mlp = MLPClassifier(random_state=24)\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fit the model\n",
    "        start_train = time.time()\n",
    "        mlp.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = mlp.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_mlp.extend(y_test_fold)\n",
    "        all_y_pred_mlp.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - MLP\")\n",
    "        pname = method + \"_fold_\"+ str(fold_number) + \"_MLP_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_mlp = time.time()\n",
    "    result(all_y_pred_mlp, all_y_test_mlp, \"MLP\", time_to_train, time_to_predict)\n",
    "\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"MLP Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"MLP\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **7.Bagging**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_bagging = []\n",
    "    all_y_pred_bagging = []\n",
    "    start_cv_bagging = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Create a base classifier (Decision Tree)\n",
    "        base_classifier = DecisionTreeClassifier(random_state=42)\n",
    "        # Create a bagging classifier\n",
    "        bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the bagging classifier\n",
    "        start_train = time.time()\n",
    "        bagging_classifier.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = bagging_classifier.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict += end_predict-start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_bagging.extend(y_test_fold)\n",
    "        all_y_pred_bagging.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Bagging\")\n",
    "        pname = method + \"_fold_\"+ str(fold_number) + \"_Bagging_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_bagging = time.time()\n",
    "    result(all_y_pred_bagging, all_y_test_bagging, \"Bagging\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Bagging Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Bagging\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **8. J48 (C4.5)**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_j48 = []\n",
    "    all_y_pred_j48 = []\n",
    "    start_cv_j48 = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize J48 (C4.5) classifier\n",
    "        classifier_j48 = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the J48 (C4.5) classifier\n",
    "        start_train = time.time()\n",
    "        classifier_j48.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = classifier_j48.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_j48.extend(y_test_fold)\n",
    "        all_y_pred_j48.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - J48 (C4.5)\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_J48_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_j48 = time.time()\n",
    "    result(all_y_pred_j48, all_y_test_j48, \"J48\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"J48 Completed :) \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"J48\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **9. ANN**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_ann = []\n",
    "    all_y_pred_ann = []\n",
    "    start_cv_ann = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize ANN model\n",
    "        multi_ann = Sequential()\n",
    "        # Adding the input layer and the first hidden layer\n",
    "        multi_ann.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=X_train.shape[1]))\n",
    "        # Adding the second hidden layer\n",
    "        multi_ann.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
    "        # Adding the output layer\n",
    "        multi_ann.add(Dense(units=10, kernel_initializer='uniform', activation='softmax'))\n",
    "        # Compiling the ANN\n",
    "        multi_ann.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fitting the ANN to the Training set\n",
    "        start_train = time.time()\n",
    "        history = multi_ann.fit(X_train_fold, y_train_fold, epochs=10, batch_size=50, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = np.argmax(multi_ann.predict(X_test_fold), axis=1)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_ann.extend(y_test_fold)\n",
    "        all_y_pred_ann.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - ANN\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_ANN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_ann = time.time()\n",
    "    result(all_y_pred_ann, all_y_test_ann, \"ANN\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"ANN Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"ANN\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **10. DNN**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_dnn = []\n",
    "    all_y_pred_dnn = []\n",
    "    start_cv_dnn = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize DNN model\n",
    "        multi_dnn = Sequential()\n",
    "        # Adding the input layer and the first hidden layer\n",
    "        multi_dnn.add(Dense(units=19, kernel_initializer='uniform', activation='relu', input_dim=X_train.shape[1]))\n",
    "        # Adding the second hidden layer\n",
    "        multi_dnn.add(Dense(units=19, kernel_initializer='uniform', activation='relu'))\n",
    "        # Adding the third hidden layer\n",
    "        multi_dnn.add(Dense(units=19, kernel_initializer='uniform', activation='relu'))\n",
    "        # Adding the output layer\n",
    "        multi_dnn.add(Dense(units=10, kernel_initializer='uniform', activation='softmax'))\n",
    "        # Compiling the DNN\n",
    "        multi_dnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fitting the DNN to the Training set\n",
    "        start_train = time.time()\n",
    "        history = multi_dnn.fit(X_train_fold, y_train_fold, epochs=10, batch_size=50, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = np.argmax(multi_dnn.predict(X_test_fold), axis=1)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_dnn.extend(y_test_fold)\n",
    "        all_y_pred_dnn.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - DNN\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_DNN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_dnn = time.time()\n",
    "    result(all_y_pred_dnn, all_y_test_dnn, \"DNN\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"DNN Completed :) \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"DNN\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **12. Gradient Boosting Classifier with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gb = []\n",
    "    all_y_pred_gb = []\n",
    "    start_cv_gb = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Gradient Boosting Classifier\n",
    "        multi_gb = GradientBoostingClassifier()\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        multi_gb.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = multi_gb.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gb.extend(y_test_fold)\n",
    "        all_y_pred_gb.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Gradient Boosting\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_GradientBoostingClassifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_gb = time.time()\n",
    "    result(all_y_pred_gb, all_y_test_gb, \"Gradient Boosting\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"GradientBoostingClassifier Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"GradientBoostingClassifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## ** 13 XGBoost Classifier**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_xgb = []\n",
    "    all_y_pred_xgb = []\n",
    "    start_cv_xgb = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize XGBoost Classifier\n",
    "        xgb_model = XGBClassifier()\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        xgb_model.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = xgb_model.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_xgb.extend(y_test_fold)\n",
    "        all_y_pred_xgb.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - XGBoost\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_XGBClassifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_xgb = time.time()\n",
    "    result(all_y_pred_xgb, all_y_test_xgb, \"XGBoost\", time_to_train, time_to_predict)\n",
    "\n",
    "    #plt.show()\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"XGBClassifier Completed :) \")\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"XGBClassifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **14. Gaussian Naive Bayes**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_nb = []\n",
    "    all_y_pred_nb = []\n",
    "    start_cv_nb = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Gaussian Naive Bayes model\n",
    "        NB_model = GaussianNB()\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        NB_model.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = NB_model.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_nb.extend(y_test_fold)\n",
    "        all_y_pred_nb.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Gaussian Naive Bayes\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_Gaussian_Naive_Bayes_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_nb = time.time()\n",
    "    result(all_y_pred_nb, all_y_test_nb, \"Gaussian Naive Bayes\", time_to_train, time_to_predict)\n",
    "    #plt.show()\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Gaussian_Naive_Bayes Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Gaussian_Naive_Bayes\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **15. Adaptive Gradient Boosting**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_ab = []\n",
    "    all_y_pred_ab = []\n",
    "    start_cv_ab = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Adaptive Gradient Boosting model\n",
    "        weak_learner = DecisionTreeClassifier(max_leaf_nodes=8)\n",
    "        n_estimators = 300\n",
    "        AB_model = AdaBoostClassifier(\n",
    "            estimator=weak_learner,\n",
    "            n_estimators=n_estimators,\n",
    "            algorithm=\"SAMME\",\n",
    "            random_state=42,\n",
    "        )\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        AB_model.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = AB_model.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_ab.extend(y_test_fold)\n",
    "        all_y_pred_ab.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Adaptive Gradient Boosting\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_Adaptive_Gradient_Boosting_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_ab = time.time()\n",
    "    result(all_y_pred_ab, all_y_test_ab, \"Adaptive Gradient Boosting\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Adaptive Gradient Boosting Completed :) \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Adaptive Gradient Boosting\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **16. Quadratic Discriminant Analysis (QDA)**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_qda = []\n",
    "    all_y_pred_qda = []\n",
    "    start_cv_qda = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Quadratic Discriminant Analysis (QDA) model\n",
    "        qda_multi = QuadraticDiscriminantAnalysis()\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        qda_multi.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = qda_multi.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_qda.extend(y_test_fold)\n",
    "        all_y_pred_qda.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Quadratic Discriminant Analysis (QDA)\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_QDA_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_qda = time.time()\n",
    "    result(all_y_pred_qda, all_y_test_qda, \"QDA\", time_to_train, time_to_predict)\n",
    "    #plt.show()\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"QDA Completed :) \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"QDA\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **17. Shallow Neural Network (SNN)**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_snn = []\n",
    "    all_y_pred_snn = []\n",
    "    start_cv_snn = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        num_classes =  len(np.unique(y_train))\n",
    "        # Initialize Shallow Neural Network (SNN) model\n",
    "        snn_multi = Sequential()\n",
    "        snn_multi.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "        snn_multi.add(Dense(32, activation='relu'))\n",
    "        snn_multi.add(Dense(20, activation='relu'))\n",
    "        snn_multi.add(Dense(num_classes, activation='softmax'))\n",
    "        snn_multi.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        history = snn_multi.fit(X_train_fold, y_train_fold, epochs=10, batch_size=50, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = np.argmax(snn_multi.predict(X_test_fold), axis=1)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_snn.extend(y_test_fold)\n",
    "        all_y_pred_snn.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Shallow Neural Network (SNN)\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_SNN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_snn = time.time()\n",
    "    result(all_y_pred_snn, all_y_test_snn, \"SNN\", time_to_train, time_to_predict)\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"SNN Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"snn\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **18. Restricted Boltzmann Machine (RBM)**\n",
    "    # Define the RBM class\n",
    "    class RBM(tf.keras.layers.Layer):\n",
    "        def __init__(self, hidden_dim, name=\"rbm\", **kwargs):\n",
    "            super(RBM, self).__init__(name=name, **kwargs)\n",
    "            self.hidden_dim = hidden_dim\n",
    "        def build(self, input_shape):\n",
    "            self.W = self.add_weight(shape=(input_shape[-1], self.hidden_dim), initializer='uniform', trainable=True, name='weights')\n",
    "            self.h_bias = self.add_weight(shape=(self.hidden_dim,), initializer='zeros', trainable=True, name='h_bias')\n",
    "            self.v_bias = self.add_weight(shape=(input_shape[-1],), initializer='zeros', trainable=True, name='v_bias')\n",
    "        def call(self, inputs):\n",
    "            hidden_prob = tf.nn.sigmoid(tf.matmul(inputs, self.W) + self.h_bias)\n",
    "            hidden_state = self._sample_prob(hidden_prob)\n",
    "            visible_prob = tf.nn.sigmoid(tf.matmul(hidden_state, tf.transpose(self.W)) + self.v_bias)\n",
    "            return visible_prob, hidden_state\n",
    "        def _sample_prob(self, probs):\n",
    "            return tf.nn.relu(tf.sign(probs - tf.random.uniform(tf.shape(probs))))\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_rbm = []\n",
    "    all_y_pred_rbm = []\n",
    "    start_cv_rbm = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        num_classes = len(np.unique(y_train))\n",
    "        input_data = Input(shape=(X_train.shape[1],))\n",
    "        rbm1_visible, rbm1_hidden = RBM(hidden_dim=128, name=f\"rbm1_fold_{fold_number}\")(input_data)\n",
    "        rbm2_visible, rbm2_hidden = RBM(hidden_dim=64, name=f\"rbm2_fold_{fold_number}\")(rbm1_hidden)\n",
    "        rbm3_visible, rbm3_hidden = RBM(hidden_dim=32, name=f\"rbm3_fold_{fold_number}\")(rbm2_hidden)\n",
    "        rbm6_visible, rbm6_hidden = RBM(hidden_dim=64, name=f\"rbm6_fold_{fold_number}\")(rbm3_hidden)\n",
    "        classifier_output = Dense(num_classes, activation='softmax', name=f'classifier_fold_{fold_number}')(rbm6_hidden)\n",
    "        model = tf.keras.Model(inputs=input_data, outputs=classifier_output)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=50, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = np.argmax(model.predict(X_test_fold), axis=1)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_rbm.extend(y_test_fold)\n",
    "        all_y_pred_rbm.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Restricted Boltzmann Machine (RBM)\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_RBM_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_rbm = time.time()\n",
    "    result(all_y_pred_rbm, all_y_test_rbm, \"RBM\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"RBM Completed :)  \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"RBM\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **19. LSTM**\n",
    "\n",
    "    # reloading as many transformations on X,Y causing errors for lstm code\n",
    "\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_lstm = []\n",
    "    all_y_pred_lstm = []\n",
    "    start_cv_lstm = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        num_classes = len(np.unique(y_train))\n",
    "\n",
    "        # Convert DataFrame to NumPy array and reshape input data for LSTM\n",
    "        X_train_array_multi = X_train.iloc[train_index].to_numpy()\n",
    "        X_test_array_multi = X_train.iloc[test_index].to_numpy()\n",
    "        X_train_reshaped_multi = X_train_array_multi.reshape((X_train_array_multi.shape[0], X_train_array_multi.shape[1], 1))\n",
    "        X_test_reshaped_multi = X_test_array_multi.reshape((X_test_array_multi.shape[0], X_test_array_multi.shape[1], 1))\n",
    "\n",
    "        # Define the LSTM model\n",
    "        rnn_multi = Sequential()\n",
    "        rnn_multi.add(LSTM(128, input_shape=(X_train_reshaped_multi.shape[1], X_train_reshaped_multi.shape[2])))\n",
    "        rnn_multi.add(Dense(32, activation='relu'))\n",
    "        rnn_multi.add(Dense(num_classes, activation='softmax'))\n",
    "        rnn_multi.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the LSTM model\n",
    "        start_train = time.time()\n",
    "        rnn_multi.fit(X_train_reshaped_multi, y_train.iloc[train_index], validation_data=(X_test_reshaped_multi, y_train.iloc[test_index]), epochs=10, batch_size=50, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = np.argmax(rnn_multi.predict(X_test_reshaped_multi), axis=1)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_lstm.extend(y_train.iloc[test_index])\n",
    "        all_y_pred_lstm.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_train.iloc[test_index], y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - LSTM\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_LSTM_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_lstm = time.time()\n",
    "    result(all_y_pred_lstm, all_y_test_lstm, \"LSTM\",time_to_train , time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"lstm Completed :)  \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"lstm\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **20. Reconstruction Neural Networks**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_recon = []\n",
    "    all_y_pred_recon = []\n",
    "    start_cv_recon = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        num_classes = len(np.unique(y_train))\n",
    "\n",
    "        # Assuming y_train_multi is one-hot encoded\n",
    "        y_train_multi_onehot = tf.keras.utils.to_categorical(y_train.iloc[train_index], num_classes=num_classes)\n",
    "        y_test_multi_onehot = tf.keras.utils.to_categorical(y_train.iloc[test_index], num_classes=num_classes)\n",
    "\n",
    "        # Define model architecture\n",
    "        input_dim = X_train.shape[1]\n",
    "        encoding_dim = 32  # Choose appropriate dimensionality\n",
    "        latent_dim = 2  # Dimensionality of the latent space\n",
    "\n",
    "        # Encoder\n",
    "        input_layer = tf.keras.layers.Input(shape=(input_dim,))\n",
    "        hidden = tf.keras.layers.Dense(64, activation='relu')(input_layer)\n",
    "        z_mean = tf.keras.layers.Dense(latent_dim)(hidden)\n",
    "        z_log_var = tf.keras.layers.Dense(latent_dim)(hidden)\n",
    "\n",
    "        # Reparameterization trick\n",
    "        def sampling(args):\n",
    "            z_mean, z_log_var = args\n",
    "            epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
    "            return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "        z = tf.keras.layers.Lambda(sampling,output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "        # Decoder\n",
    "        decoder_hidden = tf.keras.layers.Dense(64, activation='relu')(z)\n",
    "        output_layer = tf.keras.layers.Dense(num_classes, activation='softmax')(decoder_hidden)\n",
    "\n",
    "        # Define VAE model\n",
    "        vae = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile model\n",
    "        vae.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the VAE model\n",
    "        start_train = time.time()\n",
    "        vae.fit(X_train.iloc[train_index], y_train_multi_onehot, epochs=10, batch_size=50, shuffle=True, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = np.argmax(vae.predict(X_train.iloc[test_index]), axis=1)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_recon.extend(y_train.iloc[test_index])\n",
    "        all_y_pred_recon.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_train.iloc[test_index], y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Reconstruction Neural Network\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_reconstruction_NN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_recon = time.time()\n",
    "    result(all_y_pred_recon, all_y_test_recon, \"reconstruction_NN\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"reconstruction neural networks, Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"reconstruction neural networks\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **22. DANN with k-fold Cross-Validation**\n",
    "\n",
    "    def build_dann_model(input_shape, num_classes, lambda_val=1e-3):\n",
    "        input_layer = Input(shape=input_shape, name='input_layer')\n",
    "\n",
    "        # Feature extractor\n",
    "        shared_layer = Dense(128, activation='relu')(input_layer)\n",
    "        shared_layer = Dropout(0.5)(shared_layer)\n",
    "\n",
    "        # Source classifier\n",
    "        source_classifier = Dense(num_classes, activation='softmax', name='source_classifier')(shared_layer)\n",
    "\n",
    "        # Domain classifier\n",
    "        domain_classifier = Dense(1, activation='sigmoid', name='domain_classifier')(shared_layer)\n",
    "\n",
    "        # Combined model\n",
    "        model = Model(inputs=input_layer, outputs=[source_classifier, domain_classifier])\n",
    "\n",
    "        # Domain adversarial loss\n",
    "        def domain_adversarial_loss(y_true, y_pred):\n",
    "            return K.mean(K.binary_crossentropy(y_true, y_pred))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "                    loss={'source_classifier': 'categorical_crossentropy', 'domain_classifier': domain_adversarial_loss},\n",
    "                    loss_weights={'source_classifier': 1.0, 'domain_classifier': lambda_val},\n",
    "                    metrics={'source_classifier': 'accuracy'})\n",
    "\n",
    "        return model\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_dann = []\n",
    "    all_y_pred_dann = []\n",
    "    start_cv_dann = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Convert class vectors to binary class matrices\n",
    "        num_classes = len(np.unique(y_train))\n",
    "        y_train_categorical = tf.keras.utils.to_categorical(y_train.iloc[train_index], num_classes)\n",
    "        y_test_categorical = tf.keras.utils.to_categorical(y_train.iloc[test_index], num_classes)\n",
    "\n",
    "        # Build and train DANN model for each fold\n",
    "        input_shape = (X_train.shape[1],)\n",
    "        lambda_val = 1e-3  # Trade-off parameter for domain adversarial loss\n",
    "        dann_model = build_dann_model(input_shape, num_classes, lambda_val)\n",
    "\n",
    "        # Training phase\n",
    "        start_train = time.time()\n",
    "        dann_model.fit(X_train.iloc[train_index],\n",
    "                    {'source_classifier': y_train_categorical, 'domain_classifier': np.zeros((len(train_index), 1))},\n",
    "                    epochs=10, batch_size=64,\n",
    "                    validation_data=(X_train.iloc[test_index],\n",
    "                                        {'source_classifier': y_test_categorical,\n",
    "                                        'domain_classifier': np.ones((len(test_index), 1))}))\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Prediction phase\n",
    "        X_test_fold = X_train.iloc[test_index]  # Use iloc to access test fold\n",
    "        start_predict = time.time()\n",
    "        predictions = dann_model.predict(X_test_fold)\n",
    "        source_classifier_predictions = predictions[0]\n",
    "        y_pred_fold = np.argmax(source_classifier_predictions, axis=1)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        y_test = y_train.iloc[test_index]\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_dann.extend(y_test)\n",
    "        all_y_pred_dann.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - DANN\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_DANN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_dann = time.time()\n",
    "    result(all_y_pred_dann, all_y_test_dann, \"DANN\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"DANN Completed :)  \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"DANN\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **23.Deep brief networks (DBNs)**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_dbn = []\n",
    "    all_y_pred_dbn = []\n",
    "    start_cv_dbn = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Number of classes\n",
    "        num_classes = len(np.unique(y_train))\n",
    "\n",
    "        # Create a pipeline with BernoulliRBM and MLPClassifier\n",
    "        rbm = BernoulliRBM(n_components=64, learning_rate=0.01, n_iter=20, random_state=42, verbose=True)\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(128,), max_iter=10, random_state=52)\n",
    "        dbn_model = Pipeline(steps=[('rbm', rbm), ('mlp', mlp)])\n",
    "\n",
    "        # Training phase\n",
    "        start_train = time.time()\n",
    "        dbn_model.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Prediction phase\n",
    "        X_test_fold = X_train.iloc[test_index]\n",
    "        y_test_fold = y_train.iloc[test_index]\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = dbn_model.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_dbn.extend(y_test_fold)\n",
    "        all_y_pred_dbn.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - DBN\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_DBN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_dbn = time.time()\n",
    "    result(all_y_pred_dbn, all_y_test_dbn, \"DBN\", time_to_train, time_to_predict)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"DBNs\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **24. Deep Boltzmann Machines (DBMs)** with k-fold Cross-Validation\n",
    "    # Build a simple Restricted Boltzmann Machine (RBM) using TensorFlow\n",
    "    class RBM(tf.Module):\n",
    "        def __init__(self, visible_dim, hidden_dim, learning_rate=0.01):\n",
    "            self.visible_dim = visible_dim\n",
    "            self.hidden_dim = hidden_dim\n",
    "            self.learning_rate = learning_rate\n",
    "\n",
    "            # Initialize weights and biases\n",
    "            self.W = tf.Variable(tf.random.normal([visible_dim, hidden_dim], stddev=0.01, dtype=tf.float32))\n",
    "            self.b_visible = tf.Variable(tf.zeros([visible_dim], dtype=tf.float32))\n",
    "            self.b_hidden = tf.Variable(tf.zeros([hidden_dim], dtype=tf.float32))\n",
    "\n",
    "        def _softmax(self, x):\n",
    "            exp_x = tf.exp(x)\n",
    "            return exp_x / tf.reduce_sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "        def sample_hidden(self, visible_prob):\n",
    "            hidden_prob = self._softmax(tf.matmul(visible_prob, self.W) + self.b_hidden)\n",
    "            return tf.nn.relu(tf.sign(hidden_prob - tf.random.uniform(tf.shape(hidden_prob))))\n",
    "\n",
    "        def sample_visible(self, hidden_prob):\n",
    "            visible_prob = self._softmax(tf.matmul(hidden_prob, tf.transpose(self.W)) + self.b_visible)\n",
    "            return tf.nn.relu(tf.sign(visible_prob - tf.random.uniform(tf.shape(visible_prob))))\n",
    "\n",
    "        def contrastive_divergence(self, x, k=1):\n",
    "            visible = x\n",
    "            for _ in range(k):\n",
    "                hidden = self.sample_hidden(visible)\n",
    "                visible = self.sample_visible(hidden)\n",
    "\n",
    "            positive_hidden = self._softmax(tf.matmul(x, self.W) + self.b_hidden)\n",
    "            negative_hidden = self._softmax(tf.matmul(visible, self.W) + self.b_hidden)\n",
    "\n",
    "            # Update weights and biases\n",
    "            self.W.assign_add(self.learning_rate * (tf.matmul(tf.transpose(x), positive_hidden) -\n",
    "                                                    tf.matmul(tf.transpose(visible), negative_hidden)))\n",
    "            self.b_visible.assign_add(self.learning_rate * tf.reduce_mean(x - visible, axis=0))\n",
    "            self.b_hidden.assign_add(self.learning_rate * tf.reduce_mean(positive_hidden - negative_hidden, axis=0))\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_dbm = []\n",
    "    all_y_pred_dbm = []\n",
    "    start_cv_dbm = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index].values, X_train.iloc[test_index].values\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index].values, y_train.iloc[test_index].values\n",
    "\n",
    "        # Number of visible and hidden units\n",
    "        visible_dim = X_train_fold.shape[1]\n",
    "        hidden_dim1 = 64\n",
    "        hidden_dim2 = 32\n",
    "\n",
    "        # Create RBMs for each layer\n",
    "        rbm1 = RBM(visible_dim, hidden_dim1)\n",
    "        rbm2 = RBM(hidden_dim1, hidden_dim2)\n",
    "\n",
    "        # Training RBMs\n",
    "        num_epochs = 5\n",
    "        batch_size = 32\n",
    "        start = time.time()\n",
    "        # Training first RBM\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(0, len(X_train_fold), batch_size):\n",
    "                batch_data = X_train_fold[i:i+batch_size]\n",
    "                rbm1.contrastive_divergence(tf.cast(batch_data, dtype=tf.float32))\n",
    "\n",
    "        # Getting hidden layer representation from the first RBM\n",
    "        hidden1_representation = tf.nn.relu(tf.sign(rbm1.sample_hidden(tf.cast(X_train_fold, dtype=tf.float32))))\n",
    "\n",
    "        # Training second RBM using the hidden layer representation from the first RBM\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(0, len(hidden1_representation), batch_size):\n",
    "                batch_data = hidden1_representation[i:i+batch_size]\n",
    "                rbm2.contrastive_divergence(batch_data)\n",
    "\n",
    "        # Getting hidden layer representation from the second RBM\n",
    "        hidden2_representation = tf.nn.relu(tf.sign(rbm2.sample_hidden(hidden1_representation)))\n",
    "\n",
    "        # Fine-tuning for classification\n",
    "        num_classes = len(np.unique(y_train_fold))\n",
    "        dbm_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(hidden_dim1, activation='relu'),\n",
    "            tf.keras.layers.Dense(hidden_dim2, activation='relu'),\n",
    "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        dbm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        dbm_model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=50, shuffle=True, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "\n",
    "        # Predict on the test set\n",
    "        start_predict = time.time()\n",
    "        y_pred_probabilities = dbm_model.predict(X_test_fold)\n",
    "        y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_dbm.extend(y_test_fold)\n",
    "        all_y_pred_dbm.extend(y_pred)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - DBM\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_DBM_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_dbm = time.time()\n",
    "    result(all_y_pred_dbm, all_y_test_dbm, \"DBM\", time_to_train, time_to_predict)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"DBMs\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **25.DEEP AUTO ENCODERS(DA)**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_da = []\n",
    "    all_y_pred_da = []\n",
    "    start_cv_da = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Define the autoencoder model\n",
    "        autoencoder = Sequential()\n",
    "\n",
    "        # Encoder\n",
    "        autoencoder.add(Dense(128, activation='relu', input_shape=(X_train_fold.shape[1],)))\n",
    "        autoencoder.add(Dense(64, activation='relu'))\n",
    "        autoencoder.add(Dense(32, activation='relu'))\n",
    "\n",
    "        # Decoder\n",
    "        autoencoder.add(Dense(64, activation='relu'))\n",
    "        autoencoder.add(Dense(128, activation='relu'))\n",
    "        autoencoder.add(Dense(X_train_fold.shape[1], activation='linear'))\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "        # Train the autoencoder\n",
    "        autoencoder.fit(X_train_fold, X_train_fold, epochs=10, batch_size=50, verbose=0)\n",
    "\n",
    "        # Add a classification head on top of the trained autoencoder\n",
    "        da_model = Sequential()\n",
    "        da_model.add(autoencoder.layers[0])  # Add encoder layers\n",
    "        da_model.add(autoencoder.layers[1])\n",
    "        da_model.add(autoencoder.layers[2])\n",
    "        da_model.add(Dense(num_classes, activation='softmax'))  # Adjust output layer for multiple classes\n",
    "\n",
    "        # Compile the classification model\n",
    "        da_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Convert labels to one-hot encoding\n",
    "        y_train_fold_onehot = to_categorical(y_train_fold, num_classes=num_classes)\n",
    "        y_test_fold_onehot = to_categorical(y_test_fold, num_classes=num_classes)\n",
    "\n",
    "        # Train the classification model using the encoded representations\n",
    "        start_train = time.time()\n",
    "        history = da_model.fit(X_train_fold, y_train_fold_onehot, epochs=10, batch_size=32, shuffle=True, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict on the test set\n",
    "        start_predict = time.time()\n",
    "        y_pred_probabilities = da_model.predict(X_test_fold)\n",
    "        y_pred_fold = np.argmax(y_pred_probabilities, axis=1)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_da.extend(y_test_fold)\n",
    "        all_y_pred_da.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - DA\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_DA_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_da = time.time()\n",
    "    result(all_y_pred_da, all_y_test_da, \"DA\", time_to_train, time_to_predict)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"DEEP AUTO ENCODERS\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **26. PassiveAggressiveClassifier with k-fold Cross-Validation**\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_passive = []\n",
    "    all_y_pred_passive = []\n",
    "\n",
    "    start_cv_passive = time.time()\n",
    "    time_to_predict_passive = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_passive, X_test_fold_passive = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_passive, y_test_fold_passive = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Initialize PassiveAggressiveClassifier for each fold\n",
    "        model_passive = PassiveAggressiveClassifier(max_iter=1000, random_state=0, tol=1e-3)\n",
    "\n",
    "        # Train the model\n",
    "        start_train_passive = time.time()\n",
    "        model_passive.fit(X_train_fold_passive, y_train_fold_passive)\n",
    "        end_train_passive = time.time()\n",
    "        time_to_train += end_train_passive -start_train_passive\n",
    "        # Predict on the test set\n",
    "        start_predict_passive = time.time()\n",
    "        y_pred_passive = model_passive.predict(X_test_fold_passive)\n",
    "        end_predict_passive = time.time()\n",
    "        time_to_predict_passive += end_predict_passive - start_predict_passive\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_passive.extend(y_test_fold_passive)\n",
    "        all_y_pred_passive.extend(y_pred_passive)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm_passive = confusion_matrix(y_test_fold_passive, y_pred_passive)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_passive = ConfusionMatrixDisplay(confusion_matrix=cm_passive)\n",
    "        disp_passive.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - PassiveAggressiveClassifier\")\n",
    "        pname_passive = method + \"_fold_\" + str(fold_number) + \"_PassiveAggressiveClassifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname_passive)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_passive = time.time()\n",
    "    result(all_y_pred_passive, all_y_test_passive, \"PassiveAggressiveClassifier\", time_to_train, time_to_predict_passive)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"PassiveAggressiveClassifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **27. RidgeClassifier with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_ridge = []\n",
    "    all_y_pred_ridge = []\n",
    "    start_cv_ridge = time.time()\n",
    "    time_to_predict_ridge = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train.values, y_train.values), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_ridge, X_test_fold_ridge = X_train.values[train_index], X_train.values[test_index]\n",
    "        y_train_fold_ridge, y_test_fold_ridge = y_train.values[train_index], y_train.values[test_index]\n",
    "\n",
    "        # Initialize RidgeClassifier for each fold\n",
    "        model_ridge = RidgeClassifier()\n",
    "\n",
    "        # Train the model\n",
    "        start_train_ridge = time.time()\n",
    "        model_ridge.fit(X_train_fold_ridge, y_train_fold_ridge)\n",
    "        end_train_ridge = time.time()\n",
    "        time_to_train += end_train_ridge -start_train_ridge\n",
    "        # Predict    on the test set\n",
    "        start_predict_ridge = time.time()\n",
    "        y_pred_ridge = model_ridge.predict(X_test_fold_ridge)\n",
    "        end_predict_ridge = time.time()\n",
    "\n",
    "        time_to_predict_ridge += end_predict_ridge - start_predict_ridge\n",
    "        # Append metrics to lists\n",
    "        all_y_test_ridge.extend(y_test_fold_ridge)\n",
    "        all_y_pred_ridge.extend(y_pred_ridge)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm_ridge = confusion_matrix(y_test_fold_ridge, y_pred_ridge)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_ridge = ConfusionMatrixDisplay(confusion_matrix=cm_ridge)\n",
    "        disp_ridge.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - RidgeClassifier\")\n",
    "        pname_ridge = method +\"_fold_\"+ str(fold_number) + \"_RidgeClassifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname_ridge)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_ridge = time.time()\n",
    "    result(all_y_pred_ridge, all_y_test_ridge, \"RidgeClassifier\", time_to_train, time_to_predict_ridge)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"RidgeClassifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **28. NearestCentroid with k-fold Cross-Validation, Time to Predict, and Confusion Matrix**\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_nc = []\n",
    "    all_y_pred_nc = []\n",
    "    start_cv_nc = time.time()\n",
    "    total_time_to_predict_nc = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_nc, X_test_fold_nc = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_nc, y_test_fold_nc = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Initialize NearestCentroid model for each fold\n",
    "        model_nc = NearestCentroid()\n",
    "\n",
    "        # Start time for training\n",
    "        start_train_nc = time.time()\n",
    "\n",
    "        # Train the model\n",
    "        model_nc.fit(X_train_fold_nc, y_train_fold_nc)\n",
    "\n",
    "        # End time for training\n",
    "        end_train_nc = time.time()\n",
    "        time_to_train += end_train_nc - start_train_nc\n",
    "        # Start time for prediction\n",
    "        start_predict_nc = time.time()\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_fold_nc = model_nc.predict(X_test_fold_nc)\n",
    "\n",
    "        # End time for prediction\n",
    "        end_predict_nc = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict_nc = end_predict_nc - start_predict_nc\n",
    "        total_time_to_predict_nc += time_to_predict_nc\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_nc.extend(y_test_fold_nc)\n",
    "        all_y_pred_nc.extend(y_pred_fold_nc)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm_nc = confusion_matrix(y_test_fold_nc, y_pred_fold_nc)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_nc = ConfusionMatrixDisplay(confusion_matrix=cm_nc)\n",
    "        disp_nc.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - NearestCentroid\")\n",
    "        pname_nc = method+\"_fold_\" + str(fold_number) + \"_NearestCentroid_confusion_matrix.png\"\n",
    "        plt.savefig(pname_nc)\n",
    "        #plt.show()\n",
    "\n",
    "    # End time for k-fold cross-validation\n",
    "    end_cv_nc = time.time()\n",
    "    # Calculate overall performance metrics\n",
    "    result(all_y_pred_nc, all_y_test_nc, \"NearestCentroid\", time_to_train, total_time_to_predict_nc)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"NearestCentroid\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **29. Cost Sensitive Logistic Regression (CSLR) with k-fold Cross-Validation and Time to Predict**\n",
    "\n",
    "    def get_sample_weight(cost_matrix, y_tru):\n",
    "        y_true = np.array(y_tru)\n",
    "        num_samples = len(y_true)\n",
    "        sample_weights = np.zeros(num_samples)\n",
    "        for i in range(num_samples):\n",
    "            true_class = y_true[i]\n",
    "            for j in range(len(cost_matrix)):\n",
    "                if j != true_class:\n",
    "                    sample_weights[i] += cost_matrix[true_class, j]\n",
    "        return sample_weights\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_cslr = []\n",
    "    all_y_pred_cslr = []\n",
    "    # Define cost matrix for CSLR\n",
    "    cost_matrix = np.array([[0, 1, 2, 3, 4, 5, 6, 7, 8],    # Costs for misclassifying class 0\n",
    "                            [1, 0, 1, 2, 3, 4, 5, 6, 7],    # Costs for misclassifying class 1\n",
    "                            [2, 1, 0, 1, 2, 3, 4, 5, 6],    # Costs for misclassifying class 2\n",
    "                            [3, 2, 1, 0, 1, 2, 3, 4, 5],    # Costs for misclassifying class 3\n",
    "                            [4, 3, 2, 1, 0, 1, 2, 3, 4],    # Costs for misclassifying class 4\n",
    "                            [5, 4, 3, 2, 1, 0, 1, 2, 3],    # Costs for misclassifying class 5\n",
    "                            [6, 5, 4, 3, 2, 1, 0, 1, 2],    # Costs for misclassifying class 6\n",
    "                            [7, 6, 5, 4, 3, 2, 1, 0, 1],    # Costs for misclassifying class 7\n",
    "                            [8, 7, 6, 5, 4, 3, 2, 1, 0]])   # Costs for misclassifying class 8\n",
    "\n",
    "    start_cv_cslr = time.time()\n",
    "    total_time_to_predict_fold_cslr = 0\n",
    "    time_to_train = 0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_cslr, X_test_fold_cslr = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_cslr, y_test_fold_cslr = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Get sample weights for cost-sensitive learning\n",
    "        sample_weights_fold_cslr = get_sample_weight(cost_matrix, y_train_fold_cslr)\n",
    "\n",
    "        # Initialize Logistic Regression model for each fold\n",
    "        model_cslr = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "        # Start time for training\n",
    "        start_train_fold_cslr = time.time()\n",
    "\n",
    "        # Train the model\n",
    "        model_cslr.fit(X_train_fold_cslr, y_train_fold_cslr, sample_weight=sample_weights_fold_cslr)\n",
    "\n",
    "        # End time for training\n",
    "        end_train_fold_cslr = time.time()\n",
    "\n",
    "        time_to_train +=  end_train_fold_cslr - start_train_fold_cslr\n",
    "        # Start time for prediction\n",
    "        start_predict_fold_cslr = time.time()\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_fold_cslr = model_cslr.predict(X_test_fold_cslr)\n",
    "\n",
    "        # End time for prediction\n",
    "        end_predict_fold_cslr = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction in this fold\n",
    "        time_to_predict_fold_cslr = end_predict_fold_cslr - start_predict_fold_cslr\n",
    "        total_time_to_predict_fold_cslr += time_to_predict_fold_cslr\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_cslr.extend(y_test_fold_cslr)\n",
    "        all_y_pred_cslr.extend(y_pred_fold_cslr)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm_cslr = confusion_matrix(y_test_fold_cslr, y_pred_fold_cslr)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_cslr = ConfusionMatrixDisplay(confusion_matrix=cm_cslr)\n",
    "        disp_cslr.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - CSLR\")\n",
    "        pname_cslr = method +\"_fold_\" + str(fold_number) + \"_CSLR__confusion_matrix.png\"\n",
    "        plt.savefig(pname_cslr)\n",
    "        #plt.show()\n",
    "\n",
    "    # End time for k-fold cross-validation\n",
    "    end_cv_cslr = time.time()\n",
    "    result(all_y_pred_cslr, all_y_test_cslr, \"CSLR\", time_to_train, total_time_to_predict_fold_cslr)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"CSLR\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **30. Cost-sensitive Bagging Classifier (CSBC) with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_csbc = []\n",
    "    all_y_pred_csbc = []\n",
    "    start_cv_csbc = time.time()\n",
    "    time_to_predict_fold_csbc = 0\n",
    "    time_to_train = 0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_csbc, X_test_fold_csbc = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_csbc, y_test_fold_csbc = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Step 1: Compute class weights for the fold\n",
    "        class_weights_fold = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_fold_csbc), y=y_train_fold_csbc)\n",
    "\n",
    "        # Step 2: Initialize the base estimator and BaggingClassifier for the fold\n",
    "        base_estimator = DecisionTreeClassifier(max_depth=5)\n",
    "        bagging_model = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "        # Step 3: Train the model on the fold\n",
    "        start_train_fold_csbc = time.time()\n",
    "        bagging_model.fit(X_train_fold_csbc, y_train_fold_csbc)\n",
    "        end_train_fold_csbc = time.time()\n",
    "        time_to_train += end_train_fold_csbc - start_train_fold_csbc\n",
    "        # Step 4: Predict on the test set for the fold\n",
    "        start_predict_fold_csbc = time.time()\n",
    "        y_pred_fold_csbc = bagging_model.predict(X_test_fold_csbc)\n",
    "        end_predict_fold_csbc = time.time()\n",
    "\n",
    "        time_to_predict_fold_csbc += end_predict_fold_csbc - start_predict_fold_csbc\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_csbc.extend(y_test_fold_csbc)\n",
    "        all_y_pred_csbc.extend(y_pred_fold_csbc)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_csbc = confusion_matrix(y_test_fold_csbc, y_pred_fold_csbc)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_csbc = ConfusionMatrixDisplay(confusion_matrix=cm_csbc)\n",
    "        disp_csbc.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - CSBC\")\n",
    "        pname_csbc = method + \"_fold_\" + str(fold_number) + \"_CSBC_confusion_matrix.png\"\n",
    "        plt.savefig(pname_csbc)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_csbc = time.time()\n",
    "    result(all_y_pred_csbc, all_y_test_csbc, \"CSBC\", time_to_train, time_to_predict_fold_csbc)\n",
    "\n",
    "    from lightgbm import LGBMClassifier\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"CSBC\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **31. LightGBM with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_lgbm = []\n",
    "    all_y_pred_lgbm = []\n",
    "    start_cv_lgbm = time.time()\n",
    "    time_to_predict_fold_lgbm = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_lgbm, X_test_fold_lgbm = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_lgbm, y_test_fold_lgbm = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Initialize LightGBM Classifier\n",
    "        lgbm = LGBMClassifier()\n",
    "\n",
    "        # Train the model on the fold\n",
    "        start_train_fold_lgbm = time.time()\n",
    "        lgbm.fit(X_train_fold_lgbm, y_train_fold_lgbm)\n",
    "        end_train_fold_lgbm = time.time()\n",
    "        time_to_train += end_train_fold_lgbm  - start_train_fold_lgbm\n",
    "        # Predict on the test set for the fold\n",
    "        start_predict_fold_lgbm = time.time()\n",
    "        y_pred_fold_lgbm = lgbm.predict(X_test_fold_lgbm)\n",
    "        end_predict_fold_lgbm = time.time()\n",
    "\n",
    "        time_to_predict_fold_lgbm += end_predict_fold_lgbm - start_predict_fold_lgbm\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_lgbm.extend(y_test_fold_lgbm)\n",
    "        all_y_pred_lgbm.extend(y_pred_fold_lgbm)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_lgbm = confusion_matrix(y_test_fold_lgbm, y_pred_fold_lgbm)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_lgbm = ConfusionMatrixDisplay(confusion_matrix=cm_lgbm)\n",
    "        disp_lgbm.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - LightGBM\")\n",
    "        pname_lgbm = method + \"_fold_\" + str(fold_number) + \"_LightGBM_confusion_matrix.png\"\n",
    "        plt.savefig(pname_lgbm)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_lgbm = time.time()\n",
    "    result(all_y_pred_lgbm, all_y_test_lgbm, \"LightGBM\", time_to_train, time_to_predict_fold_lgbm)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"LightGBM\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **32. LinearDiscriminantAnalysis (LDA) with k-fold Cross-Validation\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_lda = []\n",
    "    all_y_pred_lda = []\n",
    "    start_cv_lda = time.time()\n",
    "    time_to_predict_fold_lda = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_lda, X_test_fold_lda = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_lda, y_test_fold_lda = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Apply Linear Discriminant Analysis (LDA) for dimensionality reduction\n",
    "        lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "        X_train_fold_lda = lda.fit_transform(X_train_fold_lda, y_train_fold_lda)\n",
    "        X_test_fold_lda = lda.transform(X_test_fold_lda)\n",
    "\n",
    "        # Train Random Forest Classifier on the transformed features\n",
    "        classifier_lda = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "        # Train the model on the fold\n",
    "        start_train_fold_lda = time.time()\n",
    "        classifier_lda.fit(X_train_fold_lda, y_train_fold_lda)\n",
    "        end_train_fold_lda = time.time()\n",
    "        time_to_train += end_train_fold_lda -start_train_fold_lda\n",
    "        # Predict on the test set for the fold\n",
    "        start_predict_fold_lda = time.time()\n",
    "        y_pred_fold_lda = classifier_lda.predict(X_test_fold_lda)\n",
    "        end_predict_fold_lda = time.time()\n",
    "\n",
    "        time_to_predict_fold_lda += end_predict_fold_lda - start_predict_fold_lda\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_lda.extend(y_test_fold_lda)\n",
    "        all_y_pred_lda.extend(y_pred_fold_lda)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_lda = confusion_matrix(y_test_fold_lda, y_pred_fold_lda)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_lda = ConfusionMatrixDisplay(confusion_matrix=cm_lda)\n",
    "        disp_lda.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - LDA\")\n",
    "        pname_lda = method + \"_fold_\" + str(fold_number) + \"_LDA_confusion_matrix.png\"\n",
    "        plt.savefig(pname_lda)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_lda = time.time()\n",
    "    result(all_y_pred_lda, all_y_test_lda, \"LDA\", time_to_train, time_to_predict_fold_lda)\n",
    "\n",
    "    # **MULTI-CLASS CLASSIFICATION**\n",
    "    # **Data Splitting**\n",
    "    # reloading as many transformations on X,Y causing errors for gru code\n",
    "    X_train = train_data.drop(columns=['label'],axis=1)\n",
    "    X_test = test_data.drop(columns=['label'],axis=1)\n",
    "    y_train = train_data['label']\n",
    "    y_test = test_data['label']\n",
    "    X_train = pd.concat([X_train, X_test], axis=0)\n",
    "    y_train = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "    # # 10 DATA COL EACH CLASS\n",
    "    # # Get unique classes\n",
    "    X_train,temp1,y_train,temp2 = train_test_split(X_train,y_train,train_size=0.1, random_state=7)\n",
    "\n",
    "    # Reset indices of X_train and y_train\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"LDA\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **33. GRU with k-fold Cross-Validation**\n",
    "    num_classes =  len(np.unique(y_train))\n",
    "    X_train_array_multi = X_train.to_numpy()\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gru = []\n",
    "    all_y_pred_gru = []\n",
    "    start_cv_gru = time.time()\n",
    "    time_to_predict_fold = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Convert fold data to numpy arrays and reshape for GRU input\n",
    "        X_train_fold_array = X_train_fold.to_numpy().reshape((X_train_fold.shape[0], X_train_fold.shape[1], 1))\n",
    "        X_test_fold_array = X_test_fold.to_numpy().reshape((X_test_fold.shape[0], X_test_fold.shape[1], 1))\n",
    "\n",
    "        # Define and compile the GRU model\n",
    "        rnn_fold = Sequential([\n",
    "            GRU(128, input_shape=(X_train_fold_array.shape[1], X_train_fold_array.shape[2])),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        rnn_fold.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model on the fold\n",
    "        start_train_fold = time.time()\n",
    "        rnn_fold.fit(X_train_fold_array, y_train_fold, epochs=10, batch_size=50, verbose=0)\n",
    "        end_train_fold = time.time()\n",
    "        time_to_train += end_train_fold -start_train_fold\n",
    "        # Predict on the test set for the fold\n",
    "        start_predict_fold = time.time()\n",
    "        y_pred_fold = np.argmax(rnn_fold.predict(X_test_fold_array), axis=1)\n",
    "        end_predict_fold = time.time()\n",
    "\n",
    "        time_to_predict_fold += end_predict_fold - start_predict_fold\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gru.extend(y_test_fold)\n",
    "        all_y_pred_gru.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - GRU\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_GRU_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_gru = time.time()\n",
    "    val_accuracy_gru = accuracy_score(all_y_test_gru, all_y_pred_gru)\n",
    "    result(all_y_pred_gru, all_y_test_gru, \"GRU\", time_to_train, time_to_predict_fold)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"GRU\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **34. Stochastic Gradient with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_sgd = []\n",
    "    all_y_pred_sgd = []\n",
    "    start_cv_sgd = time.time()\n",
    "    time_to_predict_fold = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Define the SGD classifier pipeline with standard scaler\n",
    "        sgd_fold = make_pipeline(StandardScaler(), SGDClassifier(random_state=24))\n",
    "        # Measure time to train on the fold\n",
    "        start_train_fold = time.time()\n",
    "        sgd_fold.fit(X_train_fold, y_train_fold)\n",
    "        end_train_fold = time.time()\n",
    "        time_to_train += end_train_fold -start_train_fold\n",
    "        # Measure time to predict on the fold\n",
    "        start_predict_fold = time.time()\n",
    "        y_pred_fold = sgd_fold.predict(X_test_fold)\n",
    "        end_predict_fold = time.time()\n",
    "        time_to_predict_fold += end_predict_fold - start_predict_fold\n",
    "        # Append metrics to lists\n",
    "        all_y_test_sgd.extend(y_test_fold)\n",
    "        all_y_pred_sgd.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Stochastic Gradient\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_Stochastic_gradient_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_sgd = time.time()\n",
    "    result(all_y_pred_sgd, all_y_test_sgd, \"Stochastic_gradient\", time_to_train, time_to_predict_fold)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Stochastic_gradient\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **36. Extra Trees Classifier with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_extra_trees = []\n",
    "    all_y_pred_extra_trees = []\n",
    "    start_cv_extra_trees = time.time()\n",
    "    time_to_predict_fold_extra_trees = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Define the Extra Trees classifier\n",
    "        extra_trees_fold = ExtraTreesClassifier()\n",
    "\n",
    "        # Measure time to train on the fold\n",
    "        start_train_fold_extra_trees = time.time()\n",
    "        extra_trees_fold.fit(X_train_fold, y_train_fold)\n",
    "        end_train_fold_extra_trees = time.time()\n",
    "        time_to_train += end_train_fold_extra_trees -start_train_fold_extra_trees\n",
    "        # Measure time to predict on the fold\n",
    "        start_predict_fold_extra_trees = time.time()\n",
    "        y_pred_fold_extra_trees = extra_trees_fold.predict(X_test_fold)\n",
    "        end_predict_fold_extra_trees = time.time()\n",
    "\n",
    "        time_to_predict_fold_extra_trees += end_predict_fold_extra_trees - start_predict_fold_extra_trees\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_extra_trees.extend(y_test_fold)\n",
    "        all_y_pred_extra_trees.extend(y_pred_fold_extra_trees)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_extra_trees = confusion_matrix(y_test_fold, y_pred_fold_extra_trees)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_extra_trees = ConfusionMatrixDisplay(confusion_matrix=cm_extra_trees)\n",
    "        disp_extra_trees.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Extra Trees Classifier\")\n",
    "        pname_extra_trees = method + \"_fold_\" + str(fold_number) + \"_ExtraTreesClassifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname_extra_trees)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_extra_trees = time.time()\n",
    "    result(all_y_pred_extra_trees, all_y_test_extra_trees, \"Extra Trees Classifier\", time_to_train, time_to_predict_fold_extra_trees)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Extra Trees Classifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **37. Feed Forward Neural Networks with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_ffnn = []\n",
    "    all_y_pred_ffnn = []\n",
    "    start_cv_ffnn = time.time()\n",
    "    time_to_predict_fold_ffnn = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Define the neural network architecture\n",
    "        model_ffnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_fold.shape[1],)),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(len(np.unique(y_train_fold)), activation='softmax')\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model_ffnn.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        # Measure time to train on the fold\n",
    "        start_train_fold_ffnn = time.time()\n",
    "        history_ffnn = model_ffnn.fit(X_train_fold, y_train_fold, epochs=10, batch_size=50, verbose=1)\n",
    "        end_train_fold_ffnn = time.time()\n",
    "        time_to_train += end_train_fold_ffnn -start_train_fold_ffnn\n",
    "        # Measure time to predict on the fold\n",
    "        start_predict_fold_ffnn = time.time()\n",
    "        y_pred_fold_ffnn_prob = model_ffnn.predict(X_test_fold)\n",
    "        y_pred_fold_ffnn = np.argmax(y_pred_fold_ffnn_prob, axis=1)\n",
    "        end_predict_fold_ffnn = time.time()\n",
    "\n",
    "        time_to_predict_fold_ffnn += end_predict_fold_ffnn - start_predict_fold_ffnn\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_ffnn.extend(y_test_fold)\n",
    "        all_y_pred_ffnn.extend(y_pred_fold_ffnn)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_ffnn = confusion_matrix(y_test_fold, y_pred_fold_ffnn)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_ffnn = ConfusionMatrixDisplay(confusion_matrix=cm_ffnn)\n",
    "        disp_ffnn.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Feed Forward Neural Networks\")\n",
    "        pname_ffnn = method + \"_fold_\" + str(fold_number) + \"_FFNN_confusion_matrix.png\"\n",
    "        plt.savefig(pname_ffnn)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_ffnn = time.time()\n",
    "    result(all_y_pred_ffnn, all_y_test_ffnn, \"Feed Forward Neural Networks\", time_to_train, time_to_predict_fold_ffnn)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Feed Forward Neural Networks\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **38. Fuzzy with k-fold Cross-Validation**\n",
    "\n",
    "    all_y_test_fuzzy = []\n",
    "    all_y_pred_fuzzy = []\n",
    "    start_cv_fuzzy = time.time()\n",
    "    time_to_predict_fold_fuzzy = 0\n",
    "    time_to_train=0\n",
    "    # Generate fuzzy c-means clusters\n",
    "    n_clusters = 10  # Number of classes\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        start_train_fold_fuzzy = time.time()\n",
    "        # Generate fuzzy c-means clusters for training data of the fold\n",
    "        centers, u_train_fold, _, _, _, _, _ = fuzz.cluster.cmeans(\n",
    "            X_train_fold.T, n_clusters, 2, error=0.005, maxiter=1000\n",
    "        )\n",
    "\n",
    "        # Measure time to train on the fold\n",
    "        end_train_fold_fuzzy = time.time()\n",
    "        time_to_train  += end_train_fold_fuzzy - start_train_fold_fuzzy\n",
    "        # Predict cluster membership for test data of the fold\n",
    "        start_predict_fold_fuzzy = time.time()\n",
    "        u_test_fold, _, _, _, _, _ = fuzz.cluster.cmeans_predict(\n",
    "            X_test_fold.T, centers, 2, error=0.005, maxiter=1000\n",
    "        )\n",
    "        end_predict_fold_fuzzy = time.time()\n",
    "\n",
    "        time_to_predict_fold_fuzzy += end_predict_fold_fuzzy - start_predict_fold_fuzzy\n",
    "\n",
    "        # Assign class labels based on cluster membership\n",
    "        y_pred_fold_fuzzy = np.argmax(u_test_fold, axis=0)\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_fuzzy.extend(y_test_fold)\n",
    "        all_y_pred_fuzzy.extend(y_pred_fold_fuzzy)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_fuzzy = confusion_matrix(y_test_fold, y_pred_fold_fuzzy)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_fuzzy = ConfusionMatrixDisplay(confusion_matrix=cm_fuzzy)\n",
    "        disp_fuzzy.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Fuzzy\")\n",
    "        pname_fuzzy = method + \"_fold_\" + str(fold_number) + \"_Fuzzy_confusion_matrix.png\"\n",
    "        plt.savefig(pname_fuzzy)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_fuzzy = time.time()\n",
    "    result(all_y_pred_fuzzy, all_y_test_fuzzy, \"Fuzzy\", time_to_train, time_to_predict_fold_fuzzy)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Fuzzy\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **39. Ensemble of Deep Learning Networks (EDLNs) with k-fold Cross-Validation**\n",
    "    # Define the architecture of your neural network (example architecture)\n",
    "    def create_model(input_shape, num_classes):\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(64, activation='relu', input_shape=input_shape),\n",
    "            keras.layers.Dense(64, activation='relu'),\n",
    "            keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_EDLN = []\n",
    "    all_y_pred_EDLN = []\n",
    "    start_cv_EDLN = time.time()\n",
    "    time_to_predict_fold_EDLN = 0\n",
    "    time_to_train=0\n",
    "    # Define hyperparameters\n",
    "    num_networks = 5\n",
    "    epochs = 10\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_EDLN, X_test_fold_EDLN = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_EDLN, y_test_fold_EDLN = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Train multiple neural networks\n",
    "        start = time.time()\n",
    "        models_fold_EDLN = []\n",
    "        for i in range(num_networks):\n",
    "            model_fold_EDLN = create_model(input_shape=X_train_fold_EDLN.shape[1:], num_classes=num_classes)\n",
    "            model_fold_EDLN.fit(X_train_fold_EDLN, y_train_fold_EDLN, epochs=epochs, verbose=0)\n",
    "            models_fold_EDLN.append(model_fold_EDLN)\n",
    "        end = time.time()\n",
    "        time_to_train += end - start\n",
    "        # Measure time to predict on the fold\n",
    "        start_predict_fold_EDLN = time.time()\n",
    "        # Make predictions on test data using each model\n",
    "        predictions_fold_EDLN = np.array([model_fold_EDLN.predict(X_test_fold_EDLN) for model_fold_EDLN in models_fold_EDLN])\n",
    "        end_predict_fold_EDLN = time.time()\n",
    "\n",
    "        time_to_predict_fold_EDLN += end_predict_fold_EDLN - start_predict_fold_EDLN\n",
    "\n",
    "        # Aggregate predictions by averaging\n",
    "        y_pred_fold_EDLN = np.argmax(np.mean(predictions_fold_EDLN, axis=0), axis=1)\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_EDLN.extend(y_test_fold_EDLN)\n",
    "        all_y_pred_EDLN.extend(y_pred_fold_EDLN)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_EDLN = confusion_matrix(y_test_fold_EDLN, y_pred_fold_EDLN)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_EDLN = ConfusionMatrixDisplay(confusion_matrix=cm_EDLN)\n",
    "        disp_EDLN.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - EDLNs\")\n",
    "        pname_EDLN = method + \"_fold_\" + str(fold_number) + \"_EDLNs_confusion_matrix.png\"\n",
    "        plt.savefig(pname_EDLN)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_EDLN = time.time()\n",
    "    result(all_y_pred_EDLN, all_y_test_EDLN, \"EDLNs\", time_to_train, time_to_predict_fold_EDLN)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"EDLNs\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **40. Gaussian Mixture Model (GMM) with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gmm = []\n",
    "    all_y_pred_gmm = []\n",
    "    start_cv_gmm = time.time()\n",
    "    time_to_predict_fold_gmm = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_gmm, test_index_gmm) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_gmm, X_test_fold_gmm = X_train.iloc[train_index_gmm], X_train.iloc[test_index_gmm]\n",
    "        y_train_fold_gmm, y_test_fold_gmm = y_train.iloc[train_index_gmm], y_train.iloc[test_index_gmm]\n",
    "\n",
    "        # Number of classes\n",
    "        n_classes_gmm = len(set(y_train_fold_gmm))\n",
    "\n",
    "        # Dictionary to store GMMs for each class\n",
    "        gmm_models_fold_gmm = {}\n",
    "\n",
    "        # Train GMMs for each class\n",
    "        start_train_fold_gmm = time.time()\n",
    "        for i in range(n_classes_gmm):\n",
    "            # Filter data for the current class\n",
    "            X_class_gmm = X_train_fold_gmm[y_train_fold_gmm == i]\n",
    "            # Fit Gaussian Mixture Model\n",
    "            gmm_fold_gmm = GaussianMixture(n_components=2)  # You can adjust n_components as needed\n",
    "            gmm_fold_gmm.fit(X_class_gmm)\n",
    "            # Store the trained GMM\n",
    "            gmm_models_fold_gmm[i] = gmm_fold_gmm\n",
    "        end_train_fold_gmm = time.time()\n",
    "        time_to_train += end_train_fold_gmm - start_train_fold_gmm\n",
    "        # Measure time to predict on the fold\n",
    "        start_predict_fold_gmm = time.time()\n",
    "        y_pred_fold_gmm = []\n",
    "        for x_gmm in X_test_fold_gmm.values:  # Convert DataFrame to numpy array for iteration\n",
    "            class_likelihoods_gmm = []\n",
    "            # Reshape x to have the appropriate dimensions\n",
    "            x_reshaped_gmm = x_gmm.reshape(1, -1)\n",
    "            # Calculate likelihood for each class\n",
    "            for i in range(n_classes_gmm):\n",
    "                class_likelihood_gmm = gmm_models_fold_gmm[i].score_samples(x_reshaped_gmm)\n",
    "                class_likelihoods_gmm.append(class_likelihood_gmm)\n",
    "            # Assign the class with the highest likelihood\n",
    "            predicted_class_gmm = max(zip(class_likelihoods_gmm, range(n_classes_gmm)))[1]\n",
    "            y_pred_fold_gmm.append(predicted_class_gmm)\n",
    "        end_predict_fold_gmm = time.time()\n",
    "\n",
    "        time_to_predict_fold_gmm += end_predict_fold_gmm - start_predict_fold_gmm\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gmm.extend(y_test_fold_gmm)\n",
    "        all_y_pred_gmm.extend(y_pred_fold_gmm)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_gmm = confusion_matrix(y_test_fold_gmm, y_pred_fold_gmm)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_gmm = ConfusionMatrixDisplay(confusion_matrix=cm_gmm)\n",
    "        disp_gmm.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - GMM\")\n",
    "        pname_gmm = method + \"_fold_\" + str(fold_number) + \"_GMM_confusion_matrix.png\"\n",
    "        plt.savefig(pname_gmm)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_gmm = time.time()\n",
    "    result(all_y_pred_gmm, all_y_test_gmm, \"GMM\", time_to_train, time_to_predict_fold_gmm)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"GMM Completed :)  \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"GMM\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## **41. Bernoulli Naive Bayes with k-fold Cross-Validation**\"\"\"\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_bnb = []\n",
    "    all_y_pred_bnb = []\n",
    "    start_cv_bnb = time.time()\n",
    "    time_to_predict_fold_bnb = 0\n",
    "    time_to_train=0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_bnb, test_index_bnb) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_bnb, X_test_fold_bnb = X_train.iloc[train_index_bnb], X_train.iloc[test_index_bnb]\n",
    "        y_train_fold_bnb, y_test_fold_bnb = y_train.iloc[train_index_bnb], y_train.iloc[test_index_bnb]\n",
    "\n",
    "        # Create a Bernoulli Naive Bayes classifier\n",
    "        bnb_fold_bnb = BernoulliNB()\n",
    "\n",
    "        # Train the classifier\n",
    "        start_train_fold_bnb = time.time()\n",
    "        bnb_fold_bnb.fit(X_train_fold_bnb, y_train_fold_bnb)\n",
    "        end_train_fold_bnb = time.time()\n",
    "        time_to_train += end_train_fold_bnb - start_train_fold_bnb\n",
    "\n",
    "        # Predict using the trained model\n",
    "        start_predict_fold_bnb = time.time()\n",
    "        y_pred_fold_bnb = bnb_fold_bnb.predict(X_test_fold_bnb)\n",
    "        end_predict_fold_bnb = time.time()\n",
    "        time_to_predict_fold_bnb += end_predict_fold_bnb - start_predict_fold_bnb\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_bnb.extend(y_test_fold_bnb)\n",
    "        all_y_pred_bnb.extend(y_pred_fold_bnb)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_bnb = confusion_matrix(y_test_fold_bnb, y_pred_fold_bnb)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_bnb = ConfusionMatrixDisplay(confusion_matrix=cm_bnb)\n",
    "        disp_bnb.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Bernoulli Naive Bayes\")\n",
    "        pname_bnb = method + \"_fold_\" + str(fold_number) + \"_Bernoulli_Naive_Bayes_confusion_matrix.png\"\n",
    "        plt.savefig(pname_bnb)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_bnb = time.time()\n",
    "    result(all_y_pred_bnb, all_y_test_bnb, \"Bernoulli Naive Bayes\", time_to_train, time_to_predict_fold_bnb)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Bernoulli Naive Bayes with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Bernoulli Naive Bayes\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## **42. CatBoost with k-fold Cross-Validation**\"\"\"\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_catboost = []\n",
    "    all_y_pred_catboost = []\n",
    "    start_cv_catboost = time.time()\n",
    "    time_to_predict_fold_catboost = 0\n",
    "    time_to_train=0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_catboost, test_index_catboost) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_catboost, X_test_fold_catboost = X_train.iloc[train_index_catboost], X_train.iloc[test_index_catboost]\n",
    "        y_train_fold_catboost, y_test_fold_catboost = y_train.iloc[train_index_catboost], y_train.iloc[test_index_catboost]\n",
    "\n",
    "        # Create and train the CatBoost model\n",
    "        start_train_fold_catboost = time.time()\n",
    "        catboost_model_fold_catboost = CatBoostClassifier(random_state=42)\n",
    "        catboost_model_fold_catboost.fit(X_train_fold_catboost, y_train_fold_catboost)\n",
    "        end_train_fold_catboost = time.time()\n",
    "        time_to_train += end_train_fold_catboost - start_train_fold_catboost\n",
    "\n",
    "        # Predict using the trained model\n",
    "        start_predict_fold_catboost = time.time()\n",
    "        y_pred_fold_catboost = catboost_model_fold_catboost.predict(X_test_fold_catboost)\n",
    "        end_predict_fold_catboost = time.time()\n",
    "        time_to_predict_fold_catboost += end_predict_fold_catboost - start_predict_fold_catboost\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_catboost.extend(y_test_fold_catboost)\n",
    "        all_y_pred_catboost.extend(y_pred_fold_catboost)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_catboost = confusion_matrix(y_test_fold_catboost, y_pred_fold_catboost)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_catboost = ConfusionMatrixDisplay(confusion_matrix=cm_catboost)\n",
    "        disp_catboost.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - CatBoost\")\n",
    "        pname_catboost = method + \"_fold_\" + str(fold_number) + \"_CatBoost_confusion_matrix.png\"\n",
    "        plt.savefig(pname_catboost)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_catboost = time.time()\n",
    "    result(all_y_pred_catboost, all_y_test_catboost, \"CatBoost\", time_to_train, time_to_predict_fold_catboost)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"CatBoost with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"CatBoost\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## **43. Centralised blending with k-fold Cross-Validation**\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_blend = []\n",
    "    all_y_pred_blend = []\n",
    "    start_cv_blend = time.time()\n",
    "    time_to_predict_fold_blend = 0\n",
    "    time_to_train = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_blend, test_index_blend) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_blend, X_test_fold_blend = X_train.iloc[train_index_blend], X_train.iloc[test_index_blend]\n",
    "        y_train_fold_blend, y_test_fold_blend = y_train.iloc[train_index_blend], y_train.iloc[test_index_blend]\n",
    "\n",
    "        # Define base models\n",
    "        base_model1 = DecisionTreeClassifier(random_state=24)\n",
    "        base_model2 = RandomForestClassifier(random_state=24)\n",
    "        base_model3 = LogisticRegression(random_state=24)\n",
    "\n",
    "        # Train base models\n",
    "        start_train_fold_blend = time.time()\n",
    "        base_model1.fit(X_train_fold_blend, y_train_fold_blend)\n",
    "        base_model2.fit(X_train_fold_blend, y_train_fold_blend)\n",
    "        base_model3.fit(X_train_fold_blend, y_train_fold_blend)\n",
    "        end_train_fold_blend = time.time()\n",
    "        time_to_train += end_train_fold_blend - start_train_fold_blend\n",
    "\n",
    "        # Make predictions on validation data\n",
    "        preds_val_base_model1 = base_model1.predict(X_test_fold_blend)\n",
    "        preds_val_base_model2 = base_model2.predict(X_test_fold_blend)\n",
    "        preds_val_base_model3 = base_model3.predict(X_test_fold_blend)\n",
    "\n",
    "        # Combine predictions from base models into a feature matrix for meta-model\n",
    "        X_val_meta_blend = np.column_stack((preds_val_base_model1, preds_val_base_model2, preds_val_base_model3))\n",
    "\n",
    "        # Train meta-model (blender)\n",
    "        blender_blend = LogisticRegression(random_state=24)\n",
    "        blender_blend.fit(X_val_meta_blend, y_test_fold_blend)\n",
    "\n",
    "        # Make predictions on test data using base models\n",
    "        preds_test_base_model1 = base_model1.predict(X_test_fold_blend)\n",
    "        preds_test_base_model2 = base_model2.predict(X_test_fold_blend)\n",
    "        preds_test_base_model3 = base_model3.predict(X_test_fold_blend)\n",
    "\n",
    "        # Combine predictions from base models into a feature matrix for meta-model\n",
    "        X_test_meta_blend = np.column_stack((preds_test_base_model1, preds_test_base_model2, preds_test_base_model3))\n",
    "\n",
    "        # Make predictions on test data using meta-model\n",
    "        preds_test_meta_blend = blender_blend.predict(X_test_meta_blend)\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_blend.extend(y_test_fold_blend)\n",
    "        all_y_pred_blend.extend(preds_test_meta_blend)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_blend = confusion_matrix(y_test_fold_blend, preds_test_meta_blend)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_blend = ConfusionMatrixDisplay(confusion_matrix=cm_blend)\n",
    "        disp_blend.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Centralised Blending\")\n",
    "        pname_blend = method + \"_fold_\" + str(fold_number) + \"_Centralised_Blending_confusion_matrix.png\"\n",
    "        plt.savefig(pname_blend)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_blend = time.time()\n",
    "    result(all_y_pred_blend, all_y_test_blend, \"Centralised Blending\", time_to_train, time_to_predict_fold_blend)\n",
    "\n",
    "    \"\"\"44.## Binary Logical Circular Neural Network (BLoCNet) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_blocnet = []\n",
    "    all_y_pred_blocnet = []\n",
    "    start_cv_blocnet = time.time()\n",
    "    time_to_predict_fold_blocnet = 0\n",
    "    time_to_train = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_blocnet, test_index_blocnet) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_blocnet, X_test_fold_blocnet = X_train.iloc[train_index_blocnet], X_train.iloc[test_index_blocnet]\n",
    "        y_train_fold_blocnet, y_test_fold_blocnet = y_train.iloc[train_index_blocnet], y_train.iloc[test_index_blocnet]\n",
    "\n",
    "        # Define the architecture of the BLoCNet\n",
    "        model_blocnet = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_fold_blocnet.shape[1],)),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(9, activation='softmax')  # Multi-class classification, so softmax activation\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model_blocnet.compile(optimizer='adam',\n",
    "                            loss='sparse_categorical_crossentropy',  # Multi-class classification, so sparse categorical crossentropy loss\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        start_train_fold_blocnet = time.time()\n",
    "        history_blocnet = model_blocnet.fit(X_train_fold_blocnet, y_train_fold_blocnet, epochs=10, batch_size=32, validation_split=0.2)\n",
    "        end_train_fold_blocnet = time.time()\n",
    "        time_to_train += end_train_fold_blocnet - start_train_fold_blocnet\n",
    "\n",
    "        # Evaluate the model\n",
    "        start_predict_fold_blocnet = time.time()\n",
    "        y_pred_fold_blocnet = model_blocnet.predict(X_test_fold_blocnet)\n",
    "        y_pred_fold_blocnet = np.argmax(y_pred_fold_blocnet, axis=1)\n",
    "        end_predict_fold_blocnet = time.time()\n",
    "        time_to_predict_fold_blocnet += end_predict_fold_blocnet - start_predict_fold_blocnet\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_blocnet.extend(y_test_fold_blocnet)\n",
    "        all_y_pred_blocnet.extend(y_pred_fold_blocnet)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_blocnet = confusion_matrix(y_test_fold_blocnet, y_pred_fold_blocnet)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_blocnet = ConfusionMatrixDisplay(confusion_matrix=cm_blocnet)\n",
    "        disp_blocnet.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - BLoCNet\")\n",
    "        pname_blocnet = method + \"_fold_\" + str(fold_number) + \"_BLoCNet_confusion_matrix.png\"\n",
    "        plt.savefig(pname_blocnet)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_blocnet = time.time()\n",
    "    result(all_y_pred_blocnet, all_y_test_blocnet, \"BLoCNet\", time_to_train, time_to_predict_fold_blocnet)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"BLoCNet with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"BLoCNet\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 45.constructive_learning with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_constructive_learning = []\n",
    "    all_y_pred_constructive_learning = []\n",
    "    start_cv_constructive_learning = time.time()\n",
    "    time_to_predict_fold_constructive_learning = 0\n",
    "    time_to_train = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_constructive_learning, test_index_constructive_learning) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_constructive_learning, X_test_fold_constructive_learning = X_train.iloc[train_index_constructive_learning], X_train.iloc[test_index_constructive_learning]\n",
    "        y_train_fold_constructive_learning, y_test_fold_constructive_learning = y_train.iloc[train_index_constructive_learning], y_train.iloc[test_index_constructive_learning]\n",
    "\n",
    "        # Create a basic Decision Tree model for this fold\n",
    "        base_model_fold_constructive_learning = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "        # Train the base model for this fold\n",
    "        start_train_fold_constructive_learning = time.time()\n",
    "        base_model_fold_constructive_learning.fit(X_train_fold_constructive_learning, y_train_fold_constructive_learning)\n",
    "        end_train_fold_constructive_learning = time.time()\n",
    "        time_to_train += end_train_fold_constructive_learning - start_train_fold_constructive_learning\n",
    "\n",
    "        # Evaluate the base model for this fold\n",
    "        start_predict_fold_constructive_learning = time.time()\n",
    "        y_pred_fold_constructive_learning = base_model_fold_constructive_learning.predict(X_test_fold_constructive_learning)\n",
    "        end_predict_fold_constructive_learning = time.time()\n",
    "        time_to_predict_fold_constructive_learning += end_predict_fold_constructive_learning - start_predict_fold_constructive_learning\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_constructive_learning.extend(y_test_fold_constructive_learning)\n",
    "        all_y_pred_constructive_learning.extend(y_pred_fold_constructive_learning)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_constructive_learning = confusion_matrix(y_test_fold_constructive_learning, y_pred_fold_constructive_learning)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_constructive_learning = ConfusionMatrixDisplay(confusion_matrix=cm_constructive_learning)\n",
    "        disp_constructive_learning.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - constructive_learning\")\n",
    "        pname_constructive_learning = method + \"_fold_\" + str(fold_number) + \"_constructive_learning_confusion_matrix.png\"\n",
    "        plt.savefig(pname_constructive_learning)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_constructive_learning = time.time()\n",
    "    result(all_y_pred_constructive_learning, all_y_test_constructive_learning, \"constructive_learning\", time_to_train, time_to_predict_fold_constructive_learning)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"constructive_learning with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"constructive_learning\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 46. Artificial Immune System (AIS) with k-fold Cross-Validation\"\"\"\n",
    "    class AISModel:\n",
    "        def __init__(self, base_model):\n",
    "            self.base_model = base_model\n",
    "\n",
    "        def fit(self, X_train, y_train):\n",
    "            # AIS training algorithm\n",
    "            self.base_model.fit(X_train, y_train)\n",
    "\n",
    "        def predict(self, X_test):\n",
    "            # AIS prediction algorithm\n",
    "            y_pred = self.base_model.predict(X_test)\n",
    "            return y_pred\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_ais = []\n",
    "    all_y_pred_ais = []\n",
    "    start_cv_ais = time.time()\n",
    "    time_to_predict_fold_ais = 0\n",
    "    time_to_train = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_ais, test_index_ais) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_ais, X_test_fold_ais = X_train.iloc[train_index_ais], X_train.iloc[test_index_ais]\n",
    "        y_train_fold_ais, y_test_fold_ais = y_train.iloc[train_index_ais], y_train.iloc[test_index_ais]\n",
    "\n",
    "        # Create an instance of RandomForestClassifier as the base learner for this fold\n",
    "        base_model_fold_ais = RandomForestClassifier(random_state=24)\n",
    "\n",
    "        # Create an instance of AISModel with the base learner for this fold\n",
    "        ais_model_fold_ais = AISModel(base_model_fold_ais)\n",
    "\n",
    "        # Train the AIS model for this fold\n",
    "        start_train_fold_ais = time.time()\n",
    "        ais_model_fold_ais.fit(X_train_fold_ais, y_train_fold_ais)\n",
    "        end_train_fold_ais = time.time()\n",
    "        time_to_train += end_train_fold_ais - start_train_fold_ais\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_ais = time.time()\n",
    "        y_pred_fold_ais = ais_model_fold_ais.predict(X_test_fold_ais)\n",
    "        end_predict_fold_ais = time.time()\n",
    "        time_to_predict_fold_ais += end_predict_fold_ais - start_predict_fold_ais\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_ais.extend(y_test_fold_ais)\n",
    "        all_y_pred_ais.extend(y_pred_fold_ais)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_ais = confusion_matrix(y_test_fold_ais, y_pred_fold_ais)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_ais = ConfusionMatrixDisplay(confusion_matrix=cm_ais)\n",
    "        disp_ais.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - AIS\")\n",
    "        pname_ais = method + \"_fold_\" + str(fold_number) + \"_AIS_confusion_matrix.png\"\n",
    "        plt.savefig(pname_ais)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_ais = time.time()\n",
    "    result(all_y_pred_ais, all_y_test_ais, \"AIS\", time_to_train, time_to_predict_fold_ais)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"AIS with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"AIS\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 48. GBBK Algorithm with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gbkk = []\n",
    "    all_y_pred_gbkk = []\n",
    "    start_cv_gbkk = time.time()\n",
    "    time_to_predict_fold_gbkk = 0\n",
    "    time_to_train_gbkk = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_gbkk, test_index_gbkk) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_gbkk, X_test_fold_gbkk = X_train.iloc[train_index_gbkk], X_train.iloc[test_index_gbkk]\n",
    "        y_train_fold_gbkk, y_test_fold_gbkk = y_train.iloc[train_index_gbkk], y_train.iloc[test_index_gbkk]\n",
    "\n",
    "        # Initialize Gaussian Naive Bayes (GBBK) model for this fold\n",
    "        gbbk_model_fold_gbkk = GaussianNB()\n",
    "\n",
    "        # Train the GBBK model for this fold\n",
    "        start_train_fold_gbkk = time.time()\n",
    "        gbbk_model_fold_gbkk.fit(X_train_fold_gbkk, y_train_fold_gbkk)\n",
    "        end_train_fold_gbkk = time.time()\n",
    "        time_to_train_gbkk += end_train_fold_gbkk - start_train_fold_gbkk\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_gbkk = time.time()\n",
    "        y_pred_fold_gbkk = gbbk_model_fold_gbkk.predict(X_test_fold_gbkk)\n",
    "        end_predict_fold_gbkk = time.time()\n",
    "        time_to_predict_fold_gbkk += end_predict_fold_gbkk - start_predict_fold_gbkk\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gbkk.extend(y_test_fold_gbkk)\n",
    "        all_y_pred_gbkk.extend(y_pred_fold_gbkk)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_gbkk = confusion_matrix(y_test_fold_gbkk, y_pred_fold_gbkk)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_gbkk = ConfusionMatrixDisplay(confusion_matrix=cm_gbkk)\n",
    "        disp_gbkk.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - GBBK\")\n",
    "        pname_gbkk = method + \"_fold_\" + str(fold_number) + \"_GBBK_confusion_matrix.png\"\n",
    "        plt.savefig(pname_gbkk)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_gbkk = time.time()\n",
    "    result(all_y_pred_gbkk, all_y_test_gbkk, \"GBBK\", time_to_train_gbkk, time_to_predict_fold_gbkk)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"GBBK with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"GBBK\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 48. GE SVM Algorithm with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gbkk = []\n",
    "    all_y_pred_gbkk = []\n",
    "    start_cv_gbkk = time.time()\n",
    "    time_to_predict_fold_gbkk = 0\n",
    "    time_to_train_gbkk = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_gbkk, test_index_gbkk) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_gbkk, X_test_fold_gbkk = X_train.iloc[train_index_gbkk], X_train.iloc[test_index_gbkk]\n",
    "        y_train_fold_gbkk, y_test_fold_gbkk = y_train.iloc[train_index_gbkk], y_train.iloc[test_index_gbkk]\n",
    "\n",
    "        # Initialize Gaussian Naive Bayes (GBBK) model for this fold\n",
    "        gbbk_model_fold_gbkk = SVC(kernel='rbf', decision_function_shape='ovo')\n",
    "\n",
    "        # Train the GBBK model for this fold\n",
    "        start_train_fold_gbkk = time.time()\n",
    "        gbbk_model_fold_gbkk.fit(X_train_fold_gbkk, y_train_fold_gbkk)\n",
    "        end_train_fold_gbkk = time.time()\n",
    "        time_to_train_gbkk += end_train_fold_gbkk - start_train_fold_gbkk\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_gbkk = time.time()\n",
    "        y_pred_fold_gbkk = gbbk_model_fold_gbkk.predict(X_test_fold_gbkk)\n",
    "        end_predict_fold_gbkk = time.time()\n",
    "        time_to_predict_fold_gbkk += end_predict_fold_gbkk - start_predict_fold_gbkk\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gbkk.extend(y_test_fold_gbkk)\n",
    "        all_y_pred_gbkk.extend(y_pred_fold_gbkk)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_gbkk = confusion_matrix(y_test_fold_gbkk, y_pred_fold_gbkk)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_gbkk = ConfusionMatrixDisplay(confusion_matrix=cm_gbkk)\n",
    "        disp_gbkk.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - GE SVM\")\n",
    "        pname_gbkk = method + \"_fold_\" + str(fold_number) + \"_GE_SVM_confusion_matrix.png\"\n",
    "        plt.savefig(pname_gbkk)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_gbkk = time.time()\n",
    "    result(all_y_pred_gbkk, all_y_test_gbkk, \"GE SVM\", time_to_train_gbkk, time_to_predict_fold_gbkk)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"GE SVM with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"GE SVM\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 51. Hidden Naive Bayes (HNB) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_hnb = []\n",
    "    all_y_pred_hnb = []\n",
    "    start_cv_hnb = time.time()\n",
    "    time_to_predict_fold_hnb = 0\n",
    "    time_to_train_hnb = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_hnb, test_index_hnb) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_hnb, X_test_fold_hnb = X_train.iloc[train_index_hnb], X_train.iloc[test_index_hnb]\n",
    "        y_train_fold_hnb, y_test_fold_hnb = y_train.iloc[train_index_hnb], y_train.iloc[test_index_hnb]\n",
    "\n",
    "        # Train the HNB model for this fold\n",
    "        hnb_model_fold = GaussianNB()\n",
    "        start_train_fold_hnb = time.time()\n",
    "        hnb_model_fold.fit(pd.DataFrame(X_train_fold_hnb), pd.DataFrame(y_train_fold_hnb))\n",
    "        end_train_fold_hnb = time.time()\n",
    "        time_to_train_hnb += end_train_fold_hnb - start_train_fold_hnb\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_hnb = time.time()\n",
    "        y_pred_fold_hnb = hnb_model_fold.predict(X_test_fold_hnb.values)\n",
    "        end_predict_fold_hnb = time.time()\n",
    "        time_to_predict_fold_hnb += end_predict_fold_hnb - start_predict_fold_hnb\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_hnb.extend(y_test_fold_hnb)\n",
    "        all_y_pred_hnb.extend(y_pred_fold_hnb)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_hnb = confusion_matrix(y_test_fold_hnb, y_pred_fold_hnb)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_hnb = ConfusionMatrixDisplay(confusion_matrix=cm_hnb)\n",
    "        disp_hnb.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - HNB\")\n",
    "        pname_hnb = method + \"_fold_\" + str(fold_number) + \"_HNB_confusion_matrix.png\"\n",
    "        plt.savefig(pname_hnb)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_hnb = time.time()\n",
    "    result(all_y_pred_hnb, all_y_test_hnb, \"Hidden Naive Bayes (HNB)\", time_to_train_hnb, time_to_predict_fold_hnb)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"HNB with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Hidden Naive Bayes\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 52. HistGradientBoostingClassifier with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_hgb = []\n",
    "    all_y_pred_hgb = []\n",
    "    start_cv_hgb = time.time()\n",
    "    time_to_predict_fold_hgb = 0\n",
    "    time_to_train_hgb = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_hgb, test_index_hgb) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_hgb, X_test_fold_hgb = X_train.iloc[train_index_hgb], X_train.iloc[test_index_hgb]\n",
    "        y_train_fold_hgb, y_test_fold_hgb = y_train.iloc[train_index_hgb], y_train.iloc[test_index_hgb]\n",
    "\n",
    "        # Train the HistGradientBoostingClassifier model for this fold\n",
    "        hgb_model_fold = HistGradientBoostingClassifier(random_state=24)\n",
    "        start_train_fold_hgb = time.time()\n",
    "        hgb_model_fold.fit(X_train_fold_hgb, y_train_fold_hgb)\n",
    "        end_train_fold_hgb = time.time()\n",
    "        time_to_train_hgb += end_train_fold_hgb - start_train_fold_hgb\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_hgb = time.time()\n",
    "        y_pred_fold_hgb = hgb_model_fold.predict(X_test_fold_hgb)\n",
    "        end_predict_fold_hgb = time.time()\n",
    "        time_to_predict_fold_hgb += end_predict_fold_hgb - start_predict_fold_hgb\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_hgb.extend(y_test_fold_hgb)\n",
    "        all_y_pred_hgb.extend(y_pred_fold_hgb)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_hgb = confusion_matrix(y_test_fold_hgb, y_pred_fold_hgb)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_hgb = ConfusionMatrixDisplay(confusion_matrix=cm_hgb)\n",
    "        disp_hgb.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - HistGradientBoostingClassifier\")\n",
    "        pname_hgb = method + \"_fold_\" + str(fold_number) + \"_HistGradientBoostingClassifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname_hgb)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_hgb = time.time()\n",
    "    result(all_y_pred_hgb, all_y_test_hgb, \"HistGradientBoostingClassifier\", time_to_train_hgb, time_to_predict_fold_hgb)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"HistGradientBoostingClassifier with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"HistGradientBoostingClassifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## IGRF-RFE with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize Decision Tree Classifier\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=24)\n",
    "\n",
    "    # Initialize RFE (Recursive Feature Elimination) with Decision Tree Classifier as estimator\n",
    "    rfe = RFE(estimator=dt_classifier)\n",
    "\n",
    "    # Initialize k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits= n_splits_for_cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_igrf_rfe = []\n",
    "    all_y_pred_igrf_rfe = []\n",
    "    start_cv_igrf_rfe = time.time()\n",
    "    time_to_predict_fold_igrf_rfe = 0\n",
    "    time_to_train_igrf_rfe = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_igrf_rfe, test_index_igrf_rfe) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_igrf_rfe, X_test_fold_igrf_rfe = X_train.iloc[train_index_igrf_rfe], X_train.iloc[test_index_igrf_rfe]\n",
    "        y_train_fold_igrf_rfe, y_test_fold_igrf_rfe = y_train.iloc[train_index_igrf_rfe], y_train.iloc[test_index_igrf_rfe]\n",
    "\n",
    "        # Fit RFE on training data for this fold\n",
    "        start_feature_selection_fold_igrf_rfe = time.time()\n",
    "        rfe.fit(X_train_fold_igrf_rfe, y_train_fold_igrf_rfe)\n",
    "        end_feature_selection_fold_igrf_rfe = time.time()\n",
    "\n",
    "        # Select features based on RFE ranking\n",
    "        X_train_rfe_fold_igrf_rfe = rfe.transform(X_train_fold_igrf_rfe)\n",
    "        X_test_rfe_fold_igrf_rfe = rfe.transform(X_test_fold_igrf_rfe)\n",
    "\n",
    "        # Train Decision Tree Classifier using selected features for this fold\n",
    "        start_train_fold_igrf_rfe = time.time()\n",
    "        dt_classifier.fit(X_train_rfe_fold_igrf_rfe, y_train_fold_igrf_rfe)\n",
    "        end_train_fold_igrf_rfe = time.time()\n",
    "        time_to_train_igrf_rfe += end_train_fold_igrf_rfe - start_train_fold_igrf_rfe\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_igrf_rfe = time.time()\n",
    "        y_pred_fold_igrf_rfe = dt_classifier.predict(X_test_rfe_fold_igrf_rfe)\n",
    "        end_predict_fold_igrf_rfe = time.time()\n",
    "        time_to_predict_fold_igrf_rfe += end_predict_fold_igrf_rfe - start_predict_fold_igrf_rfe\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_igrf_rfe.extend(y_test_fold_igrf_rfe)\n",
    "        all_y_pred_igrf_rfe.extend(y_pred_fold_igrf_rfe)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_igrf_rfe = confusion_matrix(y_test_fold_igrf_rfe, y_pred_fold_igrf_rfe)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_igrf_rfe = ConfusionMatrixDisplay(confusion_matrix=cm_igrf_rfe)\n",
    "        disp_igrf_rfe.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - IGRF-RFE\")\n",
    "        pname_igrf_rfe = method + \"_fold_\" + str(fold_number) + \"_IGRF_RFE_confusion_matrix.png\"\n",
    "        plt.savefig(pname_igrf_rfe)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_igrf_rfe = time.time()\n",
    "    result(all_y_pred_igrf_rfe, all_y_test_igrf_rfe, \"IGRF-RFE with k-fold Cross-Validation\", time_to_train_igrf_rfe, time_to_predict_fold_igrf_rfe)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"IGRF-RFE with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"IGRF-RFE\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 55. Independent Component Analysis (ICA) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_ica = []\n",
    "    all_y_pred_ica = []\n",
    "    start_cv_ica = time.time()\n",
    "    time_to_predict_fold_ica = 0\n",
    "    time_to_train_ica = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_ica, test_index_ica) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_ica, X_test_fold_ica = X_train.iloc[train_index_ica], X_train.iloc[test_index_ica]\n",
    "        y_train_fold_ica, y_test_fold_ica = y_train.iloc[train_index_ica], y_train.iloc[test_index_ica]\n",
    "\n",
    "        # Perform Independent Component Analysis (ICA) for dimensionality reduction\n",
    "        ica_fold = FastICA(n_components=10, random_state=42)\n",
    "        X_train_ica_fold = ica_fold.fit_transform(X_train_fold_ica)\n",
    "        X_test_ica_fold = ica_fold.transform(X_test_fold_ica)\n",
    "\n",
    "        # Normalize the data\n",
    "        scaler_fold = StandardScaler()\n",
    "        X_train_ica_fold = scaler_fold.fit_transform(X_train_ica_fold)\n",
    "        X_test_ica_fold = scaler_fold.transform(X_test_ica_fold)\n",
    "\n",
    "        # Train a RandomForestClassifier on the transformed data for this fold\n",
    "        rf_model_fold_ica = RandomForestClassifier(random_state=24)\n",
    "        start_train_fold_ica = time.time()\n",
    "        rf_model_fold_ica.fit(X_train_ica_fold, y_train_fold_ica)\n",
    "        end_train_fold_ica = time.time()\n",
    "        time_to_train_ica += end_train_fold_ica - start_train_fold_ica\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_ica = time.time()\n",
    "        y_pred_fold_ica = rf_model_fold_ica.predict(X_test_ica_fold)\n",
    "        end_predict_fold_ica = time.time()\n",
    "        time_to_predict_fold_ica += end_predict_fold_ica - start_predict_fold_ica\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_ica.extend(y_test_fold_ica)\n",
    "        all_y_pred_ica.extend(y_pred_fold_ica)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_ica = confusion_matrix(y_test_fold_ica, y_pred_fold_ica)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_ica = ConfusionMatrixDisplay(confusion_matrix=cm_ica)\n",
    "        disp_ica.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - ICA\")\n",
    "        pname_ica = method + \"_fold_\" + str(fold_number) + \"_ICA_confusion_matrix.png\"\n",
    "        plt.savefig(pname_ica)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_ica = time.time()\n",
    "    result(all_y_pred_ica, all_y_test_ica, \"ICA\", time_to_train_ica, time_to_predict_fold_ica)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"ICA with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"ICA\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 56. Lasso Regression with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_lasso = []\n",
    "    all_y_pred_lasso = []\n",
    "    start_cv_lasso = time.time()\n",
    "    time_to_predict_fold_lasso = 0\n",
    "    time_to_train_lasso = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_lasso, test_index_lasso) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_lasso, X_test_fold_lasso = X_train.iloc[train_index_lasso], X_train.iloc[test_index_lasso]\n",
    "        y_train_fold_lasso, y_test_fold_lasso = y_train.iloc[train_index_lasso], y_train.iloc[test_index_lasso]\n",
    "\n",
    "        # Initialize Lasso Regression model\n",
    "        lasso_model_fold = LogisticRegression(penalty='l1', solver='saga', random_state=24, max_iter=1000)\n",
    "\n",
    "        # Train the Lasso Regression model for this fold\n",
    "        start_train_fold_lasso = time.time()\n",
    "        lasso_model_fold.fit(X_train_fold_lasso, y_train_fold_lasso)\n",
    "        end_train_fold_lasso = time.time()\n",
    "        time_to_train_lasso += end_train_fold_lasso - start_train_fold_lasso\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_lasso = time.time()\n",
    "        y_pred_fold_lasso = lasso_model_fold.predict(X_test_fold_lasso)\n",
    "        end_predict_fold_lasso = time.time()\n",
    "        time_to_predict_fold_lasso += end_predict_fold_lasso - start_predict_fold_lasso\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_lasso.extend(y_test_fold_lasso)\n",
    "        all_y_pred_lasso.extend(y_pred_fold_lasso)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_lasso = confusion_matrix(y_test_fold_lasso, y_pred_fold_lasso)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_lasso = ConfusionMatrixDisplay(confusion_matrix=cm_lasso)\n",
    "        disp_lasso.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Lasso Regression\")\n",
    "        pname_lasso = method + \"_fold_\" + str(fold_number) + \"_Lasso_Regression_confusion_matrix.png\"\n",
    "        plt.savefig(pname_lasso)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_lasso = time.time()\n",
    "    result(all_y_pred_lasso, all_y_test_lasso, \"Lasso Regression\", time_to_train_lasso, time_to_predict_fold_lasso)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Lasso Regression with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Lasso\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 57. Meta (KNN) with Neighbors (K) and k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_meta_knn = []\n",
    "    all_y_pred_meta_knn = []\n",
    "    start_cv_meta_knn = time.time()\n",
    "    time_to_predict_fold_meta_knn = 0\n",
    "    time_to_train_meta_knn = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_meta_knn, test_index_meta_knn) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_meta_knn, X_test_fold_meta_knn = X_train.iloc[train_index_meta_knn], X_train.iloc[test_index_meta_knn]\n",
    "        y_train_fold_meta_knn, y_test_fold_meta_knn = y_train.iloc[train_index_meta_knn], y_train.iloc[test_index_meta_knn]\n",
    "\n",
    "        # Initialize base classifier (KNN) for meta-learning\n",
    "        k = 5\n",
    "        base_classifier_meta_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "        # Initialize BaggingClassifier for meta-learning with KNN base classifier\n",
    "        meta_knn_model_fold = BaggingClassifier(base_classifier_meta_knn, n_estimators=10, random_state=42)\n",
    "\n",
    "        # Train the meta KNN model for this fold\n",
    "        start_train_fold_meta_knn = time.time()\n",
    "        meta_knn_model_fold.fit(X_train_fold_meta_knn, y_train_fold_meta_knn)\n",
    "        end_train_fold_meta_knn = time.time()\n",
    "        time_to_train_meta_knn += end_train_fold_meta_knn - start_train_fold_meta_knn\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_meta_knn = time.time()\n",
    "        y_pred_fold_meta_knn = meta_knn_model_fold.predict(X_test_fold_meta_knn)\n",
    "        end_predict_fold_meta_knn = time.time()\n",
    "        time_to_predict_fold_meta_knn += end_predict_fold_meta_knn - start_predict_fold_meta_knn\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_meta_knn.extend(y_test_fold_meta_knn)\n",
    "        all_y_pred_meta_knn.extend(y_pred_fold_meta_knn)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_meta_knn = confusion_matrix(y_test_fold_meta_knn, y_pred_fold_meta_knn)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_meta_knn = ConfusionMatrixDisplay(confusion_matrix=cm_meta_knn)\n",
    "        disp_meta_knn.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Meta (KNN)\")\n",
    "        pname_meta_knn = method + \"_fold_\" + str(fold_number) + \"_Meta_KNN_confusion_matrix.png\"\n",
    "        plt.savefig(pname_meta_knn)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_meta_knn = time.time()\n",
    "    result(all_y_pred_meta_knn, all_y_test_meta_knn, \"Meta (KNN)\", time_to_train_meta_knn, time_to_predict_fold_meta_knn)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Meta (KNN) with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"KNN\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## T-SNE Random Forest (T-SNERF) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize T-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "    # Initialize Random Forest Classifier\n",
    "    rf_model = RandomForestClassifier(random_state=24)\n",
    "\n",
    "    # Initialize k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits= n_splits_for_cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_tsnerf = []\n",
    "    all_y_pred_tsnerf = []\n",
    "    start_cv_tsnerf = time.time()\n",
    "    time_to_predict_fold_tsnerf = 0\n",
    "    time_to_train_tsnerf = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_tsnerf, test_index_tsnerf) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_tsnerf, X_test_fold_tsnerf = X_train.iloc[train_index_tsnerf], X_train.iloc[test_index_tsnerf]\n",
    "        y_train_fold_tsnerf, y_test_fold_tsnerf = y_train.iloc[train_index_tsnerf], y_train.iloc[test_index_tsnerf]\n",
    "\n",
    "        # Train T-SNE on the training data for this fold\n",
    "        start_train_fold_tsnerf = time.time()\n",
    "        X_train_tsne_fold_tsnerf = tsne.fit_transform(X_train_fold_tsnerf)\n",
    "        end_train_fold_tsnerf = time.time()\n",
    "        time_to_train_tsnerf += end_train_fold_tsnerf - start_train_fold_tsnerf\n",
    "\n",
    "        # Train Random Forest on the T-SNE transformed data for this fold\n",
    "        start_rf_fold_tsnerf = time.time()\n",
    "        rf_model.fit(X_train_tsne_fold_tsnerf, y_train_fold_tsnerf)\n",
    "        end_rf_fold_tsnerf = time.time()\n",
    "\n",
    "        # Transform the test data using the trained T-SNE model for this fold\n",
    "        start_transform_fold_tsnerf = time.time()\n",
    "        X_test_tsne_fold_tsnerf = tsne.fit_transform(X_test_fold_tsnerf)\n",
    "        end_transform_fold_tsnerf = time.time()\n",
    "\n",
    "        # Predict using the trained Random Forest model for this fold\n",
    "        start_predict_fold_tsnerf = time.time()\n",
    "        y_pred_fold_tsnerf = rf_model.predict(X_test_tsne_fold_tsnerf)\n",
    "        end_predict_fold_tsnerf = time.time()\n",
    "        time_to_predict_fold_tsnerf += end_predict_fold_tsnerf - start_predict_fold_tsnerf\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_tsnerf.extend(y_test_fold_tsnerf)\n",
    "        all_y_pred_tsnerf.extend(y_pred_fold_tsnerf)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_tsnerf = confusion_matrix(y_test_fold_tsnerf, y_pred_fold_tsnerf)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_tsnerf = ConfusionMatrixDisplay(confusion_matrix=cm_tsnerf)\n",
    "        disp_tsnerf.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - T-SNE Random Forest (T-SNERF)\")\n",
    "        pname_tsnerf = method + \"_fold_\" + str(fold_number) + \"_TSNE_confusion_matrix.png\"\n",
    "        plt.savefig(pname_tsnerf)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_tsnerf = time.time()\n",
    "    result(all_y_pred_tsnerf, all_y_test_tsnerf, \"T-SNE Random Forest (T-SNERF) with k-fold Cross-Validation\", time_to_train_tsnerf, time_to_predict_fold_tsnerf)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"T-SNE Random Forest (T-SNERF) with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"T-SNE Random Forest\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 60. Projected Gradient Descent (PGD) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_pgd = []\n",
    "    all_y_pred_pgd = []\n",
    "    start_cv_pgd = time.time()\n",
    "    time_to_predict_fold_pgd = 0\n",
    "    time_to_train_pgd = 0\n",
    "\n",
    "    # Define a simple neural network model\n",
    "    class SimpleNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SimpleNN, self).__init__()\n",
    "            self.fc1 = nn.Linear(X_train.shape[1], 128)\n",
    "            self.fc2 = nn.Linear(128, len(np.unique(y_train)))\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_pgd, test_index_pgd) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_pgd, X_test_fold_pgd = X_train.iloc[train_index_pgd], X_train.iloc[test_index_pgd]\n",
    "        y_train_fold_pgd, y_test_fold_pgd = y_train.iloc[train_index_pgd], y_train.iloc[test_index_pgd]\n",
    "\n",
    "        # Convert pandas DataFrame to PyTorch tensors for this fold\n",
    "        X_train_tensor_pgd = torch.tensor(X_train_fold_pgd.values, dtype=torch.float32)\n",
    "        y_train_tensor_pgd = torch.tensor(y_train_fold_pgd.values, dtype=torch.long)\n",
    "        X_test_tensor_pgd = torch.tensor(X_test_fold_pgd.values, dtype=torch.float32)\n",
    "\n",
    "        # Create a DataLoader for training for this fold\n",
    "        train_dataset_pgd = TensorDataset(X_train_tensor_pgd, y_train_tensor_pgd)\n",
    "        train_loader_pgd = DataLoader(train_dataset_pgd, batch_size=64, shuffle=True)\n",
    "\n",
    "        # Define model, loss function, and optimizer for this fold\n",
    "        model_pgd = SimpleNN()\n",
    "        criterion_pgd = nn.CrossEntropyLoss()\n",
    "        optimizer_pgd = optim.Adam(model_pgd.parameters(), lr=0.001)\n",
    "\n",
    "        # Train the model for this fold\n",
    "        start_train_fold_pgd = time.time()\n",
    "        for epoch in range(10):\n",
    "            for inputs, labels in train_loader_pgd:\n",
    "                optimizer_pgd.zero_grad()\n",
    "                outputs = model_pgd(inputs)\n",
    "                loss = criterion_pgd(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer_pgd.step()\n",
    "        end_train_fold_pgd = time.time()\n",
    "        time_to_train_pgd += end_train_fold_pgd - start_train_fold_pgd\n",
    "\n",
    "        # Evaluate the model for this fold\n",
    "        model_pgd.eval()\n",
    "        start_predict_fold_pgd = time.time()\n",
    "        with torch.no_grad():\n",
    "            y_pred_fold_pgd = model_pgd(X_test_tensor_pgd).argmax(dim=1).detach().numpy()\n",
    "        end_predict_fold_pgd = time.time()\n",
    "        time_to_predict_fold_pgd += end_predict_fold_pgd - start_predict_fold_pgd\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_pgd.extend(y_test_fold_pgd)\n",
    "        all_y_pred_pgd.extend(y_pred_fold_pgd)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_pgd = confusion_matrix(y_test_fold_pgd, y_pred_fold_pgd)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_pgd = ConfusionMatrixDisplay(confusion_matrix=cm_pgd)\n",
    "        disp_pgd.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Projected Gradient Descent (PGD)\")\n",
    "        pname_pgd = method + \"_fold_\" + str(fold_number) + \"_PGD_confusion_matrix.png\"\n",
    "        plt.savefig(pname_pgd)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_pgd = time.time()\n",
    "    result(all_y_pred_pgd, all_y_test_pgd, \"Projected Gradient Descent (PGD)\", time_to_train_pgd, time_to_predict_fold_pgd)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Projected Gradient Descent (PGD) with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Projected Gradient Descent\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 61. Principal Component Analysis (PCA) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_pca = []\n",
    "    all_y_pred_pca = []\n",
    "    start_cv_pca = time.time()\n",
    "    time_to_predict_fold_pca = 0\n",
    "    time_to_train_pca = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_pca, test_index_pca) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_pca, X_test_fold_pca = X_train.iloc[train_index_pca], X_train.iloc[test_index_pca]\n",
    "        y_train_fold_pca, y_test_fold_pca = y_train.iloc[train_index_pca], y_train.iloc[test_index_pca]\n",
    "\n",
    "        # Convert y_test_fold_pca to integer labels if it's not already\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_test_encoded_fold_pca = label_encoder.fit_transform(y_test_fold_pca)\n",
    "\n",
    "        # Apply PCA to reduce dimensionality for this fold\n",
    "        pca_fold_pca = PCA(n_components=0.95, random_state=42)  # Retain 95% of variance\n",
    "        X_train_fold_pca = pca_fold_pca.fit_transform(X_train_fold_pca)\n",
    "        X_test_fold_pca = pca_fold_pca.transform(X_test_fold_pca)\n",
    "\n",
    "        # Train the classifier on the reduced dimensionality data for this fold\n",
    "        dt_multi_fold_pca = DecisionTreeClassifier(random_state=24)\n",
    "        start_train_fold_pca = time.time()\n",
    "        dt_multi_fold_pca.fit(X_train_fold_pca, y_train_fold_pca)\n",
    "        end_train_fold_pca = time.time()\n",
    "        time_to_train_pca += end_train_fold_pca - start_train_fold_pca\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_pca = time.time()\n",
    "        y_pred_fold_pca = dt_multi_fold_pca.predict(X_test_fold_pca)\n",
    "        end_predict_fold_pca = time.time()\n",
    "        time_to_predict_fold_pca += end_predict_fold_pca - start_predict_fold_pca\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_pca.extend(y_test_encoded_fold_pca)\n",
    "        all_y_pred_pca.extend(y_pred_fold_pca)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_pca = confusion_matrix(y_test_encoded_fold_pca, y_pred_fold_pca)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_pca = ConfusionMatrixDisplay(confusion_matrix=cm_pca)\n",
    "        disp_pca.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - PCA\")\n",
    "        pname_pca = method + \"_fold_\" + str(fold_number) + \"_PCA_confusion_matrix.png\"\n",
    "        plt.savefig(pname_pca)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_pca = time.time()\n",
    "    result(all_y_pred_pca, all_y_test_pca, \"PCA\", time_to_train_pca, time_to_predict_fold_pca)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"PCA with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"PCA\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 48. RBF SVM Algorithm with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gbkk = []\n",
    "    all_y_pred_gbkk = []\n",
    "    start_cv_gbkk = time.time()\n",
    "    time_to_predict_fold_gbkk = 0\n",
    "    time_to_train_gbkk = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_gbkk, test_index_gbkk) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_gbkk, X_test_fold_gbkk = X_train.iloc[train_index_gbkk], X_train.iloc[test_index_gbkk]\n",
    "        y_train_fold_gbkk, y_test_fold_gbkk = y_train.iloc[train_index_gbkk], y_train.iloc[test_index_gbkk]\n",
    "\n",
    "        # Initialize Gaussian Naive Bayes (GBBK) model for this fold\n",
    "        gbbk_model_fold_gbkk = SVC(kernel='rbf', random_state=24)\n",
    "\n",
    "        # Train the GBBK model for this fold\n",
    "        start_train_fold_gbkk = time.time()\n",
    "        gbbk_model_fold_gbkk.fit(X_train_fold_gbkk, y_train_fold_gbkk)\n",
    "        end_train_fold_gbkk = time.time()\n",
    "        time_to_train_gbkk += end_train_fold_gbkk - start_train_fold_gbkk\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_gbkk = time.time()\n",
    "        y_pred_fold_gbkk = gbbk_model_fold_gbkk.predict(X_test_fold_gbkk)\n",
    "        end_predict_fold_gbkk = time.time()\n",
    "        time_to_predict_fold_gbkk += end_predict_fold_gbkk - start_predict_fold_gbkk\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gbkk.extend(y_test_fold_gbkk)\n",
    "        all_y_pred_gbkk.extend(y_pred_fold_gbkk)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_gbkk = confusion_matrix(y_test_fold_gbkk, y_pred_fold_gbkk)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_gbkk = ConfusionMatrixDisplay(confusion_matrix=cm_gbkk)\n",
    "        disp_gbkk.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - RBF SVM\")\n",
    "        pname_gbkk = method + \"_fold_\" + str(fold_number) + \"_RBF_confusion_matrix.png\"\n",
    "        plt.savefig(pname_gbkk)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_gbkk = time.time()\n",
    "    result(all_y_pred_gbkk, all_y_test_gbkk, \"RBF\", time_to_train_gbkk, time_to_predict_fold_gbkk)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"RBF  with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"RBF\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## Stacked Convolutional Neural Networks with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Convert DataFrame to NumPy array\n",
    "    X = X_train.to_numpy()\n",
    "    y = y_train.to_numpy()\n",
    "\n",
    "    # Reshape the input data for Conv1D layer\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "    # Define the CNN model\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')  # Adjust the number of units based on the number of classes in your dataset\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Initialize k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits= n_splits_for_cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_cnn = []\n",
    "    all_y_pred_cnn = []\n",
    "    start_cv_cnn = time.time()\n",
    "    time_to_predict_fold_cnn = 0\n",
    "    time_to_train_cnn = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_cnn, test_index_cnn) in enumerate(skf.split(X, y), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_cnn, X_test_fold_cnn = X[train_index_cnn], X[test_index_cnn]\n",
    "        y_train_fold_cnn, y_test_fold_cnn = y[train_index_cnn], y[test_index_cnn]\n",
    "\n",
    "        # Train the model for this fold\n",
    "        start_train_fold_cnn = time.time()\n",
    "        history = model.fit(X_train_fold_cnn, y_train_fold_cnn, epochs=10, batch_size=64, validation_split=0.2, verbose=1)\n",
    "        end_train_fold_cnn = time.time()\n",
    "        time_to_train_cnn += end_train_fold_cnn - start_train_fold_cnn\n",
    "\n",
    "        # Evaluate the model for this fold\n",
    "        start_predict_fold_cnn = time.time()\n",
    "        y_pred_fold_cnn = model.predict(X_test_fold_cnn)\n",
    "        y_pred_fold_cnn = np.argmax(y_pred_fold_cnn, axis=1)\n",
    "        end_predict_fold_cnn = time.time()\n",
    "        time_to_predict_fold_cnn += end_predict_fold_cnn - start_predict_fold_cnn\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_cnn.extend(y_test_fold_cnn)\n",
    "        all_y_pred_cnn.extend(y_pred_fold_cnn)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_cnn = confusion_matrix(y_test_fold_cnn, y_pred_fold_cnn)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_cnn = ConfusionMatrixDisplay(confusion_matrix=cm_cnn)\n",
    "        disp_cnn.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Stacked Convolutional Neural Networks\")\n",
    "        pname_cnn = method + \"_fold_\" + str(fold_number) + \"_Stacked_Convolutional_Neural_Networks_confusion_matrix.png\"\n",
    "        plt.savefig(pname_cnn)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_cnn = time.time()\n",
    "    result(all_y_pred_cnn, all_y_test_cnn, \"Stacked Convolutional Neural Networks with k-fold Cross-Validation\", time_to_train_cnn, time_to_predict_fold_cnn)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Stacked Convolutional Neural Networks with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Stacked Convolutional Neural Networks\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 64. Simulated Annealing (SA) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Define the objective function for optimization\n",
    "\n",
    "    # Convert X_train and y_train to NumPy arrays\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    # Convert X_test to NumPy array if it's not already\n",
    "    X_test = np.array(X_test)\n",
    "\n",
    "    # Reshape the input data if needed\n",
    "    if X_train.ndim > 2:\n",
    "        X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    if X_test.ndim > 2:\n",
    "        X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    def objective_function(params):\n",
    "        max_depth, min_samples_split, min_samples_leaf = params\n",
    "\n",
    "        # Create and train the Decision Tree model with given hyperparameters\n",
    "        dt_model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, random_state=24)\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict using the trained model\n",
    "        y_pred = dt_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model - Example: using accuracy\n",
    "        accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "        # Return the negative of the accuracy (since we want to minimize)\n",
    "        return -accuracy\n",
    "    # Simulated Annealing hyperparameter optimization\n",
    "    def simulated_annealing(objective_function, space, n_calls=50, initial_temperature=100.0, cooling_rate=0.95):\n",
    "        best_params = None\n",
    "        best_score = float('-inf')\n",
    "        temperature = initial_temperature\n",
    "\n",
    "        current_params = [np.random.randint(low, high + 1) for low, high in space]\n",
    "\n",
    "        for _ in range(n_calls):\n",
    "            next_params = [np.random.randint(low, high + 1) for low, high in space]\n",
    "\n",
    "            current_score = objective_function(current_params)\n",
    "            next_score = objective_function(next_params)\n",
    "\n",
    "            if next_score > current_score or np.random.rand() < np.exp((next_score - current_score) / temperature):\n",
    "                current_params = next_params\n",
    "                current_score = next_score\n",
    "\n",
    "            if current_score > best_score:\n",
    "                best_params = current_params\n",
    "                best_score = current_score\n",
    "\n",
    "            temperature *= cooling_rate\n",
    "\n",
    "        return best_params\n",
    "    # Define the search space for hyperparameters\n",
    "    space = [(1, 20),  # max_depth\n",
    "            (2, 20),  # min_samples_split\n",
    "            (1, 20)]  # min_samples_leaf\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_sa = []\n",
    "    all_y_pred_sa = []\n",
    "    start_cv_sa = time.time()\n",
    "    time_to_predict_fold_sa = 0\n",
    "    time_to_train_sa = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_sa, test_index_sa) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_sa, X_test_fold_sa = X_train[train_index_sa], X_train[test_index_sa]\n",
    "        y_train_fold_sa, y_test_fold_sa = y_train[train_index_sa], y_train[test_index_sa]\n",
    "\n",
    "        # Run the optimization using Simulated Annealing for this fold\n",
    "        start_train_fold_sa = time.time()\n",
    "        best_params = simulated_annealing(objective_function, space)\n",
    "        end_train_fold_sa = time.time()\n",
    "\n",
    "        # Train the final model with the best hyperparameters for this fold\n",
    "        dt_model_final_fold_sa = DecisionTreeClassifier(max_depth=best_params[0], min_samples_split=best_params[1], min_samples_leaf=best_params[2], random_state=24)\n",
    "        dt_model_final_fold_sa.fit(X_train_fold_sa, y_train_fold_sa)\n",
    "\n",
    "        # Predict using the final model for this fold\n",
    "        start_predict_fold_sa = time.time()\n",
    "        y_pred_fold_sa = dt_model_final_fold_sa.predict(X_test_fold_sa)\n",
    "        end_predict_fold_sa = time.time()\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_sa.extend(y_test_fold_sa)\n",
    "        all_y_pred_sa.extend(y_pred_fold_sa)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_sa = confusion_matrix(y_test_fold_sa, y_pred_fold_sa)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_sa = ConfusionMatrixDisplay(confusion_matrix=cm_sa)\n",
    "        disp_sa.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - SA\")\n",
    "        pname_sa = method + \"_fold_\" + str(fold_number) + \"_SA_confusion_matrix.png\"\n",
    "        plt.savefig(pname_sa)\n",
    "        #plt.show()\n",
    "\n",
    "        # Calculate time metrics\n",
    "        time_to_train_fold_sa = end_train_fold_sa - start_train_fold_sa\n",
    "        time_to_predict_fold_sa = end_predict_fold_sa - start_predict_fold_sa\n",
    "\n",
    "        # Update overall time metrics\n",
    "        time_to_train_sa += time_to_train_fold_sa\n",
    "        time_to_predict_fold_sa += time_to_predict_fold_sa\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_sa = time.time()\n",
    "    result(all_y_pred_sa, all_y_test_sa, \"Simulated Annealing (SA)\", time_to_train_sa, time_to_predict_fold_sa)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"SA with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Simulated Annealing\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## SVM with Optimization and k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Reshape input data to have two dimensions\n",
    "    X_flattened = X.reshape(X.shape[0], -1)\n",
    "\n",
    "    # Initialize k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits= n_splits_for_cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_svm = []\n",
    "    all_y_pred_svm = []\n",
    "    start_cv_svm = time.time()\n",
    "    time_to_predict_fold_svm = 0\n",
    "    time_to_train_svm = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_svm, test_index_svm) in enumerate(skf.split(X_flattened, y), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_svm, X_test_fold_svm = X_flattened[train_index_svm], X_flattened[test_index_svm]\n",
    "        y_train_fold_svm, y_test_fold_svm = y[train_index_svm], y[test_index_svm]\n",
    "\n",
    "        # Create and train the SVM model with optimization for this fold\n",
    "        start_train_fold_svm = time.time()\n",
    "        svm_model_fold = SVC(kernel='linear', C=1.0)  # Example hyperparameters, adjust as needed\n",
    "        svm_model_fold.fit(X_train_fold_svm, y_train_fold_svm)\n",
    "        end_train_fold_svm = time.time()\n",
    "        time_to_train_svm += end_train_fold_svm - start_train_fold_svm\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_svm = time.time()\n",
    "        y_pred_fold_svm = svm_model_fold.predict(X_test_fold_svm)\n",
    "        end_predict_fold_svm = time.time()\n",
    "        time_to_predict_fold_svm += end_predict_fold_svm - start_predict_fold_svm\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_svm.extend(y_test_fold_svm)\n",
    "        all_y_pred_svm.extend(y_pred_fold_svm)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_svm = confusion_matrix(y_test_fold_svm, y_pred_fold_svm)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_svm = ConfusionMatrixDisplay(confusion_matrix=cm_svm)\n",
    "        disp_svm.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - SVM with Optimization\")\n",
    "        pname_svm = method + \"_fold_\" + str(fold_number) + \"_SVM_with_Optimization_confusion_matrix.png\"\n",
    "        plt.savefig(pname_svm)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_svm = time.time()\n",
    "    result(all_y_pred_svm, all_y_test_svm, \"SVM with Optimization and k-fold Cross-Validation\", time_to_train_svm, time_to_predict_fold_svm)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"SVM with Optimization and k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"SVM\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 66 Stacking Classifier with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Define base classifiers\n",
    "    base_classifiers = [\n",
    "        ('dt', DecisionTreeClassifier(random_state=24)),\n",
    "        ('rf', RandomForestClassifier(random_state=24)),\n",
    "        ('knn', KNeighborsClassifier())\n",
    "    ]\n",
    "\n",
    "    # Initialize Stacking Classifier with base classifiers\n",
    "    stacking_classifier = StackingClassifier(estimators=base_classifiers, final_estimator=DecisionTreeClassifier())\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_stacking = []\n",
    "    all_y_pred_stacking = []\n",
    "    start_cv_stacking = time.time()\n",
    "    time_to_predict_fold_stacking = 0\n",
    "    time_to_train_stacking = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_stacking, test_index_stacking) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_stacking, X_test_fold_stacking = X_train[train_index_stacking], X_train[test_index_stacking]\n",
    "        y_train_fold_stacking, y_test_fold_stacking = y_train[train_index_stacking], y_train[test_index_stacking]\n",
    "\n",
    "        # Train the Stacking Classifier for this fold\n",
    "        start_train_fold_stacking = time.time()\n",
    "        stacking_classifier.fit(X_train_fold_stacking, y_train_fold_stacking)\n",
    "        end_train_fold_stacking = time.time()\n",
    "        time_to_train_stacking += end_train_fold_stacking - start_train_fold_stacking\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_stacking = time.time()\n",
    "        y_pred_fold_stacking = stacking_classifier.predict(X_test_fold_stacking)\n",
    "        end_predict_fold_stacking = time.time()\n",
    "        time_to_predict_fold_stacking += end_predict_fold_stacking - start_predict_fold_stacking\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_stacking.extend(y_test_fold_stacking)\n",
    "        all_y_pred_stacking.extend(y_pred_fold_stacking)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_stacking = confusion_matrix(y_test_fold_stacking, y_pred_fold_stacking)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_stacking = ConfusionMatrixDisplay(confusion_matrix=cm_stacking)\n",
    "        disp_stacking.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Stacking Classifier\")\n",
    "        pname_stacking = method + \"_fold_\" + str(fold_number) + \"_Stacking_Classifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname_stacking)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_stacking = time.time()\n",
    "\n",
    "\n",
    "    result(all_y_pred_stacking, all_y_test_stacking, \"Stacking Classifier\",  time_to_train_stacking, time_to_predict_fold_stacking)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Stacking Classifier with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Stacking Classifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 67 Stacking Dilated Convolutional Autoencoders with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # You may replace this with your DCAE model\n",
    "    base_model = make_pipeline(StandardScaler(), DecisionTreeClassifier(random_state=24))\n",
    "\n",
    "    # Define the stacking classifier\n",
    "    stacking_model = StackingClassifier(estimators=[('dt', base_model)], final_estimator=DecisionTreeClassifier())\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_stacking_dcae = []\n",
    "    all_y_pred_stacking_dcae = []\n",
    "    time_to_predict_fold_stacking_dcae = 0\n",
    "    time_to_train_stacking_dcae = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_stacking_dcae, test_index_stacking_dcae) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_stacking_dcae, X_test_fold_stacking_dcae = X_train[train_index_stacking_dcae], X_train[test_index_stacking_dcae]\n",
    "        y_train_fold_stacking_dcae, y_test_fold_stacking_dcae = y_train[train_index_stacking_dcae], y_train[test_index_stacking_dcae]\n",
    "\n",
    "        # Training the stacking model for this fold\n",
    "        start_train_fold_stacking_dcae = time.time()\n",
    "        stacking_model.fit(X_train_fold_stacking_dcae, y_train_fold_stacking_dcae)\n",
    "        end_train_fold_stacking_dcae = time.time()\n",
    "        time_to_train_stacking_dcae += end_train_fold_stacking_dcae - start_train_fold_stacking_dcae\n",
    "\n",
    "        # Predict using the trained stacking model for this fold\n",
    "        start_predict_fold_stacking_dcae = time.time()\n",
    "        y_pred_fold_stacking_dcae = stacking_model.predict(X_test_fold_stacking_dcae)\n",
    "        end_predict_fold_stacking_dcae = time.time()\n",
    "        time_to_predict_fold_stacking_dcae += end_predict_fold_stacking_dcae - start_predict_fold_stacking_dcae\n",
    "\n",
    "        # Generate confusion matrix for this fold\n",
    "        cm_stacking_dcae = confusion_matrix(y_test_fold_stacking_dcae, y_pred_fold_stacking_dcae)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_stacking_dcae = ConfusionMatrixDisplay(confusion_matrix=cm_stacking_dcae)\n",
    "        disp_stacking_dcae.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Stacking DCAE\")\n",
    "        pname_stacking_dcae = method + \"_fold_\" + str(fold_number) + \"_Stacking_DCAE_confusion_matrix.png\"\n",
    "        plt.savefig(pname_stacking_dcae)\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_stacking_dcae.extend(y_test_fold_stacking_dcae)\n",
    "        all_y_pred_stacking_dcae.extend(y_pred_fold_stacking_dcae)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    result(all_y_pred_stacking_dcae, all_y_test_stacking_dcae, \"Stacking Dilated Convolutional Autoencoders\", time_to_train_stacking_dcae, time_to_predict_fold_stacking_dcae)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Stacking Dilated Convolutional Autoencoders with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Stacking Dilated Convolutional\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 68 Temporal Deep Feedforward Neural Network with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Define the structure of the Temporal DNN model\n",
    "    y_train = pd.Series(y_train)\n",
    "    num_classes = y_train.nunique()\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  # Assuming len(y_train.unique()) is the number of classes\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_temporal_dnn = []\n",
    "    all_y_pred_temporal_dnn = []\n",
    "    time_to_predict_fold_temporal_dnn = 0\n",
    "    time_to_train_temporal_dnn = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_temporal_dnn, test_index_temporal_dnn) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_temporal_dnn, X_test_fold_temporal_dnn = X_train[train_index_temporal_dnn], X_train[test_index_temporal_dnn]\n",
    "        y_train_fold_temporal_dnn, y_test_fold_temporal_dnn = y_train[train_index_temporal_dnn], y_train[test_index_temporal_dnn]\n",
    "\n",
    "        # Define the Temporal DNN model for this fold\n",
    "        model_fold_temporal_dnn = Sequential([\n",
    "            Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "            Dropout(0.5),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model_fold_temporal_dnn.compile(optimizer=Adam(),\n",
    "                                        loss='sparse_categorical_crossentropy',\n",
    "                                        metrics=['accuracy'])\n",
    "\n",
    "        # Training the Temporal DNN model for this fold\n",
    "        start_train_fold_temporal_dnn = time.time()\n",
    "        history = model_fold_temporal_dnn.fit(X_train_fold_temporal_dnn, y_train_fold_temporal_dnn, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
    "        end_train_fold_temporal_dnn = time.time()\n",
    "        time_to_train_temporal_dnn += end_train_fold_temporal_dnn - start_train_fold_temporal_dnn\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_temporal_dnn = time.time()\n",
    "        y_pred_probs_fold_temporal_dnn = model_fold_temporal_dnn.predict(X_test_fold_temporal_dnn)\n",
    "        y_pred_fold_temporal_dnn = np.argmax(y_pred_probs_fold_temporal_dnn, axis=1)\n",
    "        end_predict_fold_temporal_dnn = time.time()\n",
    "        time_to_predict_fold_temporal_dnn += end_predict_fold_temporal_dnn - start_predict_fold_temporal_dnn\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_temporal_dnn.extend(y_test_fold_temporal_dnn)\n",
    "        all_y_pred_temporal_dnn.extend(y_pred_fold_temporal_dnn)\n",
    "\n",
    "        # Generate confusion matrix for this fold\n",
    "        cm_temporal_dnn = confusion_matrix(y_test_fold_temporal_dnn, y_pred_fold_temporal_dnn)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_temporal_dnn = ConfusionMatrixDisplay(confusion_matrix=cm_temporal_dnn)\n",
    "        disp_temporal_dnn.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Temporal DNN\")\n",
    "        pname_temporal_dnn = method + \"_fold_\" + str(fold_number) + \"_Temporal_DNN_confusion_matrix.png\"\n",
    "        plt.savefig(pname_temporal_dnn)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    result(all_y_pred_temporal_dnn, all_y_test_temporal_dnn, \"Temporal Deep Feedforward Neural Network\", time_to_train_temporal_dnn, time_to_predict_fold_temporal_dnn)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Temporal Deep Feedforward Neural Network with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Temporal Deep Feedforward Neural\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 69 Voting Classifier with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize individual classifiers\n",
    "    dt1 = DecisionTreeClassifier(random_state=24)\n",
    "    dt2 = DecisionTreeClassifier(random_state=42)\n",
    "    # Add more classifiers if needed\n",
    "\n",
    "    # Create the Voting Classifier\n",
    "    voting_clf = VotingClassifier(estimators=[\n",
    "        ('dt1', dt1),\n",
    "        ('dt2', dt2),\n",
    "        # Add more classifiers here if needed\n",
    "    ], voting='hard')  # You can use 'soft' voting if your classifiers support probability prediction\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_voting = []\n",
    "    all_y_pred_voting = []\n",
    "    time_to_predict_fold_voting = 0\n",
    "    time_to_train_voting = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_voting, test_index_voting) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_voting, X_test_fold_voting = X_train[train_index_voting], X_train[test_index_voting]\n",
    "        y_train_fold_voting, y_test_fold_voting = y_train[train_index_voting], y_train[test_index_voting]\n",
    "\n",
    "        # Train the Voting Classifier for this fold\n",
    "        start_train_fold_voting = time.time()\n",
    "        voting_clf.fit(X_train_fold_voting, y_train_fold_voting)\n",
    "        end_train_fold_voting = time.time()\n",
    "        time_to_train_voting += end_train_fold_voting - start_train_fold_voting\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_voting = time.time()\n",
    "        y_pred_fold_voting = voting_clf.predict(X_test_fold_voting)\n",
    "        end_predict_fold_voting = time.time()\n",
    "        time_to_predict_fold_voting += end_predict_fold_voting - start_predict_fold_voting\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_voting.extend(y_test_fold_voting)\n",
    "        all_y_pred_voting.extend(y_pred_fold_voting)\n",
    "\n",
    "        # Generate confusion matrix for this fold\n",
    "        cm_voting = confusion_matrix(y_test_fold_voting, y_pred_fold_voting)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_voting = ConfusionMatrixDisplay(confusion_matrix=cm_voting)\n",
    "        disp_voting.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Voting Classifier\")\n",
    "        pname_voting = method + \"_fold_\" + str(fold_number) + \"_Voting_Classifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname_voting)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    result(all_y_pred_voting, all_y_test_voting, \"Voting Classifier\", time_to_train_voting, time_to_predict_fold_voting)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Voting Classifier with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Voting Classifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 70 GBT with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize the GBT classifier\n",
    "    gbt_model = GradientBoostingClassifier(random_state=24)\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gbt = []\n",
    "    all_y_pred_gbt = []\n",
    "    time_to_predict_fold_gbt = 0\n",
    "    time_to_train_gbt = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_gbt, test_index_gbt) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_gbt, X_test_fold_gbt = X_train[train_index_gbt], X_train[test_index_gbt]\n",
    "        y_train_fold_gbt, y_test_fold_gbt = y_train[train_index_gbt], y_train[test_index_gbt]\n",
    "\n",
    "        # Train the GBT model for this fold\n",
    "        start_train_fold_gbt = time.time()\n",
    "        gbt_model.fit(X_train_fold_gbt, y_train_fold_gbt)\n",
    "        end_train_fold_gbt = time.time()\n",
    "        time_to_train_gbt += end_train_fold_gbt - start_train_fold_gbt\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_gbt = time.time()\n",
    "        y_pred_fold_gbt = gbt_model.predict(X_test_fold_gbt)\n",
    "        end_predict_fold_gbt = time.time()\n",
    "        time_to_predict_fold_gbt += end_predict_fold_gbt - start_predict_fold_gbt\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gbt.extend(y_test_fold_gbt)\n",
    "        all_y_pred_gbt.extend(y_pred_fold_gbt)\n",
    "\n",
    "        # Generate confusion matrix for this fold\n",
    "        cm_gbt = confusion_matrix(y_test_fold_gbt, y_pred_fold_gbt)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_gbt = ConfusionMatrixDisplay(confusion_matrix=cm_gbt)\n",
    "        disp_gbt.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - GBT\")\n",
    "        pname_gbt = method + \"_fold_\" + str(fold_number) + \"_GBT_confusion_matrix.png\"\n",
    "        plt.savefig(pname_gbt)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    result(all_y_pred_gbt, all_y_test_gbt, \"GBT\", time_to_train_gbt, time_to_predict_fold_gbt)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"GBT with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"GBT\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 71 CART with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "            self.feature_index = feature_index  # Index of feature to split on\n",
    "            self.threshold = threshold  # Threshold value to split on\n",
    "            self.left = left  # Left subtree\n",
    "            self.right = right  # Right subtree\n",
    "            self.value = value  # Class label (for leaf nodes)\n",
    "\n",
    "    class CART:\n",
    "        def __init__(self, max_depth=None):\n",
    "            self.max_depth = max_depth\n",
    "\n",
    "        def fit(self, X, y):\n",
    "            self.n_classes = len(set(y))\n",
    "            self.n_features = X.shape[1]\n",
    "            self.tree = self._build_tree(X, y)\n",
    "\n",
    "        def _build_tree(self, X, y, depth=0):\n",
    "            n_samples, n_features = X.shape\n",
    "            n_labels = len(set(y))\n",
    "\n",
    "            # Stop conditions\n",
    "            if depth == self.max_depth or n_labels == 1:\n",
    "                value = max(set(y), key=list(y).count)\n",
    "                return Node(value=value)\n",
    "\n",
    "            # Find best split\n",
    "            best_gini = float('inf')\n",
    "            best_feature_index = None\n",
    "            best_threshold = None\n",
    "\n",
    "            for feature_index in range(n_features):\n",
    "                thresholds = sorted(set(X[:, feature_index]))\n",
    "                for threshold in thresholds:\n",
    "                    left_indices = (X[:, feature_index] <= threshold)\n",
    "                    right_indices = (X[:, feature_index] > threshold)\n",
    "\n",
    "                    left_gini = self._gini(y[left_indices])\n",
    "                    right_gini = self._gini(y[right_indices])\n",
    "\n",
    "                    gini = (len(left_indices) * left_gini + len(right_indices) * right_gini) / n_samples\n",
    "\n",
    "                    if gini < best_gini:\n",
    "                        best_gini = gini\n",
    "                        best_feature_index = feature_index\n",
    "                        best_threshold = threshold\n",
    "\n",
    "            # Split data\n",
    "            left_indices = (X[:, best_feature_index] <= best_threshold)\n",
    "            right_indices = (X[:, best_feature_index] > best_threshold)\n",
    "\n",
    "            left_subtree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "            right_subtree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "            return Node(best_feature_index, best_threshold, left_subtree, right_subtree)\n",
    "\n",
    "        def _gini(self, y):\n",
    "            n_samples = len(y)\n",
    "            gini = 1.0\n",
    "            for label in set(y):\n",
    "                proportion = (y == label).sum() / n_samples\n",
    "                gini -= proportion ** 2\n",
    "            return gini\n",
    "\n",
    "        def predict(self, X):\n",
    "            return [self._predict_one(sample, self.tree) for sample in X]\n",
    "\n",
    "        def _predict_one(self, sample, node):\n",
    "            if node.value is not None:\n",
    "                return node.value\n",
    "\n",
    "            if sample[node.feature_index] <= node.threshold:\n",
    "                return self._predict_one(sample, node.left)\n",
    "            else:\n",
    "                return self._predict_one(sample, node.right)\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_cart = []\n",
    "    all_y_pred_cart = []\n",
    "    time_to_predict_fold_cart = 0\n",
    "    time_to_train_cart = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_cart, test_index_cart) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_cart, X_test_fold_cart = X_train[train_index_cart], X_train[test_index_cart]\n",
    "        y_train_fold_cart, y_test_fold_cart = y_train[train_index_cart], y_train[test_index_cart]\n",
    "\n",
    "        # Create and train the CART model for this fold\n",
    "        cart_model_fold = CART(max_depth=1)\n",
    "        start_train_fold_cart = time.time()\n",
    "        cart_model_fold.fit(X_train_fold_cart, y_train_fold_cart)\n",
    "        end_train_fold_cart = time.time()\n",
    "        time_to_train_cart += end_train_fold_cart - start_train_fold_cart\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_cart = time.time()\n",
    "        y_pred_fold_cart = cart_model_fold.predict(X_test_fold_cart)\n",
    "        end_predict_fold_cart = time.time()\n",
    "        time_to_predict_fold_cart += end_predict_fold_cart - start_predict_fold_cart\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_cart.extend(y_test_fold_cart)\n",
    "        all_y_pred_cart.extend(y_pred_fold_cart)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_cart = confusion_matrix(y_test_fold_cart, y_pred_fold_cart)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_cart = ConfusionMatrixDisplay(confusion_matrix=cm_cart)\n",
    "        disp_cart.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - CART\")\n",
    "        pname_cart = method + \"_fold_\" + str(fold_number) + \"_CART_confusion_matrix.png\"\n",
    "        plt.savefig(pname_cart)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    result(all_y_pred_cart, all_y_test_cart, \"CART\", time_to_train_cart, time_to_predict_fold_cart)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"CART with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"CART\")\n",
    "\n",
    "## **Closing the outfile**\n",
    "outfile.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Set the path to your directory\n",
    "directory_path = '.'\n",
    "\n",
    "# Patterns to look for in filenames\n",
    "patterns = ['Metrics_fold_1', 'Metrics_fold_2', 'Metrics_fold_3', 'Metrics_fold_4']\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Check if the file is a PNG and contains any of the patterns\n",
    "    if filename.endswith('.png') and any(pattern in filename for pattern in patterns):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        try:\n",
    "            # Delete the file\n",
    "            os.remove(file_path)\n",
    "            print(f'Deleted: {file_path}')\n",
    "        except Exception as e:\n",
    "            print(f'Error deleting {file_path}: {e}')\n",
    "\n",
    "print('Done.')\n",
    "\n",
    "# Your code goes here...\n",
    "\n",
    "# Get the ending time\n",
    "end_time_1 = datetime.datetime.now()\n",
    "\n",
    "# Calculate the total time required for execution\n",
    "total_time = end_time_1 - start_time_1\n",
    "\n",
    "# Format the start time, end time, and total time\n",
    "start_time_str = start_time_1.strftime(\"%d-%m-%Y %H:%M\")\n",
    "end_time_str = end_time_1.strftime(\"%d-%m-%Y %H:%M\")\n",
    "total_time_str = str(total_time)\n",
    "\n",
    "# Write the start time, end time, and total time to the file\n",
    "with open(\"time.txt\", \"a\") as file:\n",
    "    file.write(f\"Start time: {start_time_str}\\n\")\n",
    "    file.write(f\"End time: {end_time_str}\\n\")\n",
    "    file.write(f\"Total time: {total_time_str}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08cfa9-b554-4121-915e-e3d24bf1a443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
